[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "Context",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "Plugin",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "get_raw_files",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "cli",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_simple_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "adapt_daq_run",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "adapt_daq_run",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "get_raw_files",
        "importPath": "waveform_analysis.core",
        "description": "waveform_analysis.core",
        "isExtraImport": true,
        "detail": "waveform_analysis.core",
        "documentation": {}
    },
    {
        "label": "get_waveforms",
        "importPath": "waveform_analysis.core",
        "description": "waveform_analysis.core",
        "isExtraImport": true,
        "detail": "waveform_analysis.core",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "plot_lineage_labview",
        "importPath": "waveform_analysis.utils.visualization.lineage_visualizer",
        "description": "waveform_analysis.utils.visualization.lineage_visualizer",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.visualization.lineage_visualizer",
        "documentation": {}
    },
    {
        "label": "plot_lineage_labview",
        "importPath": "waveform_analysis.utils.visualization.lineage_visualizer",
        "description": "waveform_analysis.utils.visualization.lineage_visualizer",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.visualization.lineage_visualizer",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "adapt_daq_run",
        "importPath": "waveform_analysis.utils.daq.daq",
        "description": "waveform_analysis.utils.daq.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq.daq",
        "documentation": {}
    },
    {
        "label": "get_raw_files",
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "get_waveforms",
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "WaveformStruct",
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "build_waveform_df",
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "find_hits",
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "group_multi_channel_hits",
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "abc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "abc",
        "description": "abc",
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "PEAK_DTYPE",
        "importPath": "waveform_analysis.utils.data_processing.wavestruct",
        "description": "waveform_analysis.utils.data_processing.wavestruct",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.data_processing.wavestruct",
        "documentation": {}
    },
    {
        "label": "RECORD_DTYPE",
        "importPath": "waveform_analysis.utils.data_processing.wavestruct",
        "description": "waveform_analysis.utils.data_processing.wavestruct",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.data_processing.wavestruct",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Minuit",
        "importPath": "iminuit",
        "description": "iminuit",
        "isExtraImport": true,
        "detail": "iminuit",
        "documentation": {}
    },
    {
        "label": "LeastSquares",
        "importPath": "iminuit.cost",
        "description": "iminuit.cost",
        "isExtraImport": true,
        "detail": "iminuit.cost",
        "documentation": {}
    },
    {
        "label": "BaseFitter",
        "importPath": "pyDAW",
        "description": "pyDAW",
        "isExtraImport": true,
        "detail": "pyDAW",
        "documentation": {}
    },
    {
        "label": "norm",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "jax",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jax",
        "description": "jax",
        "detail": "jax",
        "documentation": {}
    },
    {
        "label": "vmap",
        "importPath": "jax",
        "description": "jax",
        "isExtraImport": true,
        "detail": "jax",
        "documentation": {}
    },
    {
        "label": "jax.numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jax.numpy",
        "description": "jax.numpy",
        "detail": "jax.numpy",
        "documentation": {}
    },
    {
        "label": "erf",
        "importPath": "jax.scipy.special",
        "description": "jax.scipy.special",
        "isExtraImport": true,
        "detail": "jax.scipy.special",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "bisect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bisect",
        "description": "bisect",
        "detail": "bisect",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "FancyArrowPatch",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "Rectangle",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "LineageGraphModel",
        "importPath": "waveform_analysis.core.models",
        "description": "waveform_analysis.core.models",
        "isExtraImport": true,
        "detail": "waveform_analysis.core.models",
        "documentation": {}
    },
    {
        "label": "build_lineage_graph",
        "importPath": "waveform_analysis.core.models",
        "description": "waveform_analysis.core.models",
        "isExtraImport": true,
        "detail": "waveform_analysis.core.models",
        "documentation": {}
    },
    {
        "label": "LineageStyle",
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "isExtraImport": true,
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "get_plugin_dtype",
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "isExtraImport": true,
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "get_plugin_title",
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "isExtraImport": true,
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "get_plugins_from_context",
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "isExtraImport": true,
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "example_custom_features",
        "kind": 2,
        "importPath": "examples.advanced_features",
        "description": "examples.advanced_features",
        "peekOfCode": "def example_custom_features():\n    \"\"\"Á§∫‰æãÔºöÊ≥®ÂÜåÂíå‰ΩøÁî®Ëá™ÂÆö‰πâÁâπÂæÅ\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Ëá™ÂÆö‰πâÁâπÂæÅÁ§∫‰æã\")\n    print(\"=\" * 60)\n    dataset = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2, start_channel_slice=6)\n    # Âä†ËΩΩÂíåÂ§ÑÁêÜÊï∞ÊçÆ\n    try:\n        (dataset.load_raw_data().extract_waveforms().structure_waveforms())\n    except FileNotFoundError:",
        "detail": "examples.advanced_features",
        "documentation": {}
    },
    {
        "label": "example_custom_pairing",
        "kind": 2,
        "importPath": "examples.advanced_features",
        "description": "examples.advanced_features",
        "peekOfCode": "def example_custom_pairing():\n    \"\"\"Á§∫‰æãÔºö‰ΩøÁî®Ëá™ÂÆö‰πâÈÖçÂØπÁ≠ñÁï•\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Ëá™ÂÆö‰πâÈÖçÂØπÁ≠ñÁï•Á§∫‰æã\")\n    print(\"=\" * 60)\n    dataset = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2, start_channel_slice=6)\n    # Â§ÑÁêÜÂà∞ÂàÜÁªÑÈò∂ÊÆµ\n    try:\n        (\n            dataset.load_raw_data()",
        "detail": "examples.advanced_features",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.basic_analysis",
        "description": "examples.basic_analysis",
        "peekOfCode": "def main():\n    \"\"\"‰∏ªÂáΩÊï∞ - ÂÆåÊï¥Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ãÁ§∫‰æã\"\"\"\n    print(\"=\" * 60)\n    print(\"Ê≥¢ÂΩ¢Êï∞ÊçÆÂàÜÊûêÁ§∫‰æã\")\n    print(\"=\" * 60)\n    # 1. ÂàõÂª∫Êï∞ÊçÆÈõÜÂÆû‰æã\n    print(\"\\n1. ÂàõÂª∫Êï∞ÊçÆÈõÜ...\")\n    dataset = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2, start_channel_slice=6)\n    # 2. ÊâßË°åÂÆåÊï¥Â§ÑÁêÜÊµÅÁ®ãÔºàÈìæÂºèË∞ÉÁî®Ôºâ\n    print(\"\\n2. ÊâßË°åÊï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã...\")",
        "detail": "examples.basic_analysis",
        "documentation": {}
    },
    {
        "label": "plot_example_waveforms",
        "kind": 2,
        "importPath": "examples.basic_analysis",
        "description": "examples.basic_analysis",
        "peekOfCode": "def plot_example_waveforms(dataset, n_examples=4):\n    \"\"\"ÁªòÂà∂Á§∫‰æãÊ≥¢ÂΩ¢\"\"\"\n    df_paired = dataset.get_paired_events()\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    axes = axes.flatten()\n    for i in range(min(n_examples, len(df_paired))):\n        ax = axes[i]\n        result_ch6 = dataset.get_waveform_at(event_idx=i, channel=0)\n        result_ch7 = dataset.get_waveform_at(event_idx=i, channel=1)\n        if result_ch6 and result_ch7:",
        "detail": "examples.basic_analysis",
        "documentation": {}
    },
    {
        "label": "example_without_waveforms",
        "kind": 2,
        "importPath": "examples.skip_waveforms",
        "description": "examples.skip_waveforms",
        "peekOfCode": "def example_without_waveforms():\n    \"\"\"Á§∫‰æãÔºö‰∏çÂä†ËΩΩÊ≥¢ÂΩ¢Ôºå‰ªÖÊèêÂèñÁâπÂæÅÊï∞ÊçÆ\"\"\"\n    print(\"=\" * 60)\n    print(\"‰∏çÂä†ËΩΩÊ≥¢ÂΩ¢Êï∞ÊçÆÁ§∫‰æã\")\n    print(\"=\" * 60)\n    # ÂàõÂª∫Êï∞ÊçÆÈõÜÔºåÊåáÂÆö load_waveforms=False\n    dataset = WaveformDataset(\n        char=\"50V_OV_circulation_20thr\",\n        n_channels=2,\n        start_channel_slice=6,",
        "detail": "examples.skip_waveforms",
        "documentation": {}
    },
    {
        "label": "example_with_and_without_comparison",
        "kind": 2,
        "importPath": "examples.skip_waveforms",
        "description": "examples.skip_waveforms",
        "peekOfCode": "def example_with_and_without_comparison():\n    \"\"\"ÂØπÊØîÔºöÂä†ËΩΩvs‰∏çÂä†ËΩΩÊ≥¢ÂΩ¢ÁöÑÊÄßËÉΩÂ∑ÆÂºÇ\"\"\"\n    import time\n    print(\"\\n\" + \"=\" * 60)\n    print(\"ÊÄßËÉΩÂØπÊØîÁ§∫‰æã\")\n    print(\"=\" * 60)\n    # Âä†ËΩΩÊ≥¢ÂΩ¢\n    print(\"\\n1. Âä†ËΩΩÊ≥¢ÂΩ¢Êï∞ÊçÆ...\")\n    start = time.time()\n    dataset_with_waves = WaveformDataset(",
        "detail": "examples.skip_waveforms",
        "documentation": {}
    },
    {
        "label": "example_memory_usage",
        "kind": 2,
        "importPath": "examples.skip_waveforms",
        "description": "examples.skip_waveforms",
        "peekOfCode": "def example_memory_usage():\n    \"\"\"‰º∞ËÆ°ÂÜÖÂ≠ò‰ΩøÁî®ÊÉÖÂÜµ\"\"\"\n    import sys\n    print(\"\\n\" + \"=\" * 60)\n    print(\"ÂÜÖÂ≠ò‰ΩøÁî®‰º∞ËÆ°\")\n    print(\"=\" * 60)\n    # Âä†ËΩΩÊ≥¢ÂΩ¢\n    print(\"\\n1. Âä†ËΩΩÊ≥¢ÂΩ¢...\")\n    dataset_with = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2, load_waveforms=True)\n    try:",
        "detail": "examples.skip_waveforms",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.demo_skip_waveforms",
        "description": "scripts.demo_skip_waveforms",
        "peekOfCode": "def main():\n    print(\"\\n\" + \"=\" * 70)\n    print(\"ÊºîÁ§∫ÔºöÈÄâÊã©‰∏çÂä†ËΩΩÂéüÂßãÊ≥¢ÂΩ¢‰ª•ËäÇÁúÅÂÜÖÂ≠ò\")\n    print(\"=\" * 70)\n    # ÊñπÊ≥ï 1: Âä†ËΩΩÊ≥¢ÂΩ¢ÔºàÈªòËÆ§Ôºâ\n    print(\"\\nüìå ÊñπÊ≥ï 1: Âä†ËΩΩÊ≥¢ÂΩ¢Ôºàload_waveforms=TrueÔºåÈªòËÆ§Ôºâ\")\n    print(\"-\" * 70)\n    print(\"\"\"\n    dataset = WaveformDataset(\n        char=\"50V_OV_circulation_20thr\",",
        "detail": "scripts.demo_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "project_root",
        "kind": 5,
        "importPath": "scripts.demo_skip_waveforms",
        "description": "scripts.demo_skip_waveforms",
        "peekOfCode": "project_root = Path(__file__).parent.parent\nsys.path.insert(0, str(project_root))\nfrom waveform_analysis import WaveformDataset\ndef main():\n    print(\"\\n\" + \"=\" * 70)\n    print(\"ÊºîÁ§∫ÔºöÈÄâÊã©‰∏çÂä†ËΩΩÂéüÂßãÊ≥¢ÂΩ¢‰ª•ËäÇÁúÅÂÜÖÂ≠ò\")\n    print(\"=\" * 70)\n    # ÊñπÊ≥ï 1: Âä†ËΩΩÊ≥¢ÂΩ¢ÔºàÈªòËÆ§Ôºâ\n    print(\"\\nüìå ÊñπÊ≥ï 1: Âä†ËΩΩÊ≥¢ÂΩ¢Ôºàload_waveforms=TrueÔºåÈªòËÆ§Ôºâ\")\n    print(\"-\" * 70)",
        "detail": "scripts.demo_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "DummyPlugin",
        "kind": 6,
        "importPath": "scripts.test_profiler",
        "description": "scripts.test_profiler",
        "peekOfCode": "class DummyPlugin(Plugin):\n    provides = \"dummy_data\"\n    dtype = [(\"val\", \"f4\")]\n    def compute(self, context, run_id):\n        import time\n        time.sleep(0.1)  # Simulate work\n        return np.zeros(10, dtype=self.dtype)\ndef test_profiler():\n    st = Context(storage_dir=\"./test_profiler_data\")\n    st.register(DummyPlugin)",
        "detail": "scripts.test_profiler",
        "documentation": {}
    },
    {
        "label": "test_profiler",
        "kind": 2,
        "importPath": "scripts.test_profiler",
        "description": "scripts.test_profiler",
        "peekOfCode": "def test_profiler():\n    st = Context(storage_dir=\"./test_profiler_data\")\n    st.register(DummyPlugin)\n    print(\"Running plugin first time (compute + save)...\")\n    data = st.get_data(\"run_001\", \"dummy_data\")\n    print(f\"Result: {data}\")\n    print(\"\\nRunning plugin second time (load from cache)...\")\n    data = st.get_data(\"run_001\", \"dummy_data\")\n    print(f\"Result: {data}\")\n    print(\"\\nProfiling Summary:\")",
        "detail": "scripts.test_profiler",
        "documentation": {}
    },
    {
        "label": "check_import",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_import():\n    \"\"\"Ê£ÄÊü•ÂåÖÂØºÂÖ•\"\"\"\n    print(\"1. Ê£ÄÊü•ÂåÖÂØºÂÖ•...\")\n    try:\n        import waveform_analysis\n        print(f\"   ‚úÖ waveform_analysis ÁâàÊú¨: {waveform_analysis.__version__}\")\n    except ImportError as e:\n        print(f\"   ‚ùå ÂØºÂÖ•Â§±Ë¥•: {e}\")\n        return False\n    return True",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "check_core_modules",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_core_modules():\n    \"\"\"Ê£ÄÊü•Ê†∏ÂøÉÊ®°Âùó\"\"\"\n    print(\"\\n2. Ê£ÄÊü•Ê†∏ÂøÉÊ®°Âùó...\")\n    try:\n        from waveform_analysis import (\n            WaveformDataset,\n            WaveformStruct,\n            build_waveform_df,\n            get_raw_files,\n            get_waveforms,",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "check_submodules",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_submodules():\n    \"\"\"Ê£ÄÊü•Â≠êÊ®°Âùó\"\"\"\n    print(\"\\n3. Ê£ÄÊü•Â≠êÊ®°Âùó...\")\n    modules = [\n        (\"waveform_analysis.core\", [\"loader\", \"processor\", \"dataset\"]),\n        (\"waveform_analysis.fitting\", [\"models\"]),\n        (\"waveform_analysis.utils\", []),\n    ]\n    all_ok = True\n    for pkg, subs in modules:",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "check_cli",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_cli():\n    \"\"\"Ê£ÄÊü•ÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑\"\"\"\n    print(\"\\n4. Ê£ÄÊü•ÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑...\")\n    import subprocess\n    try:\n        result = subprocess.run([\"waveform-process\", \"--version\"], capture_output=True, text=True, timeout=5)\n        if result.returncode == 0:\n            print(f\"   ‚úÖ CLI Â∑•ÂÖ∑ÂèØÁî®: {result.stdout.strip()}\")\n            return True\n        else:",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "check_dataset_creation",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_dataset_creation():\n    \"\"\"Ê£ÄÊü•Êï∞ÊçÆÈõÜÂàõÂª∫\"\"\"\n    print(\"\\n5. Ê£ÄÊü•Êï∞ÊçÆÈõÜÂàõÂª∫...\")\n    try:\n        from waveform_analysis import WaveformDataset\n        dataset = WaveformDataset(char=\"test\", n_channels=2)\n        print(\"   ‚úÖ WaveformDataset ÂèØ‰ª•ÂàõÂª∫\")\n        print(f\"      - char: {dataset.char}\")\n        print(f\"      - n_channels: {dataset.n_channels}\")\n        return True",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def main():\n    \"\"\"‰∏ªÂáΩÊï∞\"\"\"\n    print(\"=\" * 60)\n    print(\"Waveform Analysis ÂÆâË£ÖÈ™åËØÅ\")\n    print(\"=\" * 60)\n    checks = [\n        check_import,\n        check_core_modules,\n        check_submodules,\n        check_cli,",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "make_csv_fn",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def make_csv_fn():\n    \"\"\"Fixture that returns the make_csv helper function.\"\"\"\n    return make_csv\n@pytest.fixture\ndef make_simple_csv_fn():\n    \"\"\"Fixture that returns the make_simple_csv helper function.\"\"\"\n    return make_simple_csv\n@pytest.fixture\ndef create_daq_run(tmp_path: Path):\n    \"\"\"Factory fixture to create a DAQ run directory structure.",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "make_simple_csv_fn",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def make_simple_csv_fn():\n    \"\"\"Fixture that returns the make_simple_csv helper function.\"\"\"\n    return make_simple_csv\n@pytest.fixture\ndef create_daq_run(tmp_path: Path):\n    \"\"\"Factory fixture to create a DAQ run directory structure.\n    Usage:\n        daq_root, run_dir, raw_dir = create_daq_run('my_run')\n        # optionally create files with make_csv_fn in tests\n    \"\"\"",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "create_daq_run",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def create_daq_run(tmp_path: Path):\n    \"\"\"Factory fixture to create a DAQ run directory structure.\n    Usage:\n        daq_root, run_dir, raw_dir = create_daq_run('my_run')\n        # optionally create files with make_csv_fn in tests\n    \"\"\"\n    def _create(run_name: str = \"run\"):\n        daq_root = tmp_path / \"DAQ\"\n        run_dir = daq_root / run_name\n        raw_dir = run_dir / \"RAW\"",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "test_import",
        "kind": 2,
        "importPath": "tests.test_basic",
        "description": "tests.test_basic",
        "peekOfCode": "def test_import():\n    \"\"\"ÊµãËØïÂåÖÂèØ‰ª•Ê≠£Â∏∏ÂØºÂÖ•\"\"\"\n    from waveform_analysis import (\n        WaveformDataset,\n        WaveformStruct,\n        build_waveform_df,\n        get_raw_files,\n        get_waveforms,\n        group_multi_channel_hits,\n    )",
        "detail": "tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_waveform_struct",
        "kind": 2,
        "importPath": "tests.test_basic",
        "description": "tests.test_basic",
        "peekOfCode": "def test_waveform_struct():\n    \"\"\"ÊµãËØïÊ≥¢ÂΩ¢ÁªìÊûÑÂåñ\"\"\"\n    from waveform_analysis.core import WaveformStruct\n    # ÂàõÂª∫Ê®°ÊãüÊï∞ÊçÆ\n    mock_waveforms = [np.random.randn(100, 807), np.random.randn(100, 807)]\n    struct = WaveformStruct(mock_waveforms)\n    st_waveforms = struct.structrue_waveforms()\n    assert len(st_waveforms) == 2\n    assert len(st_waveforms[0]) == 100\ndef test_dataset_init():",
        "detail": "tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_dataset_init",
        "kind": 2,
        "importPath": "tests.test_basic",
        "description": "tests.test_basic",
        "peekOfCode": "def test_dataset_init():\n    \"\"\"ÊµãËØïÊï∞ÊçÆÈõÜÂàùÂßãÂåñ\"\"\"\n    try:\n        dataset = WaveformDataset(char=\"test_dataset\", n_channels=2, start_channel_slice=6)\n        assert dataset.char == \"test_dataset\"\n        assert dataset.n_channels == 2\n    except FileNotFoundError:\n        # Â¶ÇÊûúÊµãËØïÊï∞ÊçÆ‰∏çÂ≠òÂú®ÔºåË∑≥Ëøá\n        pytest.skip(\"Test data not available\")\nif __name__ == \"__main__\":",
        "detail": "tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_persistent_cache_invalidates_on_file_change",
        "kind": 2,
        "importPath": "tests.test_cache_invalidation",
        "description": "tests.test_cache_invalidation",
        "peekOfCode": "def test_persistent_cache_invalidates_on_file_change(tmp_path: Path, make_csv_fn):\n    # Set up a DAQ-like run structure\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"inv_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create a CSV file for channel 6\n    make_csv_fn(raw_dir, 6, 0, 1000, 2000)\n    cache_path = tmp_path / \"load_cache.pkl\"\n    ds = WaveformDataset(char=\"inv_run\", data_root=str(daq_root), use_daq_scan=True)",
        "detail": "tests.test_cache_invalidation",
        "documentation": {}
    },
    {
        "label": "test_chain_continues_on_error",
        "kind": 2,
        "importPath": "tests.test_chainable_steps",
        "description": "tests.test_chainable_steps",
        "peekOfCode": "def test_chain_continues_on_error(tmp_path: Path):\n    # prepare run with minimal files\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"chain_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    make_csv(raw_dir, 6, 0, 1000, 1100, n_samples=10)\n    ds = WaveformDataset(char=\"chain_run\", data_root=str(daq_root), use_daq_scan=True)\n    # ÊõøÊç¢Á±ªÊñπÊ≥ï‰∏∫Âá∫ÈîôÁâàÊú¨Âπ∂Áî® chainable_step ÂåÖË£Ö\n    def _bad_structure(self, verbose: bool = True):",
        "detail": "tests.test_chainable_steps",
        "documentation": {}
    },
    {
        "label": "test_fail_on_error_behavior",
        "kind": 2,
        "importPath": "tests.test_chainable_steps",
        "description": "tests.test_chainable_steps",
        "peekOfCode": "def test_fail_on_error_behavior(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"chain_run2\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    from tests.utils import make_csv\n    make_csv(raw_dir, 6, 0, 2000, 2100, n_samples=10)\n    ds = WaveformDataset(char=\"chain_run2\", data_root=str(daq_root), use_daq_scan=True)\n    # ÊõøÊç¢Á±ªÊñπÊ≥ï‰∏∫Âá∫ÈîôÁâàÊú¨Âπ∂Áî® chainable_step ÂåÖË£Ö\n    def _bad_build_dataframe(self, verbose: bool = True):",
        "detail": "tests.test_chainable_steps",
        "documentation": {}
    },
    {
        "label": "test_cli_show_daq_returns_zero",
        "kind": 2,
        "importPath": "tests.test_cli_show_daq",
        "description": "tests.test_cli_show_daq",
        "peekOfCode": "def test_cli_show_daq_returns_zero(tmp_path: Path, monkeypatch):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"cli_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create minimal CSVs\n    n_samples = 50\n    header = \"HEADER;X;TIMETAG;\" + \";\".join(f\"S{i}\" for i in range(n_samples)) + \"\\n\"\n    from tests.utils import make_simple_csv\n    make_simple_csv(raw_dir, 6, 0, 1000, n_samples=50)",
        "detail": "tests.test_cli_show_daq",
        "documentation": {}
    },
    {
        "label": "test_scan_single_run",
        "kind": 2,
        "importPath": "tests.test_daq",
        "description": "tests.test_daq",
        "peekOfCode": "def test_scan_single_run(tmp_path: Path, make_csv_fn):\n    # ÂáÜÂ§áÊ®°Êãü DAQ ÁõÆÂΩï\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"test_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # ÂàõÂª∫‰∏§‰∏™ÈÄöÈÅìÁöÑ CSV Êñá‰ª∂\n    make_csv_fn(raw_dir, 1, 0, 1000, 2000)\n    make_csv_fn(raw_dir, 2, 0, 1500, 2500)\n    # ËøêË°åÊâ´Êèè",
        "detail": "tests.test_daq",
        "documentation": {}
    },
    {
        "label": "test_waveformdataset_loads_using_daq_scan",
        "kind": 2,
        "importPath": "tests.test_daq_integration",
        "description": "tests.test_daq_integration",
        "peekOfCode": "def test_waveformdataset_loads_using_daq_scan(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"my_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create CH6/CH7 files to match start_channel_slice default 6\n    make_csv(raw_dir, 6, 0, 1000, 2000)\n    make_csv(raw_dir, 7, 0, 1500, 2500)\n    # Use DAQ scan integration\n    ds = WaveformDataset(char=\"my_run\", data_root=str(daq_root), use_daq_scan=True)",
        "detail": "tests.test_daq_integration",
        "documentation": {}
    },
    {
        "label": "test_waveformdataset_loads_using_daq_report",
        "kind": 2,
        "importPath": "tests.test_daq_integration",
        "description": "tests.test_daq_integration",
        "peekOfCode": "def test_waveformdataset_loads_using_daq_report(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"report_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    make_csv(raw_dir, 6, 0, 1000, 2000)\n    # create json report\n    analyzer = DAQAnalyzer(str(daq_root))\n    analyzer.scan_all_runs()\n    out = tmp_path / \"report.json\"",
        "detail": "tests.test_daq_integration",
        "documentation": {}
    },
    {
        "label": "test_summary_includes_daq_info",
        "kind": 2,
        "importPath": "tests.test_daq_report_factory_and_summary",
        "description": "tests.test_daq_report_factory_and_summary",
        "peekOfCode": "def test_summary_includes_daq_info(tmp_path: Path, make_csv_fn):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"summ_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create channel files\n    make_csv_fn(raw_dir, 6, 0, 1000, 2000)\n    make_csv_fn(raw_dir, 7, 0, 1500, 2500)\n    ds = WaveformDataset(char=\"summ_run\", data_root=str(daq_root), use_daq_scan=True)\n    ds.check_daq_status()",
        "detail": "tests.test_daq_report_factory_and_summary",
        "documentation": {}
    },
    {
        "label": "test_from_daq_report_runs_pipeline",
        "kind": 2,
        "importPath": "tests.test_daq_report_factory_and_summary",
        "description": "tests.test_daq_report_factory_and_summary",
        "peekOfCode": "def test_from_daq_report_runs_pipeline(tmp_path: Path, make_csv_fn):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"factory_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create minimal CSVs\n    make_csv_fn(raw_dir, 6, 0, 1000, 2000)\n    make_csv_fn(raw_dir, 7, 0, 1500, 2500)\n    analyzer = DAQAnalyzer(str(daq_root))\n    analyzer.scan_all_runs()",
        "detail": "tests.test_daq_report_factory_and_summary",
        "documentation": {}
    },
    {
        "label": "test_summary_from_daq_scan_includes_fields",
        "kind": 2,
        "importPath": "tests.test_daq_summary_scan",
        "description": "tests.test_daq_summary_scan",
        "peekOfCode": "def test_summary_from_daq_scan_includes_fields(tmp_path: Path, make_csv_fn):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"scan_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    make_csv_fn(raw_dir, 6, 0, 1000, 2000)\n    make_csv_fn(raw_dir, 7, 0, 1500, 2500)\n    ds = WaveformDataset(char=\"scan_run\", data_root=str(daq_root), use_daq_scan=True, daq_root=str(daq_root))\n    info = ds.check_daq_status()\n    assert info is not None",
        "detail": "tests.test_daq_summary_scan",
        "documentation": {}
    },
    {
        "label": "test_display_run_channel_details_prints",
        "kind": 2,
        "importPath": "tests.test_display_run_channel_details",
        "description": "tests.test_display_run_channel_details",
        "peekOfCode": "def test_display_run_channel_details_prints(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"disp_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    make_csv(raw_dir, 6, 0, 1000, 2000)\n    make_csv(raw_dir, 7, 0, 1500, 2500)\n    analyzer = DAQAnalyzer(str(daq_root))\n    analyzer.scan_all_runs()\n    # ensure it doesn't raise and returns self",
        "detail": "tests.test_display_run_channel_details",
        "documentation": {}
    },
    {
        "label": "test_raw_file_loader",
        "kind": 2,
        "importPath": "tests.test_loader",
        "description": "tests.test_loader",
        "peekOfCode": "def test_raw_file_loader():\n    \"\"\"ÊµãËØïÂéüÂßãÊñá‰ª∂Âä†ËΩΩÂô®\"\"\"\n    from utils.data_processing.loader import RawFileLoader\n    loader = RawFileLoader(n_channels=8, char=\"test\")\n    assert loader.n_channels == 8\n    assert loader.base_dir.name == \"RAW\"\nif __name__ == \"__main__\":\n    pytest.main([__file__, \"-v\"])",
        "detail": "tests.test_loader",
        "documentation": {}
    },
    {
        "label": "test_without_waveforms",
        "kind": 2,
        "importPath": "tests.test_skip_waveforms",
        "description": "tests.test_skip_waveforms",
        "peekOfCode": "def test_without_waveforms(create_daq_run):\n    \"\"\"ÊµãËØïÔºö‰∏çÂä†ËΩΩÊ≥¢ÂΩ¢Ôºà‰ΩøÁî® fixtureÔºâ„ÄÇ\"\"\"\n    daq_root, run_dir, raw_dir = create_daq_run(\"50V_OV_circulation_20thr\")\n    dataset = WaveformDataset(\n        char=\"50V_OV_circulation_20thr\",\n        n_channels=2,\n        start_channel_slice=6,\n        load_waveforms=False,\n        data_root=str(daq_root),\n    )",
        "detail": "tests.test_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "test_with_waveforms",
        "kind": 2,
        "importPath": "tests.test_skip_waveforms",
        "description": "tests.test_skip_waveforms",
        "peekOfCode": "def test_with_waveforms(create_daq_run, make_simple_csv_fn):\n    \"\"\"ÊµãËØïÔºöÂä†ËΩΩÊ≥¢ÂΩ¢Ôºà‰ΩøÁî® fixtureÔºâ„ÄÇ\"\"\"\n    daq_root, run_dir, raw_dir = create_daq_run(\"50V_OV_circulation_20thr\")\n    # create a tiny CSV so load_raw_data can find something\n    make_simple_csv_fn(raw_dir, 6, 0, 1234, n_samples=20)\n    dataset = WaveformDataset(\n        char=\"50V_OV_circulation_20thr\",\n        n_channels=2,\n        start_channel_slice=6,\n        load_waveforms=True,",
        "detail": "tests.test_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "test_with_waveforms",
        "kind": 2,
        "importPath": "tests.test_skip_waveforms",
        "description": "tests.test_skip_waveforms",
        "peekOfCode": "def test_with_waveforms(tmp_path: Path):\n    \"\"\"ÊµãËØïÔºöÂä†ËΩΩÊ≥¢ÂΩ¢\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"ÊµãËØï 2: Âä†ËΩΩÊ≥¢ÂΩ¢ (load_waveforms=TrueÔºåÈªòËÆ§)\")\n    print(\"=\" * 70)\n    data_root = tmp_path / \"DAQ\"\n    run_dir = data_root / \"50V_OV_circulation_20thr\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create a tiny CSV so load_raw_data can find something",
        "detail": "tests.test_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "test_memory_cache",
        "kind": 2,
        "importPath": "tests.test_step_caching",
        "description": "tests.test_step_caching",
        "peekOfCode": "def test_memory_cache(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"cache_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    from tests.utils import make_simple_csv\n    make_simple_csv(raw_dir, 6, 0, 1000)\n    ds = WaveformDataset(char=\"cache_run\", data_root=str(daq_root), use_daq_scan=True)\n    # enable caching for structure_waveforms to store st_waveforms and pair_len\n    ds.set_step_cache(\"structure_waveforms\", enabled=True, attrs=[\"st_waveforms\", \"pair_len\"])",
        "detail": "tests.test_step_caching",
        "documentation": {}
    },
    {
        "label": "test_persistent_cache",
        "kind": 2,
        "importPath": "tests.test_step_caching",
        "description": "tests.test_step_caching",
        "peekOfCode": "def test_persistent_cache(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"cache_run2\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    from tests.utils import make_simple_csv\n    make_simple_csv(raw_dir, 6, 0, 2000)\n    ds = WaveformDataset(char=\"cache_run2\", data_root=str(daq_root), use_daq_scan=True)\n    cache_file = tmp_path / \"struct_cache.pkl\"\n    ds.set_step_cache(",
        "detail": "tests.test_step_caching",
        "documentation": {}
    },
    {
        "label": "GoodDAQWithMethod",
        "kind": 6,
        "importPath": "tests.test_utils_daq_adapter",
        "description": "tests.test_utils_daq_adapter",
        "peekOfCode": "class GoodDAQWithMethod:\n    def __init__(self, paths):\n        self._paths = paths\n    def get_channel_paths(self, n_channels):\n        out = [list(p) for p in self._paths]\n        if len(out) < n_channels:\n            out.extend([[]] * (n_channels - len(out)))\n        return out[:n_channels]\nclass BadMethodWithChannelFiles:\n    def __init__(self, channel_files):",
        "detail": "tests.test_utils_daq_adapter",
        "documentation": {}
    },
    {
        "label": "BadMethodWithChannelFiles",
        "kind": 6,
        "importPath": "tests.test_utils_daq_adapter",
        "description": "tests.test_utils_daq_adapter",
        "peekOfCode": "class BadMethodWithChannelFiles:\n    def __init__(self, channel_files):\n        self.channel_files = channel_files\n    def get_channel_paths(self, n_channels):\n        raise RuntimeError(\"simulated failure\")\ndef test_adapter_prefers_existing_method():\n    daq = GoodDAQWithMethod(paths=[[\"a.csv\"], [], [\"c1.csv\", \"c2.csv\"]])\n    adapted = adapt_daq_run(daq)\n    res = adapted.get_channel_paths(4)\n    assert isinstance(res, list)",
        "detail": "tests.test_utils_daq_adapter",
        "documentation": {}
    },
    {
        "label": "test_adapter_prefers_existing_method",
        "kind": 2,
        "importPath": "tests.test_utils_daq_adapter",
        "description": "tests.test_utils_daq_adapter",
        "peekOfCode": "def test_adapter_prefers_existing_method():\n    daq = GoodDAQWithMethod(paths=[[\"a.csv\"], [], [\"c1.csv\", \"c2.csv\"]])\n    adapted = adapt_daq_run(daq)\n    res = adapted.get_channel_paths(4)\n    assert isinstance(res, list)\n    assert len(res) == 4\n    assert res[0] == [\"a.csv\"]\n    assert res[1] == []\n    assert res[2] == [\"c1.csv\", \"c2.csv\"]\n    assert res[3] == []",
        "detail": "tests.test_utils_daq_adapter",
        "documentation": {}
    },
    {
        "label": "test_adapter_falls_back_to_channel_files_on_method_error",
        "kind": 2,
        "importPath": "tests.test_utils_daq_adapter",
        "description": "tests.test_utils_daq_adapter",
        "peekOfCode": "def test_adapter_falls_back_to_channel_files_on_method_error():\n    cf = {\n        0: [{\"path\": \"p0_first\"}, \"p0_second\"],\n        2: [{\"path\": \"p2_only\"}],\n    }\n    daq = BadMethodWithChannelFiles(channel_files=cf)\n    adapted = adapt_daq_run(daq)\n    res = adapted.get_channel_paths(4)\n    assert res[0] == [\"p0_first\", \"p0_second\"]\n    assert res[1] == []",
        "detail": "tests.test_utils_daq_adapter",
        "documentation": {}
    },
    {
        "label": "test_adapter_accepts_plain_dict_mapping",
        "kind": 2,
        "importPath": "tests.test_utils_daq_adapter",
        "description": "tests.test_utils_daq_adapter",
        "peekOfCode": "def test_adapter_accepts_plain_dict_mapping():\n    mapping = {0: [\"d0_1\", {\"path\": \"d0_2\"}], 2: [\"d2_1\"]}\n    adapted = adapt_daq_run(mapping)\n    res = adapted.get_channel_paths(4)\n    assert res[0] == [\"d0_1\", \"d0_2\"]\n    assert res[1] == []\n    assert res[2] == [\"d2_1\"]\n    assert res[3] == []\ndef test_adapter_unknown_shape_returns_empty_lists():\n    class Unknown: ...",
        "detail": "tests.test_utils_daq_adapter",
        "documentation": {}
    },
    {
        "label": "test_adapter_unknown_shape_returns_empty_lists",
        "kind": 2,
        "importPath": "tests.test_utils_daq_adapter",
        "description": "tests.test_utils_daq_adapter",
        "peekOfCode": "def test_adapter_unknown_shape_returns_empty_lists():\n    class Unknown: ...\n    adapted = adapt_daq_run(Unknown())\n    assert adapted.get_channel_paths(3) == [[], [], []]\ndef test_channel_files_non_dict_is_ignored():\n    class HasListChannelFiles:\n        def __init__(self):\n            self.channel_files = [\"not\", \"a\", \"dict\"]\n    adapted = adapt_daq_run(HasListChannelFiles())\n    assert adapted.get_channel_paths(2) == [[], []]",
        "detail": "tests.test_utils_daq_adapter",
        "documentation": {}
    },
    {
        "label": "test_channel_files_non_dict_is_ignored",
        "kind": 2,
        "importPath": "tests.test_utils_daq_adapter",
        "description": "tests.test_utils_daq_adapter",
        "peekOfCode": "def test_channel_files_non_dict_is_ignored():\n    class HasListChannelFiles:\n        def __init__(self):\n            self.channel_files = [\"not\", \"a\", \"dict\"]\n    adapted = adapt_daq_run(HasListChannelFiles())\n    assert adapted.get_channel_paths(2) == [[], []]",
        "detail": "tests.test_utils_daq_adapter",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "kind": 2,
        "importPath": "tests.utils",
        "description": "tests.utils",
        "peekOfCode": "def make_csv(dirpath: Path, ch: int, idx: int, start_tag: int, end_tag: int, n_samples: int = 200, meta: bool = True):\n    \"\"\"Create a CSV file with header and three rows (start, mid, end).\n    dirpath: Path to RAW directory\n    ch, idx: channel and index used in filename\n    start_tag, end_tag: timetag values\n    n_samples: number of sample columns (S0..)\n    meta: whether to add a metadata line before header (so skiprows=2 in loader works)\n    \"\"\"\n    fname = dirpath / f\"RUN_CH{ch}_{idx}.CSV\"\n    sample_headers = \";\".join(f\"S{i}\" for i in range(n_samples))",
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_simple_csv",
        "kind": 2,
        "importPath": "tests.utils",
        "description": "tests.utils",
        "peekOfCode": "def make_simple_csv(dirpath: Path, ch: int, idx: int, tag: int, n_samples: int = 50):\n    \"\"\"Create a simpler CSV used by some tests (two data rows)\"\"\"\n    fname = dirpath / f\"RUN_CH{ch}_{idx}.CSV\"\n    header = \"HEADER;X;TIMETAG;\" + \";\".join(f\"S{i}\" for i in range(n_samples)) + \"\\n\"\n    body = \"\".join(\n        f\"v;1;{tag + i};\" + \";\".join(str((tag + i + j) % 100) for j in range(n_samples)) + \"\\n\" for i in range(2)\n    )\n    fname.write_text(header + body, encoding=\"utf-8\")",
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tests.verify_load_waveforms_feature",
        "description": "tests.verify_load_waveforms_feature",
        "peekOfCode": "def main():\n    print(\"\\n\" + \"=\" * 70)\n    print(\"‚úÖ ÂÜÖÂ≠ò‰ºòÂåñÂäüËÉΩÈ™åËØÅ\")\n    print(\"=\" * 70)\n    # ÊµãËØï 1: ÂèÇÊï∞ÂèØÁî®ÊÄß\n    print(\"\\nüìå ÊµãËØï 1: load_waveforms ÂèÇÊï∞ÂèØÁî®ÊÄß\")\n    print(\"-\" * 70)\n    try:\n        ds_false = WaveformDataset(char=\"50V_OV_circulation_20thr\", load_waveforms=False)\n        print(f\"‚úÖ load_waveforms=False: {ds_false.load_waveforms}\")",
        "detail": "tests.verify_load_waveforms_feature",
        "documentation": {}
    },
    {
        "label": "Context",
        "kind": 6,
        "importPath": "waveform_analysis.core.cache",
        "description": "waveform_analysis.core.cache",
        "peekOfCode": "class Context(CacheMixin, PluginMixin):\n    \"\"\"\n    The Context orchestrates plugins and manages data storage/caching.\n    Inspired by strax, it is the main entry point for data analysis.\n    \"\"\"\n    def __init__(\n        self,\n        storage_dir: str = \"./strax_data\",\n        config: Optional[Dict[str, Any]] = None,\n        storage: Optional[Any] = None,",
        "detail": "waveform_analysis.core.cache",
        "documentation": {}
    },
    {
        "label": "MemmapStorage",
        "kind": 6,
        "importPath": "waveform_analysis.core.context",
        "description": "waveform_analysis.core.context",
        "peekOfCode": "class MemmapStorage:\n    \"\"\"\n    Handles persistence of structured numpy data using binary files and memmap.\n    \"\"\"\n    STORAGE_VERSION = \"1.0.0\"\n    def __init__(self, base_dir: str, profiler: Optional[Any] = None):\n        self.base_dir = base_dir\n        self.profiler = profiler\n        if not os.path.exists(base_dir):\n            os.makedirs(base_dir, exist_ok=True)",
        "detail": "waveform_analysis.core.context",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "kind": 6,
        "importPath": "waveform_analysis.core.dataset",
        "description": "waveform_analysis.core.dataset",
        "peekOfCode": "class WaveformDataset(Context, StepMixin):\n    \"\"\"\n    Áªü‰∏ÄÁöÑÊ≥¢ÂΩ¢Êï∞ÊçÆÈõÜÂÆπÂô®ÔºåÂ∞ÅË£ÖÊï¥‰∏™Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã„ÄÇ\n    Áé∞Âú®Âü∫‰∫é Context ÊûÑÂª∫ÔºåÂà©Áî®Êèí‰ª∂ÂåñÊû∂ÊûÑ„ÄÇ\n    \"\"\"\n    def __init__(\n        self,\n        char: str = \"50V_OV_circulation_20thr\",\n        n_channels: int = 2,\n        start_channel_slice: int = 6,",
        "detail": "waveform_analysis.core.dataset",
        "documentation": {}
    },
    {
        "label": "CacheMixin",
        "kind": 6,
        "importPath": "waveform_analysis.core.mixins",
        "description": "waveform_analysis.core.mixins",
        "peekOfCode": "class CacheMixin:\n    \"\"\"Mixin for handling memory and disk caching in WaveformDataset.\"\"\"\n    def __init__(self):\n        # _cache: { step_name: {attr_name: value, ...} }\n        self._cache: Dict[str, Dict[str, object]] = {}\n        # _cache_config: { step_name: {enabled: bool, attrs: [str], persist_path: Optional[str]} }\n        self._cache_config: Dict[str, Dict[str, object]] = {}\n        self.cache_dir: Optional[str] = None\n    def set_step_cache(\n        self,",
        "detail": "waveform_analysis.core.mixins",
        "documentation": {}
    },
    {
        "label": "StepMixin",
        "kind": 6,
        "importPath": "waveform_analysis.core.mixins",
        "description": "waveform_analysis.core.mixins",
        "peekOfCode": "class StepMixin:\n    \"\"\"Mixin for chainable step management and error tracking.\"\"\"\n    chainable_step = staticmethod(chainable_step)\n    def __init__(self):\n        self._step_errors: Dict[str, str] = {}\n        self._step_status: Dict[str, str] = {}\n        self._last_failed_step: Optional[str] = None\n        self.raise_on_error: bool = False\n    def _record_step_success(self, name: str) -> None:\n        self._step_status[name] = \"success\"",
        "detail": "waveform_analysis.core.mixins",
        "documentation": {}
    },
    {
        "label": "PluginMixin",
        "kind": 6,
        "importPath": "waveform_analysis.core.mixins",
        "description": "waveform_analysis.core.mixins",
        "peekOfCode": "class PluginMixin:\n    \"\"\"Mixin for orchestrating plugins in WaveformDataset.\"\"\"\n    def __init__(self):\n        self._plugins: Dict[str, Any] = {}\n    def register_plugin(self, plugin: Any, allow_override: bool = False) -> None:\n        \"\"\"\n        Register a plugin instance with strict validation.\n        \"\"\"\n        # 1. Basic validation\n        if hasattr(plugin, \"validate\"):",
        "detail": "waveform_analysis.core.mixins",
        "documentation": {}
    },
    {
        "label": "chainable_step",
        "kind": 2,
        "importPath": "waveform_analysis.core.mixins",
        "description": "waveform_analysis.core.mixins",
        "peekOfCode": "def chainable_step(fn: Callable):\n    \"\"\"Decorator for chainable steps with integrated caching and error handling.\"\"\"\n    @functools.wraps(fn)\n    def wrapper(self, *args, **kwargs):\n        name = fn.__name__\n        cfg: Dict[str, Any] = {}\n        # ÊâìÂç∞ÂΩìÂâçÊ≠•È™§\n        verbose = kwargs.get(\"verbose\", True)\n        run_id = kwargs.get(\"run_id\") or getattr(self, \"char\", \"default\")\n        # È¶ñÊ¨°ËøêË°åÊâìÂç∞ÂÆåÊï¥Êä•Âëä",
        "detail": "waveform_analysis.core.mixins",
        "documentation": {}
    },
    {
        "label": "PortModel",
        "kind": 6,
        "importPath": "waveform_analysis.core.model",
        "description": "waveform_analysis.core.model",
        "peekOfCode": "class PortModel:\n    id: str\n    name: str\n    kind: str  # 'in' or 'out'\n    dtype: str\n    parent_node_id: str\n    index: int\n@dataclass\nclass NodeModel:\n    id: str",
        "detail": "waveform_analysis.core.model",
        "documentation": {}
    },
    {
        "label": "NodeModel",
        "kind": 6,
        "importPath": "waveform_analysis.core.model",
        "description": "waveform_analysis.core.model",
        "peekOfCode": "class NodeModel:\n    id: str\n    key: str\n    title: str\n    plugin_class: str\n    description: str = \"\"\n    config: Dict[str, Any] = field(default_factory=dict)\n    in_ports: List[PortModel] = field(default_factory=list)\n    out_ports: List[PortModel] = field(default_factory=list)\n    depth: int = 0",
        "detail": "waveform_analysis.core.model",
        "documentation": {}
    },
    {
        "label": "EdgeModel",
        "kind": 6,
        "importPath": "waveform_analysis.core.model",
        "description": "waveform_analysis.core.model",
        "peekOfCode": "class EdgeModel:\n    source_node_id: str\n    source_port_id: str\n    target_node_id: str\n    target_port_id: str\n    dtype: str = \"unknown\"\n@dataclass\nclass LineageGraphModel:\n    nodes: Dict[str, NodeModel] = field(default_factory=dict)\n    edges: List[EdgeModel] = field(default_factory=list)",
        "detail": "waveform_analysis.core.model",
        "documentation": {}
    },
    {
        "label": "LineageGraphModel",
        "kind": 6,
        "importPath": "waveform_analysis.core.model",
        "description": "waveform_analysis.core.model",
        "peekOfCode": "class LineageGraphModel:\n    nodes: Dict[str, NodeModel] = field(default_factory=dict)\n    edges: List[EdgeModel] = field(default_factory=list)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    def to_mermaid(self) -> str:\n        \"\"\"\n        Â∞ÜÊ®°ÂûãËΩ¨Êç¢‰∏∫ Mermaid.js ÊµÅÁ®ãÂõæÂ≠óÁ¨¶‰∏≤„ÄÇ\n        \"\"\"\n        lines = [\"graph LR\"]\n        # 1. ÂÆö‰πâËäÇÁÇπ",
        "detail": "waveform_analysis.core.model",
        "documentation": {}
    },
    {
        "label": "build_lineage_graph",
        "kind": 2,
        "importPath": "waveform_analysis.core.model",
        "description": "waveform_analysis.core.model",
        "peekOfCode": "def build_lineage_graph(\n    lineage: Dict[str, Any],\n    target_name: str,\n    plugins: Optional[Dict[str, Any]] = None,\n) -> LineageGraphModel:\n    \"\"\"\n    Â∞ÜË°ÄÁºòÂ≠óÂÖ∏ËΩ¨Êç¢‰∏∫Á∫ØÊï∞ÊçÆÁªìÊûÑÁöÑ LineageGraphModel„ÄÇ\n    \"\"\"\n    from waveform_analysis.core.utils import get_plugin_dtype, get_plugin_title\n    model = LineageGraphModel()",
        "detail": "waveform_analysis.core.model",
        "documentation": {}
    },
    {
        "label": "Option",
        "kind": 6,
        "importPath": "waveform_analysis.core.plugins",
        "description": "waveform_analysis.core.plugins",
        "peekOfCode": "class Option:\n    \"\"\"\n    A configuration option for a plugin.\n    \"\"\"\n    def __init__(\n        self,\n        default: Any = None,\n        type: Optional[Union[Type, tuple]] = None,\n        help: str = \"\",\n        validate: Optional[callable] = None,",
        "detail": "waveform_analysis.core.plugins",
        "documentation": {}
    },
    {
        "label": "Plugin",
        "kind": 6,
        "importPath": "waveform_analysis.core.plugins",
        "description": "waveform_analysis.core.plugins",
        "peekOfCode": "class Plugin(abc.ABC):\n    \"\"\"\n    Base class for all processing plugins.\n    Inspired by strax, each plugin defines what it provides and what it depends on.\n    \"\"\"\n    provides: str = \"\"\n    depends_on: List[str] = []\n    options: Dict[str, Option] = {}\n    save_when: str = \"never\"\n    dtype: Optional[np.dtype] = None  # Legacy, use output_dtype for new plugins",
        "detail": "waveform_analysis.core.plugins",
        "documentation": {}
    },
    {
        "label": "RawFilesPlugin",
        "kind": 6,
        "importPath": "waveform_analysis.core.standard_plugins",
        "description": "waveform_analysis.core.standard_plugins",
        "peekOfCode": "class RawFilesPlugin(Plugin):\n    \"\"\"Plugin to find raw CSV files.\"\"\"\n    provides = \"raw_files\"\n    description = \"Scan the data directory and group raw CSV files by channel number.\"\n    options = {\n        \"n_channels\": Option(default=2, type=int, help=\"Number of channels to load\"),\n        \"start_channel_slice\": Option(default=6, type=int, help=\"Starting channel index\"),\n        \"data_root\": Option(default=\"DAQ\", type=str, help=\"Root directory for data\"),\n    }\n    def compute(self, context: Any, run_id: str, **kwargs) -> List[List[str]]:",
        "detail": "waveform_analysis.core.standard_plugins",
        "documentation": {}
    },
    {
        "label": "WaveformsPlugin",
        "kind": 6,
        "importPath": "waveform_analysis.core.standard_plugins",
        "description": "waveform_analysis.core.standard_plugins",
        "peekOfCode": "class WaveformsPlugin(Plugin):\n    \"\"\"Plugin to extract waveforms from raw files.\"\"\"\n    provides = \"waveforms\"\n    depends_on = [\"raw_files\"]\n    description = \"Read and parse waveform data from raw CSV files.\"\n    options = {\n        \"start_channel_slice\": Option(default=6, type=int),\n        \"n_channels\": Option(default=2, type=int),\n    }\n    def compute(self, context: Any, run_id: str, **kwargs) -> List[np.ndarray]:",
        "detail": "waveform_analysis.core.standard_plugins",
        "documentation": {}
    },
    {
        "label": "StWaveformsPlugin",
        "kind": 6,
        "importPath": "waveform_analysis.core.standard_plugins",
        "description": "waveform_analysis.core.standard_plugins",
        "peekOfCode": "class StWaveformsPlugin(Plugin):\n    \"\"\"Plugin to structure waveforms into NumPy arrays.\"\"\"\n    provides = \"st_waveforms\"\n    depends_on = [\"waveforms\"]\n    output_dtype = np.dtype(RECORD_DTYPE)\n    def compute(self, context: Any, run_id: str, **kwargs) -> List[np.ndarray]:\n        from waveform_analysis.utils.data_processing.processor import WaveformStruct\n        waveforms = context.get_data(run_id, \"waveforms\")\n        waveform_struct = WaveformStruct(waveforms)\n        st_waveforms = waveform_struct.structrue_waveforms(show_progress=context.config.get(\"show_progress\", True))",
        "detail": "waveform_analysis.core.standard_plugins",
        "documentation": {}
    },
    {
        "label": "HitFinderPlugin",
        "kind": 6,
        "importPath": "waveform_analysis.core.standard_plugins",
        "description": "waveform_analysis.core.standard_plugins",
        "peekOfCode": "class HitFinderPlugin(Plugin):\n    \"\"\"Example implementation of the HitFinder as a plugin.\"\"\"\n    provides = \"hits\"\n    depends_on = [\"st_waveforms\", \"event_len\"]\n    input_dtype = {\"st_waveforms\": np.dtype(RECORD_DTYPE)}\n    output_dtype = np.dtype(PEAK_DTYPE)\n    def compute(self, context: Any, run_id: str, threshold: float = 10.0, **kwargs) -> List[np.ndarray]:\n        from waveform_analysis.utils.data_processing.processor import find_hits\n        st_waveforms = context.get_data(run_id, \"st_waveforms\")\n        event_len = context.get_data(run_id, \"event_len\")",
        "detail": "waveform_analysis.core.standard_plugins",
        "documentation": {}
    },
    {
        "label": "MemmapStorage",
        "kind": 6,
        "importPath": "waveform_analysis.core.storage",
        "description": "waveform_analysis.core.storage",
        "peekOfCode": "class MemmapStorage:\n    \"\"\"\n    Handles persistence of structured numpy data using binary files and memmap.\n    \"\"\"\n    STORAGE_VERSION = \"1.0.0\"\n    def __init__(self, base_dir: str, profiler: Optional[Any] = None):\n        self.base_dir = base_dir\n        self.profiler = profiler\n        if not os.path.exists(base_dir):\n            os.makedirs(base_dir, exist_ok=True)",
        "detail": "waveform_analysis.core.storage",
        "documentation": {}
    },
    {
        "label": "Profiler",
        "kind": 6,
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "peekOfCode": "class Profiler:\n    \"\"\"\n    Lightweight profiler to track execution time of different components.\n    \"\"\"\n    def __init__(self):\n        self.durations = defaultdict(float)\n        self.counts = defaultdict(int)\n    @contextlib.contextmanager\n    def timeit(self, key: str):\n        start = time.perf_counter()",
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "LineageStyle",
        "kind": 6,
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "peekOfCode": "class LineageStyle:\n    \"\"\"Ê†∑ÂºèÈÖçÁΩÆÔºå‰æõÂèØËßÜÂåñ‰∏éÂÖ∂ÂÆÉÂ∑•ÂÖ∑ÂÖ±‰∫´„ÄÇ\"\"\"\n    node_width: float = 3.2\n    node_height: float = 2.0\n    header_height: float = 0.35\n    port_size: float = 0.12\n    x_gap: float = 4.5\n    y_gap: float = 2.8\n    node_bg: str = \"#f5f6fa\"\n    node_edge: str = \"#2f3640\"",
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "OneTimeGenerator",
        "kind": 6,
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "peekOfCode": "class OneTimeGenerator:\n    \"\"\"\n    A wrapper for generators that ensures they are only consumed once.\n    Raises RuntimeError if __iter__ is called more than once.\n    \"\"\"\n    def __init__(self, generator, name=\"Generator\"):\n        self.generator = generator\n        self.name = name\n        self.consumed = False\n    def __iter__(self):",
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "get_plugins_from_context",
        "kind": 2,
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "peekOfCode": "def get_plugins_from_context(ctx: Any) -> Dict[str, Any]:\n    if ctx is None:\n        return {}\n    return getattr(ctx, \"_plugins\", getattr(ctx, \"plugins\", {}))\ndef get_plugin_dtype(name: str, plugins: Dict[str, Any]) -> str:\n    if name == \"raw_files\":\n        return \"List[List[str]]\"\n    if name == \"waveforms\":\n        return \"List[np.ndarray]\"\n    plugin = plugins.get(name)",
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "get_plugin_dtype",
        "kind": 2,
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "peekOfCode": "def get_plugin_dtype(name: str, plugins: Dict[str, Any]) -> str:\n    if name == \"raw_files\":\n        return \"List[List[str]]\"\n    if name == \"waveforms\":\n        return \"List[np.ndarray]\"\n    plugin = plugins.get(name)\n    if plugin:\n        for attr in (\"dtype\", \"output_dtype\", \"DTYPE\"):\n            val = getattr(plugin, attr, None)\n            if val:",
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "get_plugin_title",
        "kind": 2,
        "importPath": "waveform_analysis.core.utils",
        "description": "waveform_analysis.core.utils",
        "peekOfCode": "def get_plugin_title(name: str, info: Dict[str, Any], plugins: Dict[str, Any]) -> str:\n    plugin = plugins.get(name)\n    if plugin:\n        for attr in (\"name\", \"plugin_name\", \"display_name\"):\n            val = getattr(plugin, attr, None)\n            if val:\n                return str(val)\n        return plugin.__class__.__name__\n    return str(info.get(\"plugin_class\", name))",
        "detail": "waveform_analysis.core.utils",
        "documentation": {}
    },
    {
        "label": "LandauGaussFitter",
        "kind": 6,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "class LandauGaussFitter(BaseFitter):\n    def __init__(self, x, y, fit_range, param):\n        super().__init__(x, y, fit_range, param)\n        self.mpv = param[0]\n        self.eta = param[1]\n        self.sigma = param[2]\n        self.const = param[3]\n        self.mu2 = param[4] if len(param) > 4 else 400\n        self.sigma2 = param[5] if len(param) > 5 else 80\n        self.A2 = param[6] if len(param) > 6 else 1e5",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "LandauGaussFitter2",
        "kind": 6,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "class LandauGaussFitter2(BaseFitter):\n    def __init__(self, x, y, fit_range, param):\n        super().__init__(x, y, fit_range, param)\n        self.mpv = param[0]\n    def fit_func(self, x, mpv, eta, sigma, const):\n        \"\"\"\n        Landau-Gauss ÂàÜÂ∏ÉÁöÑÂÖ∑‰ΩìÂÆûÁé∞\n        \"\"\"\n        xi = (x - mpv) / eta\n        landau_part = np.exp(-0.5 * (xi + np.exp(-xi))) / eta",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "gauss",
        "kind": 2,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "def gauss(x, mu, sigma, amp=1.0):\n    \"\"\"\n    È´òÊñØÂàÜÂ∏ÉÔºàÂΩí‰∏ÄÂåñÂΩ¢Âºè‰πò‰ª•ÊåØÂπÖÔºâ\n    ËøîÂõû amp * N(mu, sigma)(x)\n    \"\"\"\n    return amp * np.exp(-0.5 * ((x - mu) / sigma) ** 2) / (sigma * np.sqrt(2 * np.pi))\ndef landau_pdf_approx(x, mpv, eta):\n    \"\"\"\n    Landau PDF Ëøë‰ººÔºà‰∏ç‰æùËµñ ROOTÔºâ\n    Âü∫‰∫é ROOT ÁöÑÊ†áÂáÜÂèÇÊï∞ÂåñÔºöL(x; mpv, eta)",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "landau_pdf_approx",
        "kind": 2,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "def landau_pdf_approx(x, mpv, eta):\n    \"\"\"\n    Landau PDF Ëøë‰ººÔºà‰∏ç‰æùËµñ ROOTÔºâ\n    Âü∫‰∫é ROOT ÁöÑÊ†áÂáÜÂèÇÊï∞ÂåñÔºöL(x; mpv, eta)\n    ‰ΩøÁî®Â∏∏ËßÅÁöÑÊï∞ÂÄºÈÄºËøë\n    \"\"\"\n    y = (x - mpv) / eta\n    # Ê†áÂáÜ Landau PDFÔºöexp(-0.5*(y + exp(-y)))  / eta\n    return jnp.exp(-0.5 * (y + jnp.exp(-y))) / eta\ndef landau_gauss_jax(x, mpv, eta, sigma, n_steps=100):",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "landau_gauss_jax",
        "kind": 2,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "def landau_gauss_jax(x, mpv, eta, sigma, n_steps=100):\n    \"\"\"\n    Áî® JAX ÂÆûÁé∞ÁöÑ Landau ‚äó Gaussian Âç∑ÁßØÔºà‰øÆÂ§çÁâàÔºâ\n    ÂèÇÊï∞Ôºö\n        x       : arrayÔºåÊ±ÇÂÄºÁÇπ (1D)\n        mpv     : Landau ÁöÑÊúÄÂèØËÉΩÂÄº (Ê†áÈáè)\n        eta     : Landau ÂÆΩÂ∫¶ÂèÇÊï∞ (Ê†áÈáè)\n        sigma   : È´òÊñØÂÆΩÂ∫¶ (Ê†áÈáè)\n        n_steps : ÁßØÂàÜÊ≠•Êï∞ (Ê†áÈáè)\n    ËøîÂõûÔºö",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "kind": 6,
        "importPath": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "description": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "peekOfCode": "class DAQAnalyzer:\n    \"\"\"DAQ Êï∞ÊçÆÂàÜÊûêÂô®ÔºöÁÆ°ÁêÜÊâÄÊúâËøêË°åÁöÑÁªü‰∏ÄÂàÜÊûêÔºàÊòæÁ§∫/‰øùÂ≠òÁ≠âÔºâ„ÄÇ\"\"\"\n    def __init__(self, daq_root: str | Path = \"DAQ\") -> None:\n        self.daq_root = str(daq_root)\n        self.runs: Dict[str, DAQRun] = {}\n        self.df_runs: Optional[pd.DataFrame] = None\n        self.total_bytes = 0\n    @staticmethod\n    def format_size(bytes_val: int) -> str:\n        for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:",
        "detail": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "description": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nfrom .daq_run import DAQRun\nclass DAQAnalyzer:\n    \"\"\"DAQ Êï∞ÊçÆÂàÜÊûêÂô®ÔºöÁÆ°ÁêÜÊâÄÊúâËøêË°åÁöÑÁªü‰∏ÄÂàÜÊûêÔºàÊòæÁ§∫/‰øùÂ≠òÁ≠âÔºâ„ÄÇ\"\"\"\n    def __init__(self, daq_root: str | Path = \"DAQ\") -> None:\n        self.daq_root = str(daq_root)\n        self.runs: Dict[str, DAQRun] = {}\n        self.df_runs: Optional[pd.DataFrame] = None\n        self.total_bytes = 0\n    @staticmethod",
        "detail": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "description": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "peekOfCode": "__all__ = [\"DAQAnalyzer\"]",
        "detail": "waveform_analysis.utils.daq.__pycache__.daq_analyzer",
        "documentation": {}
    },
    {
        "label": "_DAQRunAdapter",
        "kind": 6,
        "importPath": "waveform_analysis.utils.daq.daq",
        "description": "waveform_analysis.utils.daq.daq",
        "peekOfCode": "class _DAQRunAdapter:\n    \"\"\"Lightweight adapter exposing a stable minimal DAQRun protocol:\n    - get_channel_paths(n_channels) -> List[List[str]]\n    - channel_files -> dict mapping ch -> list(entries)\n    This adapter wraps objects that either already implement the method,\n    or provide a `channel_files` attribute, or are plain dict mappings.\n    \"\"\"\n    def __init__(self, src: Any):\n        self._src = src\n    def get_channel_paths(self, n_channels: int):",
        "detail": "waveform_analysis.utils.daq.daq",
        "documentation": {}
    },
    {
        "label": "adapt_daq_run",
        "kind": 2,
        "importPath": "waveform_analysis.utils.daq.daq",
        "description": "waveform_analysis.utils.daq.daq",
        "peekOfCode": "def adapt_daq_run(obj: Any):\n    \"\"\"Return an adapter providing `get_channel_paths(n_channels)` for obj.\n    Use this in loader/dataset to normalize inputs from different DAQ tooling.\n    \"\"\"\n    return _DAQRunAdapter(obj)\n__all__ = [\"DAQRun\", \"DAQAnalyzer\"]",
        "detail": "waveform_analysis.utils.daq.daq",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "waveform_analysis.utils.daq.daq",
        "description": "waveform_analysis.utils.daq.daq",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass _DAQRunAdapter:\n    \"\"\"Lightweight adapter exposing a stable minimal DAQRun protocol:\n    - get_channel_paths(n_channels) -> List[List[str]]\n    - channel_files -> dict mapping ch -> list(entries)\n    This adapter wraps objects that either already implement the method,\n    or provide a `channel_files` attribute, or are plain dict mappings.\n    \"\"\"\n    def __init__(self, src: Any):\n        self._src = src",
        "detail": "waveform_analysis.utils.daq.daq",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "waveform_analysis.utils.daq.daq",
        "description": "waveform_analysis.utils.daq.daq",
        "peekOfCode": "__all__ = [\"DAQRun\", \"DAQAnalyzer\"]",
        "detail": "waveform_analysis.utils.daq.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "kind": 6,
        "importPath": "waveform_analysis.utils.daq.daq_analyzer",
        "description": "waveform_analysis.utils.daq.daq_analyzer",
        "peekOfCode": "class DAQAnalyzer:\n    \"\"\"DAQ Êï∞ÊçÆÂàÜÊûêÂô®ÔºöÁÆ°ÁêÜÊâÄÊúâËøêË°åÁöÑÁªü‰∏ÄÂàÜÊûêÔºàÊòæÁ§∫/‰øùÂ≠òÁ≠âÔºâ„ÄÇ\"\"\"\n    def __init__(self, daq_root: str | Path = \"DAQ\") -> None:\n        self.daq_root = str(daq_root)\n        self.runs: Dict[str, DAQRun] = {}\n        self.df_runs: Optional[pd.DataFrame] = None\n        self.total_bytes = 0\n    @staticmethod\n    def format_size(bytes_val: int) -> str:\n        for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:",
        "detail": "waveform_analysis.utils.daq.daq_analyzer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "waveform_analysis.utils.daq.daq_analyzer",
        "description": "waveform_analysis.utils.daq.daq_analyzer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nfrom .daq_run import DAQRun\nclass DAQAnalyzer:\n    \"\"\"DAQ Êï∞ÊçÆÂàÜÊûêÂô®ÔºöÁÆ°ÁêÜÊâÄÊúâËøêË°åÁöÑÁªü‰∏ÄÂàÜÊûêÔºàÊòæÁ§∫/‰øùÂ≠òÁ≠âÔºâ„ÄÇ\"\"\"\n    def __init__(self, daq_root: str | Path = \"DAQ\") -> None:\n        self.daq_root = str(daq_root)\n        self.runs: Dict[str, DAQRun] = {}\n        self.df_runs: Optional[pd.DataFrame] = None\n        self.total_bytes = 0\n    @staticmethod",
        "detail": "waveform_analysis.utils.daq.daq_analyzer",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "waveform_analysis.utils.daq.daq_analyzer",
        "description": "waveform_analysis.utils.daq.daq_analyzer",
        "peekOfCode": "__all__ = [\"DAQAnalyzer\"]",
        "detail": "waveform_analysis.utils.daq.daq_analyzer",
        "documentation": {}
    },
    {
        "label": "Context",
        "kind": 6,
        "importPath": "waveform_analysis.utils.daq.daq_run",
        "description": "waveform_analysis.utils.daq.daq_run",
        "peekOfCode": "class Context(CacheMixin, PluginMixin):\n    \"\"\"\n    The Context orchestrates plugins and manages data storage/caching.\n    Inspired by strax, it is the main entry point for data analysis.\n    \"\"\"\n    def __init__(\n        self,\n        storage_dir: str = \"./strax_data\",\n        config: Optional[Dict[str, Any]] = None,\n        storage: Optional[Any] = None,",
        "detail": "waveform_analysis.utils.daq.daq_run",
        "documentation": {}
    },
    {
        "label": "parse_files_generator",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.io",
        "description": "waveform_analysis.utils.data_processing.io",
        "peekOfCode": "def parse_files_generator(\n    file_paths: List[str],\n    skiprows: int = 2,\n    delimiter: str = \";\",\n    chunksize: int = 1000,\n    show_progress: bool = False,\n) -> Iterator[np.ndarray]:\n    \"\"\"\n    Yields chunks of parsed waveform data from a list of files.\n    \"\"\"",
        "detail": "waveform_analysis.utils.data_processing.io",
        "documentation": {}
    },
    {
        "label": "parse_and_stack_files",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.io",
        "description": "waveform_analysis.utils.data_processing.io",
        "peekOfCode": "def parse_and_stack_files(\n    file_paths: List[str],\n    skiprows: int = 2,\n    delimiter: str = \";\",\n    chunksize: int | None = None,\n    n_jobs: int = 1,\n    use_process_pool: bool = False,\n    show_progress: bool = False,\n) -> np.ndarray:\n    \"\"\"Parse a list of CSV files and return a single vstacked numpy array.",
        "detail": "waveform_analysis.utils.data_processing.io",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "waveform_analysis.utils.data_processing.io",
        "description": "waveform_analysis.utils.data_processing.io",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef parse_files_generator(\n    file_paths: List[str],\n    skiprows: int = 2,\n    delimiter: str = \";\",\n    chunksize: int = 1000,\n    show_progress: bool = False,\n) -> Iterator[np.ndarray]:\n    \"\"\"\n    Yields chunks of parsed waveform data from a list of files.",
        "detail": "waveform_analysis.utils.data_processing.io",
        "documentation": {}
    },
    {
        "label": "RawFileLoader",
        "kind": 6,
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "peekOfCode": "class RawFileLoader:\n    \"\"\"Efficient loader for DAQ waveform files with channel-aware grouping.\"\"\"\n    # **È¢ÑÁºñËØëÊ≠£Âàô**ÂáèÂ∞ëÈáçÂ§ç cost\n    _ch_re = re.compile(r\"CH(\\d+)\")\n    _idx_re = re.compile(r\"_(\\d+)\\.CSV$\", re.IGNORECASE)\n    def __init__(self, n_channels: int = 6, char: str = \"All_SelfTrigger\", data_root: str = \"DAQ\"):\n        self.base_dir = Path(data_root) / char / \"RAW\"\n        self.n_channels = n_channels\n        self.pattern = \"*CH*.CSV\"\n    def _extract(self, filename: str) -> Optional[tuple[int, int]]:",
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "get_raw_files",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "peekOfCode": "def get_raw_files(n_channels=6, char=\"All_SelfTrigger\", daq_run=None, data_root=\"DAQ\"):\n    \"\"\"ËøîÂõûÊØè‰∏™ÈÄöÈÅìÁöÑÊñá‰ª∂ÂàóË°®„ÄÇ\n    ÂèÇÊï∞:\n        n_channels: ÈÄöÈÅìÊï∞\n        char: ËøêË°åÊ†áËØÜÔºàÁî®‰∫éÊåâÂéüÂßãË∑ØÂæÑÂåπÈÖçÔºâ\n        daq_run: ÂèØÈÄâÁöÑ `DAQRun` ÂØπË±°ÔºàÊù•Ëá™ `waveform_analysis.utils.daq`ÔºâÔºå\n                 Ëã•Êèê‰æõÂàôÁî®ÂÖ∂Êñá‰ª∂ÂàóË°®Êõø‰ª£Âü∫‰∫éÊñá‰ª∂Á≥ªÁªüÁöÑÊâ´Êèè„ÄÇ\n        data_root: Êï∞ÊçÆÊ†πÁõÆÂΩï\n    \"\"\"\n    if daq_run is not None:",
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "get_waveforms_generator",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "peekOfCode": "def get_waveforms_generator(\n    raw_filess: Optional[List[List[str]]] = None,\n    daq_run=None,\n    n_channels: int = 6,\n    chunksize: int = 1000,\n    show_progress: bool = False,\n):\n    \"\"\"\n    Yields synchronized chunks of waveforms for all channels.\n    Returns a generator of tuples/lists, where each element is a list of numpy arrays (one per channel).",
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "get_waveforms",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "peekOfCode": "def get_waveforms(\n    raw_filess: Optional[List[List[str]]] = None,\n    daq_run=None,\n    n_channels: int = 6,\n    show_progress: bool = False,\n):\n    \"\"\"Â∞ÜÊâÄÊúâ CSV Âä†ËΩΩÂπ∂ÊãºÊé•Êàê numpy Êï∞ÁªÑÔºàfast modeÔºâ„ÄÇ\n    ÂèÇÊï∞:\n        raw_filess: ÂèØÈÄâÁöÑÊØèÈÄöÈÅìÊñá‰ª∂Ë∑ØÂæÑÂàóË°®\n        daq_run: ÂèØÈÄâÁöÑ DAQRun ÁªìÊûúÔºàÂØπË±°Êàñ dictÔºâÔºå‰ºòÂÖàÁî®‰∫éÊûÑÂª∫Êñá‰ª∂ÂàóË°®",
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "build_filetime_index",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "peekOfCode": "def build_filetime_index(raw_filess):\n    \"\"\"Âª∫Á´ãÂü∫‰∫éÊñá‰ª∂ mtime ÁöÑÂø´ÈÄüÊü•ÊâæË°®„ÄÇ\"\"\"\n    indexed = []\n    for ch_files in raw_filess:\n        if not ch_files:\n            indexed.append([])\n            continue\n        times = [(os.path.getmtime(f), f) for f in ch_files]\n        times.sort()\n        indexed.append(times)",
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "get_files_by_filetime",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "peekOfCode": "def get_files_by_filetime(indexed_table, t_query_mtime):\n    \"\"\"\n    ‰ΩøÁî®‰∫åÂàÜÊü•ÊâæÔºàbisectÔºâÔºåÊâæÂà∞ÊúÄÊé•ËøëÁöÑÊó∂Èó¥Êñá‰ª∂ÔºåÊØîÂéüÂÆûÁé∞Êõ¥Âø´„ÄÇ\n    \"\"\"\n    result = {}\n    for ch, entries in enumerate(indexed_table):\n        if not entries:\n            continue\n        timestamps = [t for t, _ in entries]\n        pos = bisect.bisect_left(timestamps, t_query_mtime)",
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "get_files_before",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.loader",
        "description": "waveform_analysis.utils.data_processing.loader",
        "peekOfCode": "def get_files_before(raw_filess, files_by_time):\n    sel_raw_filess = []\n    for channel_idx, channel_files in enumerate(raw_filess):\n        target_fp = files_by_time.get(channel_idx)\n        if not target_fp:\n            sel_raw_filess.append([])\n            continue\n        if target_fp in channel_files:\n            matched_pos = channel_files.index(target_fp)\n            sel_raw_filess.append(channel_files[: matched_pos + 1])",
        "detail": "waveform_analysis.utils.data_processing.loader",
        "documentation": {}
    },
    {
        "label": "Datas",
        "kind": 6,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "class Datas:\n    def __init__(self, cache_dir) -> None:\n        self.cache_dir = cache_dir\n        df_file = os.path.join(cache_dir, \"df.feather\")\n        event_file = os.path.join(cache_dir, \"df_events.feather\")\n        self.df = pd.read_feather(df_file)\n        self.df_events = pd.read_feather(event_file)\ndef hist_count_ratio(data_a, data_b, bins):\n    counts_a, bin_edges = np.histogram(data_a, bins=bins)\n    counts_b, _ = np.histogram(data_b, bins=bins)",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "find_hits",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def find_hits(\n    waves: np.ndarray,\n    baselines: np.ndarray,\n    threshold: float,\n    left_extension: int = 2,\n    right_extension: int = 2,\n) -> np.ndarray:\n    \"\"\"\n    Vectorized hit-finding. Finds contiguous regions where (baseline - wave) > threshold.\n    Args:",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "build_waveform_df",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def build_waveform_df(\n    st_waveforms,\n    peaks,\n    charges,\n    event_len,\n    n_channels=6,\n    peak_max_min=None,\n    peak_baseline=None,\n):\n    \"\"\"ÊääÊØè‰∏™ÈÄöÈÅìÁöÑ timestamp / charge / peak / channel ÊãºÊàê‰∏Ä‰∏™ DataFrame„ÄÇ",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "group_multi_channel_hits",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def group_multi_channel_hits(df, time_window_ns, show_progress: bool = False):\n    \"\"\"\n    Âú® df ‰∏≠Êåâ timestamp ËÅöÁ±ªÔºåÊâæ‚ÄúÂêå‰∏Ä‰∫ã‰ª∂ÁöÑÂ§öÈÄöÈÅìËß¶Âèë‚ÄùÔºåÂπ∂Âú®Á∞áÂÜÖÈÉ®\n    Êåâ channel ‰ªéÂ∞èÂà∞Â§ßÂØπ (channels, charges, peaks, timestamps) ÂêåÊ≠•ÊéíÂ∫è„ÄÇ\n    \"\"\"\n    time_window_ps = time_window_ns * 1e3\n    # ÂÖàÊåâÊó∂Èó¥ÊéíÂ∫è‰∏ÄÊ¨°\n    df_sorted = df.sort_values(\"timestamp\").reset_index(drop=True)\n    # ‰∏ÄÊ¨°ÊÄßÂèñÊàê numpy Êï∞ÁªÑÔºåÂêéÈù¢Âæ™ÁéØÂè™Â§ÑÁêÜÁ¥¢ÂºïÔºåÂ∞ëÂÅö iloc / array ÊûÑÈÄ†\n    ts_all = df_sorted[\"timestamp\"].to_numpy()",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "encode_groups_binary",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def encode_groups_binary(channels):\n    \"\"\"\n    ‰ªªÊÑèÁªÑÂá∫Áé∞‰∫ÜÈÉ®ÂàÜÊàêÂëòÔºà‰∏çÊàêÂØπÔºâ -> Êï¥‰ΩìËøîÂõû 0ÔºàÂºÇÂ∏∏Ôºâ\n    ÊâÄÊúâÁªÑË¶Å‰πàÂÆåÊï¥Âá∫Áé∞ÔºåË¶Å‰πàÂÆåÂÖ®‰∏çÂá∫Áé∞„ÄÇ\n    \"\"\"\n    if channels is None or len(channels) == 0:\n        return 0\n    ch_set = set(map(int, channels))\n    code = 0\n    for weight, group_members in GROUP_WEIGHTS.items():",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "encode_channels_binary",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def encode_channels_binary(channels):\n    \"\"\"\n    Â∞Ü channel ÂàóË°®ËΩ¨Êç¢‰∏∫‰∫åËøõÂà∂‰ΩçÊé©Á†Å„ÄÇ\n    ‰æãÂ¶Ç [0,3,5] ‚Üí 1<<0 | 1<<3 | 1<<5 = 41\n    \"\"\"\n    if not channels:\n        return 0\n    mask = 0\n    for ch in channels:\n        mask |= 1 << int(ch)",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "mask_to_channels",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def mask_to_channels(mask):\n    \"\"\"\n    Â∞Ü bitmask ËΩ¨Âõû channel ÂàóË°®„ÄÇ\n    ‰æãÂ¶Ç 41 (0b101001) ‚Üí [0,3,5]\n    \"\"\"\n    if mask is None or mask == 0:\n        return []\n    channels = []\n    bit_pos = 0\n    while mask > 0:",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "channels_to_mask",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def channels_to_mask(channels):\n    \"\"\"\n    Â∞Ü channels ÂàóË°®ËΩ¨Êç¢‰∏∫ bitmask„ÄÇ\n    ‰æãÂ¶Ç [0,3,5] ‚Üí 41 (‰∫åËøõÂà∂ 0b101001)\n    \"\"\"\n    if not channels:\n        return 0\n    mask = 0\n    for ch in channels:\n        mask |= 1 << int(ch)",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "get_paired_data",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def get_paired_data(df_events, group_mask, char):\n    \"\"\"\n    Ê†πÊçÆ encode_groups_binary ÁöÑÂä†ÊùÉÁªìÊûúÁ≠õÈÄâ‰∫ã‰ª∂Ôºå\n    Âπ∂ËøîÂõû (char) ÂØπÂ∫îÁöÑ numpy Êï∞ÁªÑ„ÄÇ\n    \"\"\"\n    # 1. Ëß£Á†ÅÔºömask ‚Üí Âì™‰∫õ group Âá∫Áé∞\n    # Áõ¥Êé•Âà©Áî® bit ËøêÁÆóÔºömask Êâ£Âì™‰∏™ weightÔºåÂ∞±ËØ¥ÊòéÂì™‰∏™ group Âá∫Áé∞\n    selected_groups = []\n    for weight, members in GROUP_WEIGHTS.items():\n        if group_mask & weight:  # bit on ‚Üí Â∑≤ÂåÖÂê´ËØ• group",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "energy_rec",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def energy_rec(data):\n    x, y = data\n    energy = np.sqrt(np.prod([x, y], axis=0)) * 2\n    return energy\ndef lr_log_ratio(data):\n    x, y = data\n    log_ratio = np.log(x) - np.log(y)\n    return log_ratio\nclass Datas:\n    def __init__(self, cache_dir) -> None:",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "lr_log_ratio",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def lr_log_ratio(data):\n    x, y = data\n    log_ratio = np.log(x) - np.log(y)\n    return log_ratio\nclass Datas:\n    def __init__(self, cache_dir) -> None:\n        self.cache_dir = cache_dir\n        df_file = os.path.join(cache_dir, \"df.feather\")\n        event_file = os.path.join(cache_dir, \"df_events.feather\")\n        self.df = pd.read_feather(df_file)",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "hist_count_ratio",
        "kind": 2,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "def hist_count_ratio(data_a, data_b, bins):\n    counts_a, bin_edges = np.histogram(data_a, bins=bins)\n    counts_b, _ = np.histogram(data_b, bins=bins)\n    ratio = np.divide(\n        counts_a,\n        counts_b,\n        out=np.zeros_like(counts_a, dtype=float),\n        where=counts_b > 0,\n    )\n    return bin_edges, counts_a, counts_b, ratio",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "GROUP_MAP",
        "kind": 5,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "GROUP_MAP = {\n    0: 1,\n    1: 1,  # group0: channels [0,1]\n    2: 3,\n    3: 3,  # group1: channels [2,3]\n    4: 7,\n    5: 7,  # group2: channels [4,5]\n}\n# ÁªÑÂêàÊùÉÈáçÔºàÁî®‰∫éÁªÑÂÆåÊï¥ÊÄßÁºñÁ†ÅÔºâ\nGROUP_WEIGHTS = {",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "GROUP_WEIGHTS",
        "kind": 5,
        "importPath": "waveform_analysis.utils.data_processing.processor",
        "description": "waveform_analysis.utils.data_processing.processor",
        "peekOfCode": "GROUP_WEIGHTS = {\n    1: {0, 1},  # weight 1 ‚Üí ÁªÑ {0,1}\n    3: {2, 3},  # weight 3 ‚Üí ÁªÑ {2,3}\n    7: {4, 5},  # weight 7 ‚Üí ÁªÑ {4,5}\n}\ndef encode_groups_binary(channels):\n    \"\"\"\n    ‰ªªÊÑèÁªÑÂá∫Áé∞‰∫ÜÈÉ®ÂàÜÊàêÂëòÔºà‰∏çÊàêÂØπÔºâ -> Êï¥‰ΩìËøîÂõû 0ÔºàÂºÇÂ∏∏Ôºâ\n    ÊâÄÊúâÁªÑË¶Å‰πàÂÆåÊï¥Âá∫Áé∞ÔºåË¶Å‰πàÂÆåÂÖ®‰∏çÂá∫Áé∞„ÄÇ\n    \"\"\"",
        "detail": "waveform_analysis.utils.data_processing.processor",
        "documentation": {}
    },
    {
        "label": "WaveformStruct",
        "kind": 6,
        "importPath": "waveform_analysis.utils.data_processing.wavestruct",
        "description": "waveform_analysis.utils.data_processing.wavestruct",
        "peekOfCode": "class WaveformStruct:\n    def __init__(self, waveforms):\n        self.waveforms = waveforms\n        self.event_length = None\n        self.waveform_structureds = None\n    def _structrue_waveform(self, waves=None):\n        # If no explicit waves passed, use the first channel\n        if waves is None:\n            if not self.waveforms:\n                return np.zeros(0, dtype=RECORD_DTYPE)",
        "detail": "waveform_analysis.utils.data_processing.wavestruct",
        "documentation": {}
    },
    {
        "label": "RECORD_DTYPE",
        "kind": 5,
        "importPath": "waveform_analysis.utils.data_processing.wavestruct",
        "description": "waveform_analysis.utils.data_processing.wavestruct",
        "peekOfCode": "RECORD_DTYPE = [\n    (\"baseline\", \"f8\"),  # float64 for baseline\n    (\"timestamp\", \"i8\"),  # int64 for ps-level timestamps\n    (\"event_length\", \"i8\"),  # length of the event\n    (\"wave\", \"O\"),  # object for variable length waveform (or fixed if padded)\n]\n# Peak: A detected peak in a waveform\nPEAK_DTYPE = [\n    (\"time\", \"i8\"),  # time of the peak\n    (\"area\", \"f4\"),  # area of the peak",
        "detail": "waveform_analysis.utils.data_processing.wavestruct",
        "documentation": {}
    },
    {
        "label": "PEAK_DTYPE",
        "kind": 5,
        "importPath": "waveform_analysis.utils.data_processing.wavestruct",
        "description": "waveform_analysis.utils.data_processing.wavestruct",
        "peekOfCode": "PEAK_DTYPE = [\n    (\"time\", \"i8\"),  # time of the peak\n    (\"area\", \"f4\"),  # area of the peak\n    (\"height\", \"f4\"),  # height of the peak\n    (\"width\", \"f4\"),  # width of the peak\n    (\"channel\", \"i2\"),  # channel index\n    (\"event_index\", \"i8\"),  # index of the event in the dataset\n]\nclass WaveformStruct:\n    def __init__(self, waveforms):",
        "detail": "waveform_analysis.utils.data_processing.wavestruct",
        "documentation": {}
    },
    {
        "label": "plot_lineage_labview",
        "kind": 2,
        "importPath": "waveform_analysis.utils.visualization.lineage_visulizer",
        "description": "waveform_analysis.utils.visualization.lineage_visulizer",
        "peekOfCode": "def plot_lineage_labview(\n    lineage: Any,\n    target_name: str,\n    context: Any = None,\n    style: Optional[LineageStyle] = None,\n    show_dtype_on_wire: bool = True,\n    **kwargs,\n):\n    \"\"\"\n    ÁªòÂà∂È´òÂ∫¶ÂèØÂÆöÂà∂ÁöÑ LabVIEW È£éÊ†ºÊèí‰ª∂Ë°ÄÁºòÂõæ„ÄÇ",
        "detail": "waveform_analysis.utils.visualization.lineage_visulizer",
        "documentation": {}
    },
    {
        "label": "plot_waveforms",
        "kind": 2,
        "importPath": "waveform_analysis.utils.visualization.visulizer",
        "description": "waveform_analysis.utils.visualization.visulizer",
        "peekOfCode": "def plot_waveforms(\n    waveforms: Union[np.ndarray, List[np.ndarray]],\n    hits: Optional[np.ndarray] = None,\n    event_index: int = 0,\n    channels: Optional[List[int]] = None,\n    title: str = \"Waveform Viewer\",\n):\n    \"\"\"\n    Creates an interactive Plotly figure for browsing waveforms and hits.\n    Args:",
        "detail": "waveform_analysis.utils.visualization.visulizer",
        "documentation": {}
    },
    {
        "label": "create_interactive_browser",
        "kind": 2,
        "importPath": "waveform_analysis.utils.visualization.visulizer",
        "description": "waveform_analysis.utils.visualization.visulizer",
        "peekOfCode": "def create_interactive_browser(context, run_id: str):\n    \"\"\"\n    Returns a function that can be used with ipywidgets.interact to browse events.\n    \"\"\"\n    # This is intended for use in a Jupyter Notebook\n    waveforms = context.get_data(run_id, \"st_waveforms\")\n    hits = context.get_data(run_id, \"hits\")\n    def browse(event_index=0):\n        fig = plot_waveforms(waveforms, hits, event_index=event_index)\n        fig.show()",
        "detail": "waveform_analysis.utils.visualization.visulizer",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "waveform_analysis.cli",
        "description": "waveform_analysis.cli",
        "peekOfCode": "def main():\n    \"\"\"‰∏ªÂëΩ‰ª§Ë°åÂÖ•Âè£\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Waveform Analysis - waveform data processing toolkit\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nÁ§∫‰æã:\n  # Â§ÑÁêÜÂçï‰∏™Êï∞ÊçÆÈõÜ\n  waveform-process --char 50V_OV_circulation_20thr --output results.csv\n  # ÊåáÂÆöÊó∂Èó¥Á™óÂè£",
        "detail": "waveform_analysis.cli",
        "documentation": {}
    },
    {
        "label": "DAQRun",
        "kind": 6,
        "importPath": "DAQAnalyzer",
        "description": "DAQAnalyzer",
        "peekOfCode": "class DAQRun:\n    \"\"\"Âçï‰∏™ DAQ ËøêË°åÁöÑÊï∞ÊçÆÂíåÂàÜÊûêÁ±ª\"\"\"\n    # ‰ªÖÂ§ÑÁêÜ CSV Êï∞ÊçÆÊñá‰ª∂ÔºåÈÅøÂÖçËØØËØª .root/.dat\n    ALLOWED_EXTS = (\".CSV\", \".csv\")\n    CH_PATTERN = re.compile(r\"CH(\\d+)\")\n    IDX_PATTERN = re.compile(r\"_(\\d+)\\.CSV$\", re.IGNORECASE)\n    def __init__(self, run_name, run_path):\n        self.run_name = run_name\n        self.run_path = run_path\n        self.raw_dir = os.path.join(run_path, \"RAW\")",
        "detail": "DAQAnalyzer",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "kind": 6,
        "importPath": "DAQAnalyzer",
        "description": "DAQAnalyzer",
        "peekOfCode": "class DAQAnalyzer:\n    \"\"\"DAQ Êï∞ÊçÆÂàÜÊûêÂô®ÔºöÁÆ°ÁêÜÊâÄÊúâËøêË°åÁöÑÁªü‰∏ÄÂàÜÊûê\"\"\"\n    def __init__(self, daq_root=\"DAQ\"):\n        self.daq_root = daq_root\n        self.runs = {}  # {run_name: DAQRun}\n        self.df_runs = None\n        self.total_bytes = 0\n    @staticmethod\n    def format_size(bytes_val):\n        \"\"\"Â∞ÜÂ≠óËäÇËΩ¨Êç¢‰∏∫ÊòìËØªÊ†ºÂºè\"\"\"",
        "detail": "DAQAnalyzer",
        "documentation": {}
    }
]