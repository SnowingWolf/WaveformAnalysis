[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "get_raw_files",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "cli",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "importPath": "waveform_analysis",
        "description": "waveform_analysis",
        "isExtraImport": true,
        "detail": "waveform_analysis",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_simple_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "importPath": "tests.utils",
        "description": "tests.utils",
        "isExtraImport": true,
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "isExtraImport": true,
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "get_raw_files",
        "importPath": "waveform_analysis.core",
        "description": "waveform_analysis.core",
        "isExtraImport": true,
        "detail": "waveform_analysis.core",
        "documentation": {}
    },
    {
        "label": "get_waveforms",
        "importPath": "waveform_analysis.core",
        "description": "waveform_analysis.core",
        "isExtraImport": true,
        "detail": "waveform_analysis.core",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "bisect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bisect",
        "description": "bisect",
        "detail": "bisect",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "Minuit",
        "importPath": "iminuit",
        "description": "iminuit",
        "isExtraImport": true,
        "detail": "iminuit",
        "documentation": {}
    },
    {
        "label": "LeastSquares",
        "importPath": "iminuit.cost",
        "description": "iminuit.cost",
        "isExtraImport": true,
        "detail": "iminuit.cost",
        "documentation": {}
    },
    {
        "label": "BaseFitter",
        "importPath": "pyDAW",
        "description": "pyDAW",
        "isExtraImport": true,
        "detail": "pyDAW",
        "documentation": {}
    },
    {
        "label": "norm",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "jax",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jax",
        "description": "jax",
        "detail": "jax",
        "documentation": {}
    },
    {
        "label": "vmap",
        "importPath": "jax",
        "description": "jax",
        "isExtraImport": true,
        "detail": "jax",
        "documentation": {}
    },
    {
        "label": "jax.numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jax.numpy",
        "description": "jax.numpy",
        "detail": "jax.numpy",
        "documentation": {}
    },
    {
        "label": "erf",
        "importPath": "jax.scipy.special",
        "description": "jax.scipy.special",
        "isExtraImport": true,
        "detail": "jax.scipy.special",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "example_custom_features",
        "kind": 2,
        "importPath": "examples.advanced_features",
        "description": "examples.advanced_features",
        "peekOfCode": "def example_custom_features():\n    \"\"\"ç¤ºä¾‹ï¼šæ³¨å†Œå’Œä½¿ç”¨è‡ªå®šä¹‰ç‰¹å¾\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"è‡ªå®šä¹‰ç‰¹å¾ç¤ºä¾‹\")\n    print(\"=\" * 60)\n    dataset = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2, start_channel_slice=6)\n    # åŠ è½½å’Œå¤„ç†æ•°æ®\n    try:\n        (dataset.load_raw_data().extract_waveforms().structure_waveforms())\n    except FileNotFoundError:",
        "detail": "examples.advanced_features",
        "documentation": {}
    },
    {
        "label": "example_custom_pairing",
        "kind": 2,
        "importPath": "examples.advanced_features",
        "description": "examples.advanced_features",
        "peekOfCode": "def example_custom_pairing():\n    \"\"\"ç¤ºä¾‹ï¼šä½¿ç”¨è‡ªå®šä¹‰é…å¯¹ç­–ç•¥\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"è‡ªå®šä¹‰é…å¯¹ç­–ç•¥ç¤ºä¾‹\")\n    print(\"=\" * 60)\n    dataset = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2, start_channel_slice=6)\n    # å¤„ç†åˆ°åˆ†ç»„é˜¶æ®µ\n    try:\n        (\n            dataset.load_raw_data()",
        "detail": "examples.advanced_features",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.basic_analysis",
        "description": "examples.basic_analysis",
        "peekOfCode": "def main():\n    \"\"\"ä¸»å‡½æ•° - å®Œæ•´æ•°æ®å¤„ç†æµç¨‹ç¤ºä¾‹\"\"\"\n    print(\"=\" * 60)\n    print(\"æ³¢å½¢æ•°æ®åˆ†æç¤ºä¾‹\")\n    print(\"=\" * 60)\n    # 1. åˆ›å»ºæ•°æ®é›†å®ä¾‹\n    print(\"\\n1. åˆ›å»ºæ•°æ®é›†...\")\n    dataset = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2, start_channel_slice=6)\n    # 2. æ‰§è¡Œå®Œæ•´å¤„ç†æµç¨‹ï¼ˆé“¾å¼è°ƒç”¨ï¼‰\n    print(\"\\n2. æ‰§è¡Œæ•°æ®å¤„ç†æµç¨‹...\")",
        "detail": "examples.basic_analysis",
        "documentation": {}
    },
    {
        "label": "plot_example_waveforms",
        "kind": 2,
        "importPath": "examples.basic_analysis",
        "description": "examples.basic_analysis",
        "peekOfCode": "def plot_example_waveforms(dataset, n_examples=4):\n    \"\"\"ç»˜åˆ¶ç¤ºä¾‹æ³¢å½¢\"\"\"\n    df_paired = dataset.get_paired_events()\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    axes = axes.flatten()\n    for i in range(min(n_examples, len(df_paired))):\n        ax = axes[i]\n        result_ch6 = dataset.get_waveform_at(event_idx=i, channel=0)\n        result_ch7 = dataset.get_waveform_at(event_idx=i, channel=1)\n        if result_ch6 and result_ch7:",
        "detail": "examples.basic_analysis",
        "documentation": {}
    },
    {
        "label": "example_without_waveforms",
        "kind": 2,
        "importPath": "examples.skip_waveforms",
        "description": "examples.skip_waveforms",
        "peekOfCode": "def example_without_waveforms():\n    \"\"\"ç¤ºä¾‹ï¼šä¸åŠ è½½æ³¢å½¢ï¼Œä»…æå–ç‰¹å¾æ•°æ®\"\"\"\n    print(\"=\" * 60)\n    print(\"ä¸åŠ è½½æ³¢å½¢æ•°æ®ç¤ºä¾‹\")\n    print(\"=\" * 60)\n    # åˆ›å»ºæ•°æ®é›†ï¼ŒæŒ‡å®š load_waveforms=False\n    dataset = WaveformDataset(\n        char=\"50V_OV_circulation_20thr\",\n        n_channels=2,\n        start_channel_slice=6,",
        "detail": "examples.skip_waveforms",
        "documentation": {}
    },
    {
        "label": "example_with_and_without_comparison",
        "kind": 2,
        "importPath": "examples.skip_waveforms",
        "description": "examples.skip_waveforms",
        "peekOfCode": "def example_with_and_without_comparison():\n    \"\"\"å¯¹æ¯”ï¼šåŠ è½½vsä¸åŠ è½½æ³¢å½¢çš„æ€§èƒ½å·®å¼‚\"\"\"\n    import time\n    print(\"\\n\" + \"=\" * 60)\n    print(\"æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹\")\n    print(\"=\" * 60)\n    # åŠ è½½æ³¢å½¢\n    print(\"\\n1. åŠ è½½æ³¢å½¢æ•°æ®...\")\n    start = time.time()\n    dataset_with_waves = WaveformDataset(",
        "detail": "examples.skip_waveforms",
        "documentation": {}
    },
    {
        "label": "example_memory_usage",
        "kind": 2,
        "importPath": "examples.skip_waveforms",
        "description": "examples.skip_waveforms",
        "peekOfCode": "def example_memory_usage():\n    \"\"\"ä¼°è®¡å†…å­˜ä½¿ç”¨æƒ…å†µ\"\"\"\n    import sys\n    print(\"\\n\" + \"=\" * 60)\n    print(\"å†…å­˜ä½¿ç”¨ä¼°è®¡\")\n    print(\"=\" * 60)\n    # åŠ è½½æ³¢å½¢\n    print(\"\\n1. åŠ è½½æ³¢å½¢...\")\n    dataset_with = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2, load_waveforms=True)\n    try:",
        "detail": "examples.skip_waveforms",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.demo_skip_waveforms",
        "description": "scripts.demo_skip_waveforms",
        "peekOfCode": "def main():\n    print(\"\\n\" + \"=\" * 70)\n    print(\"æ¼”ç¤ºï¼šé€‰æ‹©ä¸åŠ è½½åŸå§‹æ³¢å½¢ä»¥èŠ‚çœå†…å­˜\")\n    print(\"=\" * 70)\n    # æ–¹æ³• 1: åŠ è½½æ³¢å½¢ï¼ˆé»˜è®¤ï¼‰\n    print(\"\\nğŸ“Œ æ–¹æ³• 1: åŠ è½½æ³¢å½¢ï¼ˆload_waveforms=Trueï¼Œé»˜è®¤ï¼‰\")\n    print(\"-\" * 70)\n    print(\"\"\"\n    dataset = WaveformDataset(\n        char=\"50V_OV_circulation_20thr\",",
        "detail": "scripts.demo_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "project_root",
        "kind": 5,
        "importPath": "scripts.demo_skip_waveforms",
        "description": "scripts.demo_skip_waveforms",
        "peekOfCode": "project_root = Path(__file__).parent.parent\nsys.path.insert(0, str(project_root))\nfrom waveform_analysis import WaveformDataset\ndef main():\n    print(\"\\n\" + \"=\" * 70)\n    print(\"æ¼”ç¤ºï¼šé€‰æ‹©ä¸åŠ è½½åŸå§‹æ³¢å½¢ä»¥èŠ‚çœå†…å­˜\")\n    print(\"=\" * 70)\n    # æ–¹æ³• 1: åŠ è½½æ³¢å½¢ï¼ˆé»˜è®¤ï¼‰\n    print(\"\\nğŸ“Œ æ–¹æ³• 1: åŠ è½½æ³¢å½¢ï¼ˆload_waveforms=Trueï¼Œé»˜è®¤ï¼‰\")\n    print(\"-\" * 70)",
        "detail": "scripts.demo_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "check_import",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_import():\n    \"\"\"æ£€æŸ¥åŒ…å¯¼å…¥\"\"\"\n    print(\"1. æ£€æŸ¥åŒ…å¯¼å…¥...\")\n    try:\n        import waveform_analysis\n        print(f\"   âœ… waveform_analysis ç‰ˆæœ¬: {waveform_analysis.__version__}\")\n    except ImportError as e:\n        print(f\"   âŒ å¯¼å…¥å¤±è´¥: {e}\")\n        return False\n    return True",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "check_core_modules",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_core_modules():\n    \"\"\"æ£€æŸ¥æ ¸å¿ƒæ¨¡å—\"\"\"\n    print(\"\\n2. æ£€æŸ¥æ ¸å¿ƒæ¨¡å—...\")\n    try:\n        from waveform_analysis import (\n            WaveformDataset,\n            WaveformStruct,\n            build_waveform_df,\n            get_raw_files,\n            get_waveforms,",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "check_submodules",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_submodules():\n    \"\"\"æ£€æŸ¥å­æ¨¡å—\"\"\"\n    print(\"\\n3. æ£€æŸ¥å­æ¨¡å—...\")\n    modules = [\n        (\"waveform_analysis.core\", [\"loader\", \"processor\", \"dataset\"]),\n        (\"waveform_analysis.fitting\", [\"models\"]),\n        (\"waveform_analysis.utils\", []),\n    ]\n    all_ok = True\n    for pkg, subs in modules:",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "check_cli",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_cli():\n    \"\"\"æ£€æŸ¥å‘½ä»¤è¡Œå·¥å…·\"\"\"\n    print(\"\\n4. æ£€æŸ¥å‘½ä»¤è¡Œå·¥å…·...\")\n    import subprocess\n    try:\n        result = subprocess.run([\"waveform-process\", \"--version\"], capture_output=True, text=True, timeout=5)\n        if result.returncode == 0:\n            print(f\"   âœ… CLI å·¥å…·å¯ç”¨: {result.stdout.strip()}\")\n            return True\n        else:",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "check_dataset_creation",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def check_dataset_creation():\n    \"\"\"æ£€æŸ¥æ•°æ®é›†åˆ›å»º\"\"\"\n    print(\"\\n5. æ£€æŸ¥æ•°æ®é›†åˆ›å»º...\")\n    try:\n        from waveform_analysis import WaveformDataset\n        dataset = WaveformDataset(char=\"test\", n_channels=2)\n        print(\"   âœ… WaveformDataset å¯ä»¥åˆ›å»º\")\n        print(f\"      - char: {dataset.char}\")\n        print(f\"      - n_channels: {dataset.n_channels}\")\n        return True",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.verify_install",
        "description": "scripts.verify_install",
        "peekOfCode": "def main():\n    \"\"\"ä¸»å‡½æ•°\"\"\"\n    print(\"=\" * 60)\n    print(\"Waveform Analysis å®‰è£…éªŒè¯\")\n    print(\"=\" * 60)\n    checks = [\n        check_import,\n        check_core_modules,\n        check_submodules,\n        check_cli,",
        "detail": "scripts.verify_install",
        "documentation": {}
    },
    {
        "label": "make_csv_fn",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def make_csv_fn():\n    \"\"\"Fixture that returns the make_csv helper function.\"\"\"\n    return make_csv\n@pytest.fixture\ndef make_simple_csv_fn():\n    \"\"\"Fixture that returns the make_simple_csv helper function.\"\"\"\n    return make_simple_csv\n@pytest.fixture\ndef create_daq_run(tmp_path: Path):\n    \"\"\"Factory fixture to create a DAQ run directory structure.",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "make_simple_csv_fn",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def make_simple_csv_fn():\n    \"\"\"Fixture that returns the make_simple_csv helper function.\"\"\"\n    return make_simple_csv\n@pytest.fixture\ndef create_daq_run(tmp_path: Path):\n    \"\"\"Factory fixture to create a DAQ run directory structure.\n    Usage:\n        daq_root, run_dir, raw_dir = create_daq_run('my_run')\n        # optionally create files with make_csv_fn in tests\n    \"\"\"",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "create_daq_run",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def create_daq_run(tmp_path: Path):\n    \"\"\"Factory fixture to create a DAQ run directory structure.\n    Usage:\n        daq_root, run_dir, raw_dir = create_daq_run('my_run')\n        # optionally create files with make_csv_fn in tests\n    \"\"\"\n    def _create(run_name: str = \"run\"):\n        daq_root = tmp_path / \"DAQ\"\n        run_dir = daq_root / run_name\n        raw_dir = run_dir / \"RAW\"",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "test_import",
        "kind": 2,
        "importPath": "tests.test_basic",
        "description": "tests.test_basic",
        "peekOfCode": "def test_import():\n    \"\"\"æµ‹è¯•åŒ…å¯ä»¥æ­£å¸¸å¯¼å…¥\"\"\"\n    from waveform_analysis import (\n        WaveformDataset,\n        WaveformStruct,\n        build_waveform_df,\n        get_raw_files,\n        get_waveforms,\n        group_multi_channel_hits,\n    )",
        "detail": "tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_waveform_struct",
        "kind": 2,
        "importPath": "tests.test_basic",
        "description": "tests.test_basic",
        "peekOfCode": "def test_waveform_struct():\n    \"\"\"æµ‹è¯•æ³¢å½¢ç»“æ„åŒ–\"\"\"\n    from waveform_analysis.core import WaveformStruct\n    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®\n    mock_waveforms = [np.random.randn(100, 807), np.random.randn(100, 807)]\n    struct = WaveformStruct(mock_waveforms)\n    st_waveforms = struct.structrue_waveforms()\n    assert len(st_waveforms) == 2\n    assert len(st_waveforms[0]) == 100\ndef test_dataset_init():",
        "detail": "tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_dataset_init",
        "kind": 2,
        "importPath": "tests.test_basic",
        "description": "tests.test_basic",
        "peekOfCode": "def test_dataset_init():\n    \"\"\"æµ‹è¯•æ•°æ®é›†åˆå§‹åŒ–\"\"\"\n    try:\n        dataset = WaveformDataset(char=\"test_dataset\", n_channels=2, start_channel_slice=6)\n        assert dataset.char == \"test_dataset\"\n        assert dataset.n_channels == 2\n    except FileNotFoundError:\n        # å¦‚æœæµ‹è¯•æ•°æ®ä¸å­˜åœ¨ï¼Œè·³è¿‡\n        pytest.skip(\"Test data not available\")\nif __name__ == \"__main__\":",
        "detail": "tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_chain_continues_on_error",
        "kind": 2,
        "importPath": "tests.test_chainable_steps",
        "description": "tests.test_chainable_steps",
        "peekOfCode": "def test_chain_continues_on_error(tmp_path: Path):\n    # prepare run with minimal files\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"chain_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    make_csv(raw_dir, 6, 0, 1000, 1100, n_samples=10)\n    ds = WaveformDataset(char=\"chain_run\", data_root=str(daq_root), use_daq_scan=True)\n    # æ›¿æ¢ç±»æ–¹æ³•ä¸ºå‡ºé”™ç‰ˆæœ¬å¹¶ç”¨ chainable_step åŒ…è£…\n    def _bad_structure(self, verbose: bool = True):",
        "detail": "tests.test_chainable_steps",
        "documentation": {}
    },
    {
        "label": "test_fail_on_error_behavior",
        "kind": 2,
        "importPath": "tests.test_chainable_steps",
        "description": "tests.test_chainable_steps",
        "peekOfCode": "def test_fail_on_error_behavior(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"chain_run2\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    from tests.utils import make_csv\n    make_csv(raw_dir, 6, 0, 2000, 2100, n_samples=10)\n    ds = WaveformDataset(char=\"chain_run2\", data_root=str(daq_root), use_daq_scan=True)\n    # æ›¿æ¢ç±»æ–¹æ³•ä¸ºå‡ºé”™ç‰ˆæœ¬å¹¶ç”¨ chainable_step åŒ…è£…\n    def _bad_build_dataframe(self, verbose: bool = True):",
        "detail": "tests.test_chainable_steps",
        "documentation": {}
    },
    {
        "label": "test_cli_show_daq_returns_zero",
        "kind": 2,
        "importPath": "tests.test_cli_show_daq",
        "description": "tests.test_cli_show_daq",
        "peekOfCode": "def test_cli_show_daq_returns_zero(tmp_path: Path, monkeypatch):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"cli_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create minimal CSVs\n    n_samples = 50\n    header = \"HEADER;X;TIMETAG;\" + \";\".join(f\"S{i}\" for i in range(n_samples)) + \"\\n\"\n    from tests.utils import make_simple_csv\n    make_simple_csv(raw_dir, 6, 0, 1000, n_samples=50)",
        "detail": "tests.test_cli_show_daq",
        "documentation": {}
    },
    {
        "label": "test_scan_single_run",
        "kind": 2,
        "importPath": "tests.test_daq",
        "description": "tests.test_daq",
        "peekOfCode": "def test_scan_single_run(tmp_path: Path, make_csv_fn):\n    # å‡†å¤‡æ¨¡æ‹Ÿ DAQ ç›®å½•\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"test_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # åˆ›å»ºä¸¤ä¸ªé€šé“çš„ CSV æ–‡ä»¶\n    make_csv_fn(raw_dir, 1, 0, 1000, 2000)\n    make_csv_fn(raw_dir, 2, 0, 1500, 2500)\n    # è¿è¡Œæ‰«æ",
        "detail": "tests.test_daq",
        "documentation": {}
    },
    {
        "label": "test_waveformdataset_loads_using_daq_scan",
        "kind": 2,
        "importPath": "tests.test_daq_integration",
        "description": "tests.test_daq_integration",
        "peekOfCode": "def test_waveformdataset_loads_using_daq_scan(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"my_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create CH6/CH7 files to match start_channel_slice default 6\n    make_csv(raw_dir, 6, 0, 1000, 2000)\n    make_csv(raw_dir, 7, 0, 1500, 2500)\n    # Use DAQ scan integration\n    ds = WaveformDataset(char=\"my_run\", data_root=str(daq_root), use_daq_scan=True)",
        "detail": "tests.test_daq_integration",
        "documentation": {}
    },
    {
        "label": "test_waveformdataset_loads_using_daq_report",
        "kind": 2,
        "importPath": "tests.test_daq_integration",
        "description": "tests.test_daq_integration",
        "peekOfCode": "def test_waveformdataset_loads_using_daq_report(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"report_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    make_csv(raw_dir, 6, 0, 1000, 2000)\n    # create json report\n    analyzer = DAQAnalyzer(str(daq_root))\n    analyzer.scan_all_runs()\n    out = tmp_path / \"report.json\"",
        "detail": "tests.test_daq_integration",
        "documentation": {}
    },
    {
        "label": "test_summary_includes_daq_info",
        "kind": 2,
        "importPath": "tests.test_daq_report_factory_and_summary",
        "description": "tests.test_daq_report_factory_and_summary",
        "peekOfCode": "def test_summary_includes_daq_info(tmp_path: Path, make_csv_fn):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"summ_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create channel files\n    make_csv(raw_dir, 6, 0, 1000, 2000)\n    make_csv(raw_dir, 7, 0, 1500, 2500)\n    ds = WaveformDataset(char=\"summ_run\", data_root=str(daq_root), use_daq_scan=True)\n    ds.check_daq_status()",
        "detail": "tests.test_daq_report_factory_and_summary",
        "documentation": {}
    },
    {
        "label": "test_from_daq_report_runs_pipeline",
        "kind": 2,
        "importPath": "tests.test_daq_report_factory_and_summary",
        "description": "tests.test_daq_report_factory_and_summary",
        "peekOfCode": "def test_from_daq_report_runs_pipeline(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"factory_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create minimal CSVs\n    make_csv_fn(raw_dir, 6, 0, 1000, 2000)\n    make_csv_fn(raw_dir, 7, 0, 1500, 2500)\n    analyzer = DAQAnalyzer(str(daq_root))\n    analyzer.scan_all_runs()",
        "detail": "tests.test_daq_report_factory_and_summary",
        "documentation": {}
    },
    {
        "label": "test_summary_from_daq_scan_includes_fields",
        "kind": 2,
        "importPath": "tests.test_daq_summary_scan",
        "description": "tests.test_daq_summary_scan",
        "peekOfCode": "def test_summary_from_daq_scan_includes_fields(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"scan_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    make_csv(raw_dir, 6, 0, 1000, 2000)\n    make_csv(raw_dir, 7, 0, 1500, 2500)\n    ds = WaveformDataset(char=\"scan_run\", data_root=str(daq_root), use_daq_scan=True, daq_root=str(daq_root))\n    info = ds.check_daq_status()\n    assert info is not None",
        "detail": "tests.test_daq_summary_scan",
        "documentation": {}
    },
    {
        "label": "tmp_simple_csv",
        "kind": 2,
        "importPath": "tests.test_display_run_channel_details",
        "description": "tests.test_display_run_channel_details",
        "peekOfCode": "def tmp_simple_csv(tmp_path):\n    csv_path = tmp_path / \"file.csv\"\n    make_csv(csv_path, samples=40)\n    return csv_path\n@pytest.fixture\ndef sample_df(tmp_simple_csv):\n    # load into DataFrame similar to loader behavior for testing styler\n    df = pd.read_csv(tmp_simple_csv, sep=';', header=None)\n    df = df.apply(pd.to_numeric, errors='coerce')\n    return df",
        "detail": "tests.test_display_run_channel_details",
        "documentation": {}
    },
    {
        "label": "sample_df",
        "kind": 2,
        "importPath": "tests.test_display_run_channel_details",
        "description": "tests.test_display_run_channel_details",
        "peekOfCode": "def sample_df(tmp_simple_csv):\n    # load into DataFrame similar to loader behavior for testing styler\n    df = pd.read_csv(tmp_simple_csv, sep=';', header=None)\n    df = df.apply(pd.to_numeric, errors='coerce')\n    return df\ndef test_display_run_channel_details_prints(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"disp_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)",
        "detail": "tests.test_display_run_channel_details",
        "documentation": {}
    },
    {
        "label": "test_display_run_channel_details_prints",
        "kind": 2,
        "importPath": "tests.test_display_run_channel_details",
        "description": "tests.test_display_run_channel_details",
        "peekOfCode": "def test_display_run_channel_details_prints(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"disp_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    make_csv(raw_dir, 6, 0, 1000, 2000)\n    make_csv(raw_dir, 7, 0, 1500, 2500)\n    analyzer = DAQAnalyzer(str(daq_root))\n    analyzer.scan_all_runs()\n    # ensure it doesn't raise and returns self",
        "detail": "tests.test_display_run_channel_details",
        "documentation": {}
    },
    {
        "label": "test_raw_file_loader",
        "kind": 2,
        "importPath": "tests.test_loader",
        "description": "tests.test_loader",
        "peekOfCode": "def test_raw_file_loader():\n    \"\"\"æµ‹è¯•åŸå§‹æ–‡ä»¶åŠ è½½å™¨\"\"\"\n    from waveform_analysis.core.loader import RawFileLoader\n    loader = RawFileLoader(n_channels=8, char=\"test\")\n    assert loader.n_channels == 8\n    assert loader.base_dir.name == \"RAW\"\nif __name__ == \"__main__\":\n    pytest.main([__file__, \"-v\"])",
        "detail": "tests.test_loader",
        "documentation": {}
    },
    {
        "label": "test_without_waveforms",
        "kind": 2,
        "importPath": "tests.test_skip_waveforms",
        "description": "tests.test_skip_waveforms",
        "peekOfCode": "def test_without_waveforms(tmp_path: Path):\n    \"\"\"æµ‹è¯•ï¼šä¸åŠ è½½æ³¢å½¢\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"æµ‹è¯• 1: ä¸åŠ è½½æ³¢å½¢ (load_waveforms=False)\")\n    print(\"=\" * 70)\n    data_root = tmp_path / \"DAQ\"\n    run_dir = data_root / \"50V_OV_circulation_20thr\"\n    (run_dir / \"RAW\").mkdir(parents=True)\n    dataset = WaveformDataset(\n        char=\"50V_OV_circulation_20thr\", n_channels=2, start_channel_slice=6, load_waveforms=False, data_root=str(data_root)",
        "detail": "tests.test_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "test_with_waveforms",
        "kind": 2,
        "importPath": "tests.test_skip_waveforms",
        "description": "tests.test_skip_waveforms",
        "peekOfCode": "def test_with_waveforms(tmp_path: Path):\n    \"\"\"æµ‹è¯•ï¼šåŠ è½½æ³¢å½¢\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"æµ‹è¯• 2: åŠ è½½æ³¢å½¢ (load_waveforms=Trueï¼Œé»˜è®¤)\")\n    print(\"=\" * 70)\n    data_root = tmp_path / \"DAQ\"\n    run_dir = data_root / \"50V_OV_circulation_20thr\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    # create a tiny CSV so load_raw_data can find something",
        "detail": "tests.test_skip_waveforms",
        "documentation": {}
    },
    {
        "label": "test_memory_cache",
        "kind": 2,
        "importPath": "tests.test_step_caching",
        "description": "tests.test_step_caching",
        "peekOfCode": "def test_memory_cache(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"cache_run\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    from tests.utils import make_simple_csv\n    make_simple_csv(raw_dir, 6, 0, 1000)\n    ds = WaveformDataset(char=\"cache_run\", data_root=str(daq_root), use_daq_scan=True)\n    # enable caching for structure_waveforms to store st_waveforms and pair_len\n    ds.set_step_cache(\"structure_waveforms\", enabled=True, attrs=[\"st_waveforms\", \"pair_len\"])",
        "detail": "tests.test_step_caching",
        "documentation": {}
    },
    {
        "label": "test_persistent_cache",
        "kind": 2,
        "importPath": "tests.test_step_caching",
        "description": "tests.test_step_caching",
        "peekOfCode": "def test_persistent_cache(tmp_path: Path):\n    daq_root = tmp_path / \"DAQ\"\n    run_dir = daq_root / \"cache_run2\"\n    raw_dir = run_dir / \"RAW\"\n    raw_dir.mkdir(parents=True)\n    from tests.utils import make_simple_csv\n    make_simple_csv(raw_dir, 6, 0, 2000)\n    ds = WaveformDataset(char=\"cache_run2\", data_root=str(daq_root), use_daq_scan=True)\n    cache_file = tmp_path / \"struct_cache.pkl\"\n    ds.set_step_cache(",
        "detail": "tests.test_step_caching",
        "documentation": {}
    },
    {
        "label": "make_csv",
        "kind": 2,
        "importPath": "tests.utils",
        "description": "tests.utils",
        "peekOfCode": "def make_csv(dirpath: Path, ch: int, idx: int, start_tag: int, end_tag: int, n_samples: int = 200, meta: bool = True):\n    \"\"\"Create a CSV file with header and three rows (start, mid, end).\n    dirpath: Path to RAW directory\n    ch, idx: channel and index used in filename\n    start_tag, end_tag: timetag values\n    n_samples: number of sample columns (S0..)\n    meta: whether to add a metadata line before header (so skiprows=2 in loader works)\n    \"\"\"\n    fname = dirpath / f\"RUN_CH{ch}_{idx}.CSV\"\n    sample_headers = \";\".join(f\"S{i}\" for i in range(n_samples))",
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "make_simple_csv",
        "kind": 2,
        "importPath": "tests.utils",
        "description": "tests.utils",
        "peekOfCode": "def make_simple_csv(dirpath: Path, ch: int, idx: int, tag: int, n_samples: int = 50):\n    \"\"\"Create a simpler CSV used by some tests (two data rows)\"\"\"\n    fname = dirpath / f\"RUN_CH{ch}_{idx}.CSV\"\n    header = \"HEADER;X;TIMETAG;\" + \";\".join(f\"S{i}\" for i in range(n_samples)) + \"\\n\"\n    body = \"\".join(f\"v;1;{tag + i};\" + \";\".join(str((tag + i + j) % 100) for j in range(n_samples)) + \"\\n\" for i in range(2))\n    fname.write_text(header + body, encoding=\"utf-8\")",
        "detail": "tests.utils",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tests.verify_load_waveforms_feature",
        "description": "tests.verify_load_waveforms_feature",
        "peekOfCode": "def main():\n    print(\"\\n\" + \"=\" * 70)\n    print(\"âœ… å†…å­˜ä¼˜åŒ–åŠŸèƒ½éªŒè¯\")\n    print(\"=\" * 70)\n    # æµ‹è¯• 1: å‚æ•°å¯ç”¨æ€§\n    print(\"\\nğŸ“Œ æµ‹è¯• 1: load_waveforms å‚æ•°å¯ç”¨æ€§\")\n    print(\"-\" * 70)\n    try:\n        ds_false = WaveformDataset(char=\"50V_OV_circulation_20thr\", load_waveforms=False)\n        print(f\"âœ… load_waveforms=False: {ds_false.load_waveforms}\")",
        "detail": "tests.verify_load_waveforms_feature",
        "documentation": {}
    },
    {
        "label": "WaveformDataset",
        "kind": 6,
        "importPath": "waveform_analysis.core.dataset",
        "description": "waveform_analysis.core.dataset",
        "peekOfCode": "class WaveformDataset:\n    \"\"\"\n    ç»Ÿä¸€çš„æ³¢å½¢æ•°æ®é›†å®¹å™¨ï¼Œå°è£…æ•´ä¸ªæ•°æ®å¤„ç†æµç¨‹ã€‚\n    æ”¯æŒé“¾å¼è°ƒç”¨ï¼Œç®€åŒ–æ•°æ®åŠ è½½ã€é¢„å¤„ç†å’Œåˆ†æã€‚\n    ä½¿ç”¨ç¤ºä¾‹ï¼š\n        dataset = WaveformDataset(char=\"50V_OV_circulation_20thr\", n_channels=2)\n        dataset.load_raw_data().extract_waveforms().structure_waveforms()\\\\\n               .build_waveform_features().build_dataframe().group_events()\\\\\n               .pair_events().save_results()\n        df_paired = dataset.get_paired_events()",
        "detail": "waveform_analysis.core.dataset",
        "documentation": {}
    },
    {
        "label": "RawFileLoader",
        "kind": 6,
        "importPath": "waveform_analysis.core.loader",
        "description": "waveform_analysis.core.loader",
        "peekOfCode": "class RawFileLoader:\n    \"\"\"Efficient loader for DAQ waveform files with channel-aware grouping.\"\"\"\n    # **é¢„ç¼–è¯‘æ­£åˆ™**å‡å°‘é‡å¤ cost\n    _ch_re = re.compile(r\"CH(\\d+)\")\n    _idx_re = re.compile(r\"_(\\d+)\\.CSV$\", re.IGNORECASE)\n    def __init__(self, n_channels: int = 6, char: str = \"All_SelfTrigger\"):\n        self.base_dir = Path(f\"./DAQ/{char}/RAW\")\n        self.n_channels = n_channels\n        self.pattern = f\"DataR_CH*@VX2730_53013_{char}*.CSV\"\n    def _extract(self, filename: str) -> Optional[tuple[int, int]]:",
        "detail": "waveform_analysis.core.loader",
        "documentation": {}
    },
    {
        "label": "get_raw_files",
        "kind": 2,
        "importPath": "waveform_analysis.core.loader",
        "description": "waveform_analysis.core.loader",
        "peekOfCode": "def get_raw_files(n_channels=6, char=\"All_SelfTrigger\"):\n    return RawFileLoader(n_channels, char).get_raw_files()\ndef get_waveforms(raw_filess: List[List[str]]):\n    \"\"\"å°†æ‰€æœ‰ CSV åŠ è½½å¹¶æ‹¼æ¥æˆ numpy æ•°ç»„ï¼ˆfast modeï¼‰ã€‚\"\"\"\n    waveforms = []\n    for files in raw_filess:\n        if not files:\n            waveforms.append(np.array([]))\n            continue\n        arrs = []",
        "detail": "waveform_analysis.core.loader",
        "documentation": {}
    },
    {
        "label": "get_waveforms",
        "kind": 2,
        "importPath": "waveform_analysis.core.loader",
        "description": "waveform_analysis.core.loader",
        "peekOfCode": "def get_waveforms(raw_filess: List[List[str]]):\n    \"\"\"å°†æ‰€æœ‰ CSV åŠ è½½å¹¶æ‹¼æ¥æˆ numpy æ•°ç»„ï¼ˆfast modeï¼‰ã€‚\"\"\"\n    waveforms = []\n    for files in raw_filess:\n        if not files:\n            waveforms.append(np.array([]))\n            continue\n        arrs = []\n        for f in files:\n            try:",
        "detail": "waveform_analysis.core.loader",
        "documentation": {}
    },
    {
        "label": "build_filetime_index",
        "kind": 2,
        "importPath": "waveform_analysis.core.loader",
        "description": "waveform_analysis.core.loader",
        "peekOfCode": "def build_filetime_index(raw_filess):\n    \"\"\"å»ºç«‹åŸºäºæ–‡ä»¶ mtime çš„å¿«é€ŸæŸ¥æ‰¾è¡¨ã€‚\"\"\"\n    indexed = []\n    for ch_files in raw_filess:\n        if not ch_files:\n            indexed.append([])\n            continue\n        times = [(os.path.getmtime(f), f) for f in ch_files]\n        times.sort()\n        indexed.append(times)",
        "detail": "waveform_analysis.core.loader",
        "documentation": {}
    },
    {
        "label": "get_files_by_filetime",
        "kind": 2,
        "importPath": "waveform_analysis.core.loader",
        "description": "waveform_analysis.core.loader",
        "peekOfCode": "def get_files_by_filetime(indexed_table, t_query_mtime):\n    \"\"\"\n    ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾ï¼ˆbisectï¼‰ï¼Œæ‰¾åˆ°æœ€æ¥è¿‘çš„æ—¶é—´æ–‡ä»¶ï¼Œæ¯”åŸå®ç°æ›´å¿«ã€‚\n    \"\"\"\n    result = {}\n    for ch, entries in enumerate(indexed_table):\n        if not entries:\n            continue\n        timestamps = [t for t, _ in entries]\n        pos = bisect.bisect_left(timestamps, t_query_mtime)",
        "detail": "waveform_analysis.core.loader",
        "documentation": {}
    },
    {
        "label": "get_files_before",
        "kind": 2,
        "importPath": "waveform_analysis.core.loader",
        "description": "waveform_analysis.core.loader",
        "peekOfCode": "def get_files_before(raw_filess, files_by_time):\n    sel_raw_filess = []\n    for channel_idx, channel_files in enumerate(raw_filess):\n        target_fp = files_by_time.get(channel_idx)\n        if not target_fp:\n            sel_raw_filess.append([])\n            continue\n        if target_fp in channel_files:\n            matched_pos = channel_files.index(target_fp)\n            sel_raw_filess.append(channel_files[: matched_pos + 1])",
        "detail": "waveform_analysis.core.loader",
        "documentation": {}
    },
    {
        "label": "WaveformStruct",
        "kind": 6,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "class WaveformStruct:\n    def __init__(self, waveforms):\n        self.waveforms = waveforms\n        self.pair_length = None\n        self.waveform_structureds = None\n    def _structrue_waveform(self, waves=None):\n        # If no explicit waves passed, use the first channel\n        if waves is None:\n            if not self.waveforms:\n                return np.zeros(0, dtype=[(\"baseline\", \"f8\"), (\"timestamp\", \"i8\"), (\"pair_length\", \"i8\"), (\"wave\", \"O\")])",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "Datas",
        "kind": 6,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "class Datas:\n    def __init__(self, cache_dir) -> None:\n        self.cache_dir = cache_dir\n        df_file = os.path.join(cache_dir, \"df.feather\")\n        event_file = os.path.join(cache_dir, \"df_events.feather\")\n        self.df = pd.read_feather(df_file)\n        self.df_events = pd.read_feather(event_file)\ndef hist_count_ratio(data_a, data_b, bins):\n    counts_a, bin_edges = np.histogram(data_a, bins=bins)\n    counts_b, _ = np.histogram(data_b, bins=bins)",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "build_waveform_df",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def build_waveform_df(st_waveforms, peaks, charges, pair_len, n_channels=6):\n    \"\"\"æŠŠæ¯ä¸ªé€šé“çš„ timestamp / charge / peak / channel æ‹¼æˆä¸€ä¸ª DataFrame.\"\"\"\n    all_timestamps = []\n    all_charges = []\n    all_peaks = []\n    all_channels = []\n    for ch in range(n_channels):\n        n = pair_len[ch]\n        # å¦‚æœ timestamp æ˜¯ 1Dï¼ˆæ¯ä¸ªäº‹ä»¶ä¸€ä¸ªå€¼ï¼‰ï¼Œè¿™è¡Œæ˜¯ OK çš„ï¼›\n        # å¦‚æœæ˜¯ 2Dï¼ˆäº‹ä»¶ Ã— é‡‡æ ·ç‚¹ï¼‰ï¼Œå¯ä»¥æ”¹æˆ .mean(axis=1) æˆ– [:, 0]",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "group_multi_channel_hits",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def group_multi_channel_hits(df, time_window_ns):\n    \"\"\"\n    åœ¨ df ä¸­æŒ‰ timestamp èšç±»ï¼Œæ‰¾â€œåŒä¸€äº‹ä»¶çš„å¤šé€šé“è§¦å‘â€ï¼Œå¹¶åœ¨ç°‡å†…éƒ¨\n    æŒ‰ channel ä»å°åˆ°å¤§å¯¹ (channels, charges, peaks, timestamps) åŒæ­¥æ’åºã€‚\n    \"\"\"\n    time_window_ps = time_window_ns * 1e3\n    # å…ˆæŒ‰æ—¶é—´æ’åºä¸€æ¬¡\n    df_sorted = df.sort_values(\"timestamp\").reset_index(drop=True)\n    # ä¸€æ¬¡æ€§å–æˆ numpy æ•°ç»„ï¼Œåé¢å¾ªç¯åªå¤„ç†ç´¢å¼•ï¼Œå°‘åš iloc / array æ„é€ \n    ts_all = df_sorted[\"timestamp\"].to_numpy()",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "encode_groups_binary",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def encode_groups_binary(channels):\n    \"\"\"\n    ä»»æ„ç»„å‡ºç°äº†éƒ¨åˆ†æˆå‘˜ï¼ˆä¸æˆå¯¹ï¼‰ -> æ•´ä½“è¿”å› 0ï¼ˆå¼‚å¸¸ï¼‰\n    æ‰€æœ‰ç»„è¦ä¹ˆå®Œæ•´å‡ºç°ï¼Œè¦ä¹ˆå®Œå…¨ä¸å‡ºç°ã€‚\n    \"\"\"\n    if channels is None or len(channels) == 0:\n        return 0\n    ch_set = set(map(int, channels))\n    code = 0\n    for weight, group_members in GROUP_WEIGHTS.items():",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "encode_channels_binary",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def encode_channels_binary(channels):\n    \"\"\"\n    å°† channel åˆ—è¡¨è½¬æ¢ä¸ºäºŒè¿›åˆ¶ä½æ©ç ã€‚\n    ä¾‹å¦‚ [0,3,5] â†’ 1<<0 | 1<<3 | 1<<5 = 41\n    \"\"\"\n    if not channels:\n        return 0\n    mask = 0\n    for ch in channels:\n        mask |= 1 << int(ch)",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "mask_to_channels",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def mask_to_channels(mask):\n    \"\"\"\n    å°† bitmask è½¬å› channel åˆ—è¡¨ã€‚\n    ä¾‹å¦‚ 41 (0b101001) â†’ [0,3,5]\n    \"\"\"\n    if mask is None or mask == 0:\n        return []\n    channels = []\n    bit_pos = 0\n    while mask > 0:",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "channels_to_mask",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def channels_to_mask(channels):\n    \"\"\"\n    å°† channels åˆ—è¡¨è½¬æ¢ä¸º bitmaskã€‚\n    ä¾‹å¦‚ [0,3,5] â†’ 41 (äºŒè¿›åˆ¶ 0b101001)\n    \"\"\"\n    if not channels:\n        return 0\n    mask = 0\n    for ch in channels:\n        mask |= 1 << int(ch)",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "get_paired_data",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def get_paired_data(df_events, group_mask, char):\n    \"\"\"\n    æ ¹æ® encode_groups_binary çš„åŠ æƒç»“æœç­›é€‰äº‹ä»¶ï¼Œ\n    å¹¶è¿”å› (char) å¯¹åº”çš„ numpy æ•°ç»„ã€‚\n    \"\"\"\n    # 1. è§£ç ï¼šmask â†’ å“ªäº› group å‡ºç°\n    # ç›´æ¥åˆ©ç”¨ bit è¿ç®—ï¼šmask æ‰£å“ªä¸ª weightï¼Œå°±è¯´æ˜å“ªä¸ª group å‡ºç°\n    selected_groups = []\n    for weight, members in GROUP_WEIGHTS.items():\n        if group_mask & weight:  # bit on â†’ å·²åŒ…å«è¯¥ group",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "energy_rec",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def energy_rec(data):\n    x, y = data\n    energy = np.sqrt(np.prod([x, y], axis=0)) * 2\n    return energy\ndef lr_log_ratio(data):\n    x, y = data\n    log_ratio = np.log(x) - np.log(y)\n    return log_ratio\nclass Datas:\n    def __init__(self, cache_dir) -> None:",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "lr_log_ratio",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def lr_log_ratio(data):\n    x, y = data\n    log_ratio = np.log(x) - np.log(y)\n    return log_ratio\nclass Datas:\n    def __init__(self, cache_dir) -> None:\n        self.cache_dir = cache_dir\n        df_file = os.path.join(cache_dir, \"df.feather\")\n        event_file = os.path.join(cache_dir, \"df_events.feather\")\n        self.df = pd.read_feather(df_file)",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "hist_count_ratio",
        "kind": 2,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "def hist_count_ratio(data_a, data_b, bins):\n    counts_a, bin_edges = np.histogram(data_a, bins=bins)\n    counts_b, _ = np.histogram(data_b, bins=bins)\n    ratio = np.divide(\n        counts_a,\n        counts_b,\n        out=np.zeros_like(counts_a, dtype=float),\n        where=counts_b > 0,\n    )\n    return bin_edges, counts_a, counts_b, ratio",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "GROUP_MAP",
        "kind": 5,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "GROUP_MAP = {\n    0: 1,\n    1: 1,  # group0: channels [0,1]\n    2: 3,\n    3: 3,  # group1: channels [2,3]\n    4: 7,\n    5: 7,  # group2: channels [4,5]\n}\n# ç»„åˆæƒé‡ï¼ˆç”¨äºç»„å®Œæ•´æ€§ç¼–ç ï¼‰\nGROUP_WEIGHTS = {",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "GROUP_WEIGHTS",
        "kind": 5,
        "importPath": "waveform_analysis.core.processor",
        "description": "waveform_analysis.core.processor",
        "peekOfCode": "GROUP_WEIGHTS = {\n    1: {0, 1},  # weight 1 â†’ ç»„ {0,1}\n    3: {2, 3},  # weight 3 â†’ ç»„ {2,3}\n    7: {4, 5},  # weight 7 â†’ ç»„ {4,5}\n}\ndef encode_groups_binary(channels):\n    \"\"\"\n    ä»»æ„ç»„å‡ºç°äº†éƒ¨åˆ†æˆå‘˜ï¼ˆä¸æˆå¯¹ï¼‰ -> æ•´ä½“è¿”å› 0ï¼ˆå¼‚å¸¸ï¼‰\n    æ‰€æœ‰ç»„è¦ä¹ˆå®Œæ•´å‡ºç°ï¼Œè¦ä¹ˆå®Œå…¨ä¸å‡ºç°ã€‚\n    \"\"\"",
        "detail": "waveform_analysis.core.processor",
        "documentation": {}
    },
    {
        "label": "LandauGaussFitter",
        "kind": 6,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "class LandauGaussFitter(BaseFitter):\n    def __init__(self, x, y, fit_range, param):\n        super().__init__(x, y, fit_range, param)\n        self.mpv = param[0]\n        self.eta = param[1]\n        self.sigma = param[2]\n        self.const = param[3]\n        self.mu2 = param[4] if len(param) > 4 else 400\n        self.sigma2 = param[5] if len(param) > 5 else 80\n        self.A2 = param[6] if len(param) > 6 else 1e5",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "LandauGaussFitter2",
        "kind": 6,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "class LandauGaussFitter2(BaseFitter):\n    def __init__(self, x, y, fit_range, param):\n        super().__init__(x, y, fit_range, param)\n        self.mpv = param[0]\n    def fit_func(self, x, mpv, eta, sigma, const):\n        \"\"\"\n        Landau-Gauss åˆ†å¸ƒçš„å…·ä½“å®ç°\n        \"\"\"\n        xi = (x - mpv) / eta\n        landau_part = np.exp(-0.5 * (xi + np.exp(-xi))) / eta",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "gauss",
        "kind": 2,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "def gauss(x, mu, sigma, amp=1.0):\n    \"\"\"\n    é«˜æ–¯åˆ†å¸ƒï¼ˆå½’ä¸€åŒ–å½¢å¼ä¹˜ä»¥æŒ¯å¹…ï¼‰\n    è¿”å› amp * N(mu, sigma)(x)\n    \"\"\"\n    return amp * np.exp(-0.5 * ((x - mu) / sigma) ** 2) / (sigma * np.sqrt(2 * np.pi))\ndef landau_pdf_approx(x, mpv, eta):\n    \"\"\"\n    Landau PDF è¿‘ä¼¼ï¼ˆä¸ä¾èµ– ROOTï¼‰\n    åŸºäº ROOT çš„æ ‡å‡†å‚æ•°åŒ–ï¼šL(x; mpv, eta)",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "landau_pdf_approx",
        "kind": 2,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "def landau_pdf_approx(x, mpv, eta):\n    \"\"\"\n    Landau PDF è¿‘ä¼¼ï¼ˆä¸ä¾èµ– ROOTï¼‰\n    åŸºäº ROOT çš„æ ‡å‡†å‚æ•°åŒ–ï¼šL(x; mpv, eta)\n    ä½¿ç”¨å¸¸è§çš„æ•°å€¼é€¼è¿‘\n    \"\"\"\n    y = (x - mpv) / eta\n    # æ ‡å‡† Landau PDFï¼šexp(-0.5*(y + exp(-y)))  / eta\n    return jnp.exp(-0.5 * (y + jnp.exp(-y))) / eta\ndef landau_gauss_jax(x, mpv, eta, sigma, n_steps=100):",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "landau_gauss_jax",
        "kind": 2,
        "importPath": "waveform_analysis.fitting.models",
        "description": "waveform_analysis.fitting.models",
        "peekOfCode": "def landau_gauss_jax(x, mpv, eta, sigma, n_steps=100):\n    \"\"\"\n    ç”¨ JAX å®ç°çš„ Landau âŠ— Gaussian å·ç§¯ï¼ˆä¿®å¤ç‰ˆï¼‰\n    å‚æ•°ï¼š\n        x       : arrayï¼Œæ±‚å€¼ç‚¹ (1D)\n        mpv     : Landau çš„æœ€å¯èƒ½å€¼ (æ ‡é‡)\n        eta     : Landau å®½åº¦å‚æ•° (æ ‡é‡)\n        sigma   : é«˜æ–¯å®½åº¦ (æ ‡é‡)\n        n_steps : ç§¯åˆ†æ­¥æ•° (æ ‡é‡)\n    è¿”å›ï¼š",
        "detail": "waveform_analysis.fitting.models",
        "documentation": {}
    },
    {
        "label": "DAQRun",
        "kind": 6,
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "peekOfCode": "class DAQRun:\n    \"\"\"å•ä¸ª DAQ è¿è¡Œçš„æ•°æ®å’Œåˆ†æç±»\"\"\"\n    ALLOWED_EXTS = (\".CSV\", \".csv\")\n    CH_PATTERN = re.compile(r\"CH(\\d+)\")\n    IDX_PATTERN = re.compile(r\"_(\\d+)\\.CSV$\", re.IGNORECASE)\n    def __init__(self, run_name: str, run_path: str | Path):\n        self.run_name = run_name\n        self.run_path = str(run_path)\n        self.raw_dir = os.path.join(self.run_path, \"RAW\")\n        self.description = self._load_description()",
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "kind": 6,
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "peekOfCode": "class DAQAnalyzer:\n    \"\"\"DAQ æ•°æ®åˆ†æå™¨ï¼šç®¡ç†æ‰€æœ‰è¿è¡Œçš„ç»Ÿä¸€åˆ†æ\"\"\"\n    def __init__(self, daq_root: str | Path = \"DAQ\") -> None:\n        self.daq_root = str(daq_root)\n        self.runs: Dict[str, DAQRun] = {}\n        self.df_runs: Optional[pd.DataFrame] = None\n        self.total_bytes = 0\n    @staticmethod\n    def format_size(bytes_val: int) -> str:\n        for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:",
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass DAQRun:\n    \"\"\"å•ä¸ª DAQ è¿è¡Œçš„æ•°æ®å’Œåˆ†æç±»\"\"\"\n    ALLOWED_EXTS = (\".CSV\", \".csv\")\n    CH_PATTERN = re.compile(r\"CH(\\d+)\")\n    IDX_PATTERN = re.compile(r\"_(\\d+)\\.CSV$\", re.IGNORECASE)\n    def __init__(self, run_name: str, run_path: str | Path):\n        self.run_name = run_name\n        self.run_path = str(run_path)\n        self.raw_dir = os.path.join(self.run_path, \"RAW\")",
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "waveform_analysis.utils.daq",
        "description": "waveform_analysis.utils.daq",
        "peekOfCode": "__all__ = [\"DAQRun\", \"DAQAnalyzer\"]\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser(description=\"DAQ Analysis - CLI for quick scanning\")\n    parser.add_argument(\"--root\", type=str, default=\"DAQ\", help=\"DAQ root directory\")\n    parser.add_argument(\"--out\", type=str, default=\"daq_analysis.json\", help=\"è¾“å‡º JSON æ–‡ä»¶è·¯å¾„\")\n    args = parser.parse_args()\n    logging.basicConfig(level=logging.INFO)\n    analyzer = DAQAnalyzer(args.root)\n    analyzer.scan_all_runs()",
        "detail": "waveform_analysis.utils.daq",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "waveform_analysis.cli",
        "description": "waveform_analysis.cli",
        "peekOfCode": "def main():\n    \"\"\"ä¸»å‘½ä»¤è¡Œå…¥å£\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Waveform Analysis - æ³¢å½¢æ•°æ®å¤„ç†å·¥å…·\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nç¤ºä¾‹:\n  # å¤„ç†å•ä¸ªæ•°æ®é›†\n  waveform-process --char 50V_OV_circulation_20thr --output results.csv\n  # æŒ‡å®šæ—¶é—´çª—å£",
        "detail": "waveform_analysis.cli",
        "documentation": {}
    },
    {
        "label": "DAQRun",
        "kind": 6,
        "importPath": "DAQAnalyzer",
        "description": "DAQAnalyzer",
        "peekOfCode": "class DAQRun:\n    \"\"\"å•ä¸ª DAQ è¿è¡Œçš„æ•°æ®å’Œåˆ†æç±»\"\"\"\n    # ä»…å¤„ç† CSV æ•°æ®æ–‡ä»¶ï¼Œé¿å…è¯¯è¯» .root/.dat\n    ALLOWED_EXTS = (\".CSV\", \".csv\")\n    CH_PATTERN = re.compile(r\"CH(\\d+)\")\n    IDX_PATTERN = re.compile(r\"_(\\d+)\\.CSV$\", re.IGNORECASE)\n    def __init__(self, run_name, run_path):\n        self.run_name = run_name\n        self.run_path = run_path\n        self.raw_dir = os.path.join(run_path, \"RAW\")",
        "detail": "DAQAnalyzer",
        "documentation": {}
    },
    {
        "label": "DAQAnalyzer",
        "kind": 6,
        "importPath": "DAQAnalyzer",
        "description": "DAQAnalyzer",
        "peekOfCode": "class DAQAnalyzer:\n    \"\"\"DAQ æ•°æ®åˆ†æå™¨ï¼šç®¡ç†æ‰€æœ‰è¿è¡Œçš„ç»Ÿä¸€åˆ†æ\"\"\"\n    def __init__(self, daq_root=\"DAQ\"):\n        self.daq_root = daq_root\n        self.runs = {}  # {run_name: DAQRun}\n        self.df_runs = None\n        self.total_bytes = 0\n    @staticmethod\n    def format_size(bytes_val):\n        \"\"\"å°†å­—èŠ‚è½¬æ¢ä¸ºæ˜“è¯»æ ¼å¼\"\"\"",
        "detail": "DAQAnalyzer",
        "documentation": {}
    }
]