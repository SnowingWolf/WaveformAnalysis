# -*- coding: utf-8 -*-
"""
ä¾èµ–åˆ†ææ¨¡å— - æ’ä»¶ä¾èµ–å…³ç³»å›¾ï¼ˆDAGï¼‰åˆ†æã€‚

æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
1. é™æ€ä¾èµ–åˆ†æï¼šåŸºäº DAG ç»“æ„åˆ†æ
2. åŠ¨æ€æ€§èƒ½åˆ†æï¼šæ•´åˆå®é™…æ‰§è¡Œæ•°æ®
3. å…³é”®è·¯å¾„è¯†åˆ«ï¼šCPM ç®—æ³•
4. å¹¶è¡Œæœºä¼šè¯†åˆ«ï¼šå±‚æ¬¡åˆ†æ
5. æ€§èƒ½ç“¶é¢ˆè¯†åˆ«ï¼šå¤šç»´åº¦è¯„ä¼°
6. æ™ºèƒ½ä¼˜åŒ–å»ºè®®ï¼šè§„åˆ™å¼•æ“

ä½¿ç”¨ç¤ºä¾‹ï¼š

    from waveform_analysis.core.context import Context

    ctx = Context(enable_stats=True)
    # ... æ³¨å†Œæ’ä»¶å¹¶æ‰§è¡Œ ...

    # åˆ†æä¾èµ–å…³ç³»
    analysis = ctx.analyze_dependencies('paired_events')

    # æŸ¥çœ‹æ‘˜è¦
    print(analysis.summary())

    # å¯¼å‡ºæŠ¥å‘Š
    analysis.to_markdown('report.md')
    data = analysis.to_dict()  # å¯ä¿å­˜ä¸º JSON
"""

import json
from collections import defaultdict
from dataclasses import asdict, dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional, Set, Tuple

from waveform_analysis.core.foundation.model import EdgeModel, LineageGraphModel, build_lineage_graph
from waveform_analysis.core.foundation.utils import exporter

export, __all__ = exporter()


@export
@dataclass
class DependencyAnalysisResult:
    """ä¾èµ–åˆ†æç»“æœ"""

    # åŸºæœ¬ä¿¡æ¯
    target_name: str
    total_plugins: int
    execution_plan: List[str]  # æ‹“æ‰‘æ’åºç»“æœ

    # DAG ç»“æ„åˆ†æ
    max_depth: int  # DAG æœ€å¤§æ·±åº¦
    max_width: int  # DAG æœ€å¤§å®½åº¦
    layers: Dict[int, List[str]] = field(default_factory=dict)  # æŒ‰æ·±åº¦åˆ†å±‚

    # å…³é”®è·¯å¾„åˆ†æ
    critical_path: List[str] = field(default_factory=list)  # å…³é”®è·¯å¾„ä¸Šçš„æ’ä»¶åˆ—è¡¨
    critical_path_time: Optional[float] = None  # æ€»æ—¶é—´ï¼ˆå¦‚æœæœ‰æ€§èƒ½æ•°æ®ï¼‰

    # å¹¶è¡Œæœºä¼š
    parallel_groups: List[List[str]] = field(default_factory=list)  # å¯å¹¶è¡Œæ‰§è¡Œçš„æ’ä»¶ç»„
    parallelization_potential: float = 1.0  # ç†è®ºåŠ é€Ÿæ¯”

    # æ€§èƒ½ç“¶é¢ˆï¼ˆä»…åœ¨æœ‰ç»Ÿè®¡æ•°æ®æ—¶å¯ç”¨ï¼‰
    bottlenecks: List[Dict[str, Any]] = field(default_factory=list)
    performance_summary: Optional[Dict[str, Any]] = None

    # ä¼˜åŒ–å»ºè®®
    recommendations: List[str] = field(default_factory=list)

    # å…ƒæ•°æ®
    analyzed_at: str = field(default_factory=lambda: datetime.now().isoformat())
    has_performance_data: bool = False

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸ï¼ˆå¯JSONåºåˆ—åŒ–ï¼‰"""
        data = asdict(self)
        # ç¡®ä¿æ‰€æœ‰æ•°æ®å¯ä»¥è¢« JSON åºåˆ—åŒ–
        return data

    def to_json(self, filepath: Optional[str] = None, indent: int = 2) -> str:
        """
        è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ï¼Œå¯é€‰ä¿å­˜åˆ°æ–‡ä»¶

        Args:
            filepath: å¯é€‰çš„æ–‡ä»¶è·¯å¾„
            indent: JSON ç¼©è¿›ç©ºæ ¼æ•°

        Returns:
            JSON å­—ç¬¦ä¸²
        """
        json_str = json.dumps(self.to_dict(), indent=indent, ensure_ascii=False)

        if filepath:
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(json_str)

        return json_str

    def to_markdown(self) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        lines = []

        # æ ‡é¢˜
        lines.append(f"# ä¾èµ–åˆ†ææŠ¥å‘Šï¼š{self.target_name}\n")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {self.analyzed_at}")
        lines.append(
            f"**åˆ†ææ¨¡å¼**: {'åŠ¨æ€åˆ†æï¼ˆå«æ€§èƒ½æ•°æ®ï¼‰' if self.has_performance_data else 'é™æ€åˆ†æ'}\n"
        )

        # æ¦‚è§ˆ
        lines.append("## ğŸ“Š æ¦‚è§ˆ\n")
        lines.append(f"- **æ€»æ’ä»¶æ•°**: {self.total_plugins}")
        lines.append(f"- **DAG æ·±åº¦**: {self.max_depth}")
        lines.append(f"- **DAG å®½åº¦**: {self.max_width}")
        lines.append(f"- **æ‰§è¡Œè®¡åˆ’**: {' â†’ '.join(self.execution_plan)}\n")

        # å±‚æ¬¡ç»“æ„
        if self.layers:
            lines.append("## ğŸ—ï¸ å±‚æ¬¡ç»“æ„\n")
            for depth in sorted(self.layers.keys()):
                plugins = self.layers[depth]
                lines.append(f"**æ·±åº¦ {depth}**: {', '.join(plugins)}")
            lines.append("")

        # å…³é”®è·¯å¾„
        if self.critical_path:
            lines.append("## ğŸ¯ å…³é”®è·¯å¾„\n")
            if self.critical_path_time is not None:
                lines.append(f"**æ€»è€—æ—¶**: {self.critical_path_time:.2f} ç§’\n")

            for i, plugin in enumerate(self.critical_path, 1):
                # å°è¯•ä»æ€§èƒ½æ‘˜è¦ä¸­è·å–æ—¶é—´
                time_info = ""
                if self.performance_summary and plugin in self.performance_summary:
                    stats = self.performance_summary[plugin]
                    mean_time = stats.get("mean_time", 0)
                    percentage = (
                        stats.get("time_percentage", 0) if self.critical_path_time else 0
                    )
                    time_info = f" ({mean_time:.2f}s, {percentage:.1f}%)"
                lines.append(f"{i}. {plugin}{time_info}")
            lines.append("")

        # å¹¶è¡Œæœºä¼š
        if self.parallel_groups:
            lines.append("## âš¡ å¹¶è¡Œæœºä¼š\n")
            lines.append(
                f"**ç†è®ºåŠ é€Ÿæ¯”**: {self.parallelization_potential:.2f}x\n"
            )

            for i, group in enumerate(self.parallel_groups, 1):
                lines.append(f"### å¹¶è¡Œç»„ #{i}")
                lines.append(f"- **æ’ä»¶**: {', '.join(group)}")
                lines.append(f"- **æ’ä»¶æ•°é‡**: {len(group)}\n")

        # æ€§èƒ½ç“¶é¢ˆ
        if self.bottlenecks:
            lines.append("## ğŸ”´ æ€§èƒ½ç“¶é¢ˆ\n")

            for i, bottleneck in enumerate(self.bottlenecks, 1):
                plugin = bottleneck["plugin_name"]
                severity = bottleneck["severity"].upper()
                metrics = bottleneck["metrics"]

                severity_icon = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}.get(
                    severity, "âšª"
                )

                lines.append(f"### {severity_icon} ç“¶é¢ˆ #{i}: {plugin} [{severity}]")
                lines.append(f"- **å¹³å‡æ‰§è¡Œæ—¶é—´**: {metrics.get('mean_time', 0):.2f}s")
                lines.append(
                    f"- **æ—¶é—´å æ¯”**: {metrics.get('time_percentage', 0):.1f}%"
                )
                lines.append(
                    f"- **ç¼“å­˜å‘½ä¸­ç‡**: {metrics.get('cache_hit_rate', 0):.1%}"
                )
                lines.append(f"- **è°ƒç”¨æ¬¡æ•°**: {metrics.get('call_count', 0)}")

                if "peak_memory_mb" in metrics and metrics["peak_memory_mb"] > 0:
                    lines.append(
                        f"- **å³°å€¼å†…å­˜**: {metrics['peak_memory_mb']:.2f}MB"
                    )

                issues = bottleneck.get("issues", [])
                if issues:
                    lines.append(f"- **é—®é¢˜**: {', '.join(issues)}")

                lines.append("")

        # ä¼˜åŒ–å»ºè®®
        if self.recommendations:
            lines.append("## ğŸ’¡ ä¼˜åŒ–å»ºè®®\n")
            for i, rec in enumerate(self.recommendations, 1):
                lines.append(f"{i}. {rec}")
            lines.append("")

        return "\n".join(lines)

    def save_markdown(self, filepath: str):
        """ä¿å­˜ Markdown æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(self.to_markdown())

    def __repr__(self) -> str:
        """è¿”å›æ ¼å¼åŒ–çš„æ‘˜è¦å­—ç¬¦ä¸²ï¼Œåœ¨ Jupyter notebook ä¸­æ­£ç¡®æ˜¾ç¤ºæ¢è¡Œ"""
        return self.summary()

    def _repr_pretty_(self, p, cycle):
        """IPython ç¾åŒ–æ˜¾ç¤ºæ”¯æŒï¼Œç¡®ä¿æ¢è¡Œæ­£ç¡®æ˜¾ç¤º"""
        if cycle:
            p.text("DependencyAnalysisResult(...)")
        else:
            p.text(self.summary())

    def summary(self) -> str:
        """ç”Ÿæˆç®€è¦æ–‡æœ¬æ‘˜è¦"""
        lines = []
        lines.append(f"=== ä¾èµ–åˆ†ææ‘˜è¦ï¼š{self.target_name} ===")
        lines.append(
            f"åˆ†ææ¨¡å¼: {'åŠ¨æ€ï¼ˆå«æ€§èƒ½æ•°æ®ï¼‰' if self.has_performance_data else 'é™æ€'}"
        )
        lines.append(f"æ€»æ’ä»¶æ•°: {self.total_plugins}")
        lines.append(f"DAG æ·±åº¦: {self.max_depth}, å®½åº¦: {self.max_width}")

        if self.critical_path:
            lines.append(f"\nå…³é”®è·¯å¾„ ({len(self.critical_path)} ä¸ªæ’ä»¶):")
            path_str = " â†’ ".join(self.critical_path[:5])
            if len(self.critical_path) > 5:
                path_str += f" ... (è¿˜æœ‰ {len(self.critical_path) - 5} ä¸ª)"
            lines.append(f"  {path_str}")

            if self.critical_path_time is not None:
                lines.append(f"  æ€»è€—æ—¶: {self.critical_path_time:.2f}s")

        if self.parallel_groups:
            lines.append(f"\nå¹¶è¡Œæœºä¼š: {len(self.parallel_groups)} ç»„")
            lines.append(f"  ç†è®ºåŠ é€Ÿæ¯”: {self.parallelization_potential:.2f}x")

        if self.bottlenecks:
            lines.append(f"\næ€§èƒ½ç“¶é¢ˆ: {len(self.bottlenecks)} ä¸ª")
            high_severity = [b for b in self.bottlenecks if b["severity"] == "high"]
            if high_severity:
                lines.append(f"  é«˜ä¸¥é‡æ€§: {len(high_severity)} ä¸ª")

        if self.recommendations:
            lines.append(f"\nä¼˜åŒ–å»ºè®®: {len(self.recommendations)} æ¡")
            lines.append(f"  é¦–è¦å»ºè®®: {self.recommendations[0]}")

        return "\n".join(lines)


@export
class DependencyAnalyzer:
    """ä¾èµ–åˆ†æå™¨ - åˆ†ææ’ä»¶ä¾èµ–å…³ç³»å›¾"""

    def __init__(self, context: Any):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            context: Context å®ä¾‹
        """
        self.context = context

    def analyze(
        self,
        target_name: str,
        include_performance: bool = True,
        run_id: Optional[str] = None,
    ) -> DependencyAnalysisResult:
        """
        æ‰§è¡Œä¾èµ–åˆ†æ

        Args:
            target_name: ç›®æ ‡æ•°æ®åç§°
            include_performance: æ˜¯å¦åŒ…å«æ€§èƒ½æ•°æ®åˆ†æ
            run_id: å¯é€‰çš„ run_idï¼ˆæš‚æœªä½¿ç”¨ï¼Œä¸ºæœªæ¥æ‰©å±•é¢„ç•™ï¼‰

        Returns:
            DependencyAnalysisResult: åˆ†æç»“æœ
        """
        # 1. è·å–è¡€ç¼˜å›¾
        lineage = self.context.get_lineage(target_name)
        plugins = {name: self.context._plugins.get(name) for name in lineage.keys()}
        graph = build_lineage_graph(lineage, target_name, plugins)

        # 2. è·å–æ‰§è¡Œè®¡åˆ’ï¼ˆæ‹“æ‰‘æ’åºï¼‰
        execution_plan = self._get_execution_plan(target_name)

        # 3. é™æ€ç»“æ„åˆ†æ
        static_analysis = self._analyze_static_structure(graph, execution_plan)

        # 4. æ€§èƒ½æ•°æ®åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
        performance_data = None
        has_performance = False

        if include_performance and self.context.stats_collector:
            if self.context.stats_collector.is_enabled():
                performance_data = self._get_performance_data(execution_plan)
                has_performance = bool(performance_data)

        # 5. å…³é”®è·¯å¾„åˆ†æ
        if has_performance and performance_data:
            critical_path, critical_path_time = self._find_critical_path_dynamic(
                graph, execution_plan, performance_data
            )
        else:
            critical_path = self._find_critical_path_static(graph, execution_plan)
            critical_path_time = None

        # 6. å¹¶è¡Œæœºä¼šè¯†åˆ«
        parallel_groups = self._find_parallel_opportunities(graph, execution_plan)
        parallelization_potential = self._calculate_parallelization_potential(
            parallel_groups, performance_data
        )

        # 7. æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
        bottlenecks = []
        if has_performance and performance_data:
            bottlenecks = self._identify_bottlenecks(
                performance_data, critical_path, execution_plan
            )

        # 8. ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = self._generate_recommendations(
            static_analysis,
            critical_path,
            critical_path_time,
            parallel_groups,
            parallelization_potential,
            bottlenecks,
            has_performance,
        )

        # 9. æ„å»ºç»“æœ
        result = DependencyAnalysisResult(
            target_name=target_name,
            total_plugins=len(execution_plan),
            execution_plan=execution_plan,
            max_depth=static_analysis["max_depth"],
            max_width=static_analysis["max_width"],
            layers=static_analysis["layers"],
            critical_path=critical_path,
            critical_path_time=critical_path_time,
            parallel_groups=parallel_groups,
            parallelization_potential=parallelization_potential,
            bottlenecks=bottlenecks,
            performance_summary=performance_data,
            recommendations=recommendations,
            has_performance_data=has_performance,
        )

        return result

    def _get_execution_plan(self, target_name: str) -> List[str]:
        """è·å–æ‰§è¡Œè®¡åˆ’ï¼ˆæ‹“æ‰‘æ’åºï¼‰"""
        # resolve_dependencies is a method of PluginMixin, called via context
        plan = self.context.resolve_dependencies(target_name)
        return plan

    def _analyze_static_structure(
        self, graph: LineageGraphModel, execution_plan: List[str]
    ) -> Dict[str, Any]:
        """
        é™æ€ä¾èµ–åˆ†æï¼ˆä¸éœ€è¦æ€§èƒ½æ•°æ®ï¼‰

        åˆ†æå†…å®¹ï¼š
        1. DAG å±‚æ¬¡ç»“æ„ï¼ˆæ·±åº¦ã€å®½åº¦ï¼‰
        2. æ¯å±‚çš„æ’ä»¶æ•°é‡
        3. åˆ†æ”¯å’Œæ±‡èšç‚¹
        """
        # æŒ‰å±‚æ¬¡åˆ†ç»„
        layers = defaultdict(list)
        for node_id, node in graph.nodes.items():
            if not node_id.startswith(("IN::", "OUT::")):  # æ’é™¤ç«¯å£èŠ‚ç‚¹
                layers[node.depth].append(node_id)

        max_depth = max(layers.keys()) if layers else 0
        max_width = max(len(plugins) for plugins in layers.values()) if layers else 0

        return {
            "max_depth": max_depth,
            "max_width": max_width,
            "layers": dict(layers),
        }

    def _get_performance_data(
        self, execution_plan: List[str]
    ) -> Optional[Dict[str, Any]]:
        """è·å–æ€§èƒ½ç»Ÿè®¡æ•°æ®"""
        if not self.context.stats_collector:
            return None

        stats = self.context.stats_collector.get_statistics()
        if not stats:
            return None

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        performance_data = {}
        for plugin_name in execution_plan:
            if plugin_name in stats:
                stat = stats[plugin_name]
                performance_data[plugin_name] = {
                    "mean_time": stat.mean_time,
                    "total_calls": stat.total_calls,
                    "cache_hit_rate": stat.cache_hit_rate(),
                    "peak_memory_mb": stat.peak_memory_mb,
                }

        return performance_data if performance_data else None

    def _find_critical_path_static(
        self, graph: LineageGraphModel, execution_plan: List[str]
    ) -> List[str]:
        """
        åŸºäº DAG æ·±åº¦çš„å…³é”®è·¯å¾„ï¼ˆé™æ€åˆ†æï¼‰

        å‡è®¾æ‰€æœ‰æ’ä»¶æƒé‡ç›¸ç­‰ï¼Œå…³é”®è·¯å¾„ = æœ€é•¿çš„ä¾èµ–é“¾
        """
        # æ‰¾åˆ°æœ€æ·±çš„èŠ‚ç‚¹ï¼ˆæ’é™¤ç«¯å£èŠ‚ç‚¹ï¼‰
        plugin_nodes = {
            nid: node
            for nid, node in graph.nodes.items()
            if not nid.startswith(("IN::", "OUT::"))
        }

        if not plugin_nodes:
            return []

        deepest_node = max(plugin_nodes.values(), key=lambda n: n.depth)

        # å›æº¯åˆ°æ ¹èŠ‚ç‚¹
        path = []
        current = deepest_node.key

        while current:
            path.append(current)
            # æ‰¾åˆ°æ·±åº¦æœ€å¤§çš„çˆ¶èŠ‚ç‚¹
            parent = self._find_deepest_parent(graph, current)
            if parent == current:  # é¿å…æ­»å¾ªç¯
                break
            current = parent

        return list(reversed(path))

    def _find_deepest_parent(
        self, graph: LineageGraphModel, node_id: str
    ) -> Optional[str]:
        """æ‰¾åˆ°èŠ‚ç‚¹çš„æ·±åº¦æœ€å¤§çš„çˆ¶èŠ‚ç‚¹"""
        node = graph.nodes.get(node_id)
        if not node or not node.in_ports:
            return None

        # æ‰¾åˆ°æ‰€æœ‰è¾“å…¥è¾¹
        parent_nodes = set()
        for edge in graph.edges:
            for port in node.in_ports:
                if edge.target_port_id == port.id:
                    # æ‰¾åˆ°æºèŠ‚ç‚¹
                    for src_node_id, src_node in graph.nodes.items():
                        for src_port in src_node.out_ports:
                            if src_port.id == edge.source_port_id:
                                parent_nodes.add(src_node_id)

        if not parent_nodes:
            return None

        # è¿”å›æ·±åº¦æœ€å¤§çš„çˆ¶èŠ‚ç‚¹
        parents_with_depth = [
            (pid, graph.nodes[pid].depth)
            for pid in parent_nodes
            if pid in graph.nodes
        ]
        if not parents_with_depth:
            return None

        return max(parents_with_depth, key=lambda x: x[1])[0]

    def _find_critical_path_dynamic(
        self,
        graph: LineageGraphModel,
        execution_plan: List[str],
        performance_data: Dict[str, Any],
    ) -> Tuple[List[str], float]:
        """
        åŸºäºå®é™…æ‰§è¡Œæ—¶é—´çš„å…³é”®è·¯å¾„ï¼ˆCPMç®—æ³•ï¼‰

        ä½¿ç”¨å…³é”®è·¯å¾„æ³•ï¼ˆCritical Path Methodï¼‰è®¡ç®—
        """
        # 1. æ„å»ºä¾èµ–å…³ç³»å›¾ï¼ˆä»…åŒ…å«æ’ä»¶èŠ‚ç‚¹ï¼‰
        dependencies = self._build_dependency_graph(graph, execution_plan)

        # 2. å‰å‘è®¡ç®—æœ€æ—©å®Œæˆæ—¶é—´ï¼ˆES - Earliest Startï¼‰
        earliest_start = {}
        earliest_finish = {}

        for node_id in execution_plan:
            # ES = max(EF of all predecessors)
            predecessors = dependencies.get(node_id, {}).get("predecessors", [])
            es = max([earliest_finish.get(p, 0) for p in predecessors], default=0)

            # è·å–æ‰§è¡Œæ—¶é—´
            duration = performance_data.get(node_id, {}).get("mean_time", 0)
            ef = es + duration

            earliest_start[node_id] = es
            earliest_finish[node_id] = ef

        # 3. åå‘è®¡ç®—æœ€æ™šå¼€å§‹æ—¶é—´ï¼ˆLS - Latest Startï¼‰
        target = execution_plan[-1] if execution_plan else None
        if not target:
            return [], 0.0

        latest_start = {target: earliest_start.get(target, 0)}
        latest_finish = {target: earliest_finish.get(target, 0)}

        for node_id in reversed(execution_plan):
            successors = dependencies.get(node_id, {}).get("successors", [])
            if successors:
                lf = min(
                    [latest_start.get(s, float("inf")) for s in successors],
                    default=latest_finish.get(target, 0),
                )
            else:
                lf = latest_finish.get(target, 0)

            duration = performance_data.get(node_id, {}).get("mean_time", 0)
            ls = lf - duration

            latest_start[node_id] = ls
            latest_finish[node_id] = lf

        # 4. è®¡ç®—æ¾å¼›æ—¶é—´ï¼ˆSlack = LS - ESï¼‰
        slack = {
            n: latest_start.get(n, 0) - earliest_start.get(n, 0)
            for n in execution_plan
        }

        # 5. æ¾å¼›æ—¶é—´æ¥è¿‘0çš„èŠ‚ç‚¹å³å…³é”®è·¯å¾„
        critical_nodes = [n for n, s in slack.items() if abs(s) < 0.001]

        # 6. æŒ‰æ‰§è¡Œé¡ºåºæ’åº
        critical_path = [n for n in execution_plan if n in critical_nodes]
        total_time = earliest_finish.get(target, 0)

        return critical_path, total_time

    def _build_dependency_graph(
        self, graph: LineageGraphModel, execution_plan: List[str]
    ) -> Dict[str, Dict[str, List[str]]]:
        """æ„å»ºç®€åŒ–çš„ä¾èµ–å…³ç³»å›¾"""
        dependencies = {node: {"predecessors": [], "successors": []} for node in execution_plan}

        for node_id in execution_plan:
            node = graph.nodes.get(node_id)
            if not node:
                continue

            # æ‰¾åˆ°æ‰€æœ‰å‰é©±èŠ‚ç‚¹
            for edge in graph.edges:
                for in_port in node.in_ports:
                    if edge.target_port_id == in_port.id:
                        # æ‰¾åˆ°æºèŠ‚ç‚¹
                        for src_id, src_node in graph.nodes.items():
                            if src_id in execution_plan:
                                for out_port in src_node.out_ports:
                                    if out_port.id == edge.source_port_id:
                                        if src_id not in dependencies[node_id]["predecessors"]:
                                            dependencies[node_id]["predecessors"].append(src_id)
                                        if node_id not in dependencies[src_id]["successors"]:
                                            dependencies[src_id]["successors"].append(node_id)

        return dependencies

    def _find_parallel_opportunities(
        self, graph: LineageGraphModel, execution_plan: List[str]
    ) -> List[List[str]]:
        """
        è¯†åˆ«å¯å¹¶è¡Œæ‰§è¡Œçš„æ’ä»¶ç»„

        åŸç†ï¼šåŒä¸€å±‚ï¼ˆdepthç›¸åŒï¼‰ä¸”æ— ç›´æ¥ä¾èµ–å…³ç³»çš„æ’ä»¶å¯å¹¶è¡Œ
        """
        # æŒ‰æ·±åº¦åˆ†ç»„
        layers = defaultdict(list)
        for node_id, node in graph.nodes.items():
            if node_id in execution_plan:  # åªè€ƒè™‘æ’ä»¶èŠ‚ç‚¹
                layers[node.depth].append(node_id)

        parallel_groups = []

        for depth, plugins in layers.items():
            if len(plugins) > 1:
                # è¯¥å±‚æœ‰å¤šä¸ªæ’ä»¶ï¼Œæ£€æŸ¥å®ƒä»¬æ˜¯å¦çœŸçš„ç‹¬ç«‹
                # ç®€åŒ–ç‰ˆæœ¬ï¼šå‡è®¾åŒä¸€å±‚çš„æ’ä»¶éƒ½å¯ä»¥å¹¶è¡Œ
                parallel_groups.append(sorted(plugins))

        return [g for g in parallel_groups if len(g) > 1]

    def _calculate_parallelization_potential(
        self,
        parallel_groups: List[List[str]],
        performance_data: Optional[Dict[str, Any]],
    ) -> float:
        """
        è®¡ç®—ç†è®ºåŠ é€Ÿæ¯”

        Speedup = T_sequential / T_parallel
        """
        if not parallel_groups:
            return 1.0

        if not performance_data:
            # é™æ€ä¼°ç®—ï¼šå‡è®¾å‡åŒ€åˆ†å¸ƒ
            max_group_size = max(len(g) for g in parallel_groups)
            return float(max_group_size)

        # åŠ¨æ€è®¡ç®—ï¼šåŸºäºå®é™…æ—¶é—´
        total_sequential = sum(
            data.get("mean_time", 0) for data in performance_data.values()
        )

        if total_sequential == 0:
            return 1.0

        # è®¡ç®—å¹¶è¡Œæ‰§è¡Œæ—¶é—´ï¼ˆæ¯ç»„å–æœ€å¤§ï¼‰
        total_parallel = total_sequential
        for group in parallel_groups:
            group_times = [
                performance_data.get(p, {}).get("mean_time", 0) for p in group
            ]
            if group_times:
                saved_time = sum(group_times) - max(group_times)
                total_parallel -= saved_time

        return total_sequential / total_parallel if total_parallel > 0 else 1.0

    def _identify_bottlenecks(
        self,
        performance_data: Dict[str, Any],
        critical_path: List[str],
        execution_plan: List[str],
    ) -> List[Dict[str, Any]]:
        """
        è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ

        ç“¶é¢ˆåˆ¤æ–­è§„åˆ™ï¼š
        1. æ‰§è¡Œæ—¶é—´å æ¯” > 20% â†’ high severity
        2. åœ¨å…³é”®è·¯å¾„ä¸Š â†’ æå‡ä¼˜å…ˆçº§
        3. ç¼“å­˜å‘½ä¸­ç‡ < 30% â†’ ç¼“å­˜é—®é¢˜
        4. é¢‘ç¹è°ƒç”¨ä¸”å•æ¬¡è€—æ—¶é•¿ â†’ ä¼˜åŒ–ç›®æ ‡
        5. å†…å­˜ä½¿ç”¨ > 1GB â†’ å†…å­˜ç“¶é¢ˆ
        """
        total_time = sum(
            data.get("mean_time", 0) * data.get("total_calls", 1)
            for data in performance_data.values()
        )

        if total_time == 0:
            return []

        bottlenecks = []

        for plugin_name, data in performance_data.items():
            mean_time = data.get("mean_time", 0)
            total_calls = data.get("total_calls", 1)
            cache_hit_rate = data.get("cache_hit_rate", 1.0)
            peak_memory = data.get("peak_memory_mb", 0)

            plugin_total_time = mean_time * total_calls
            time_percentage = (plugin_total_time / total_time * 100) if total_time > 0 else 0

            issues = []
            severity = "low"

            # è§„åˆ™1ï¼šæ‰§è¡Œæ—¶é—´å æ¯”é«˜
            if time_percentage > 20:
                issues.append("execution_time")
                severity = "high"
            elif time_percentage > 10:
                issues.append("execution_time")
                severity = "medium"

            # è§„åˆ™2ï¼šç¼“å­˜å‘½ä¸­ç‡ä½
            if cache_hit_rate < 0.3 and total_calls > 5:
                issues.append("cache_miss")
                if severity == "low":
                    severity = "medium"

            # è§„åˆ™3ï¼šå†…å­˜ä½¿ç”¨é«˜
            if peak_memory > 1024:  # > 1GB
                issues.append("memory")
                if severity == "low":
                    severity = "medium"

            # è§„åˆ™4ï¼šåœ¨å…³é”®è·¯å¾„ä¸Š
            if plugin_name in critical_path:
                issues.append("critical_path")
                # æå‡ä¸¥é‡æ€§ç­‰çº§
                if severity == "low":
                    severity = "medium"
                elif severity == "medium":
                    severity = "high"

            # è§„åˆ™5ï¼šé¢‘ç¹è°ƒç”¨
            if total_calls > 10 and mean_time > 1.0:
                issues.append("frequency")

            if issues:
                bottlenecks.append(
                    {
                        "plugin_name": plugin_name,
                        "severity": severity,
                        "issues": issues,
                        "metrics": {
                            "mean_time": mean_time,
                            "time_percentage": time_percentage,
                            "cache_hit_rate": cache_hit_rate,
                            "call_count": total_calls,
                            "peak_memory_mb": peak_memory,
                        },
                    }
                )

        # æŒ‰ä¸¥é‡æ€§å’Œæ—¶é—´å æ¯”æ’åº
        severity_order = {"high": 0, "medium": 1, "low": 2}
        bottlenecks.sort(
            key=lambda x: (
                severity_order[x["severity"]],
                -x["metrics"]["time_percentage"],
            )
        )

        return bottlenecks

    def _generate_recommendations(
        self,
        static_analysis: Dict[str, Any],
        critical_path: List[str],
        critical_path_time: Optional[float],
        parallel_groups: List[List[str]],
        parallelization_potential: float,
        bottlenecks: List[Dict[str, Any]],
        has_performance: bool,
    ) -> List[str]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # å»ºè®®1ï¼šå…³é”®è·¯å¾„ä¼˜åŒ–
        if critical_path and has_performance:
            top_critical = critical_path[:3]
            time_info = (
                f"ï¼ˆæ€»è€—æ—¶ {critical_path_time:.2f}sï¼‰" if critical_path_time else ""
            )
            recommendations.append(
                f"ğŸ¯ å…³é”®è·¯å¾„ä¼˜åŒ–ï¼šé‡ç‚¹å…³æ³¨ {', '.join(top_critical)}{time_info}ï¼Œ"
                f"å®ƒä»¬å†³å®šäº†æ•´ä½“æ‰§è¡Œæ—¶é—´"
            )

        # å»ºè®®2ï¼šå¹¶è¡Œæ‰§è¡Œ
        if parallel_groups and parallelization_potential > 1.2:
            for i, group in enumerate(parallel_groups[:3], 1):
                recommendations.append(
                    f"âš¡ å¹¶è¡Œæœºä¼š #{i}ï¼š{', '.join(group)} å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Œ"
                    f"é¢„è®¡åŠ é€Ÿ {len(group):.1f}x"
                )

        # å»ºè®®3ï¼šç“¶é¢ˆä¼˜åŒ–ï¼ˆæŒ‰ä¸¥é‡æ€§ï¼‰
        for i, bottleneck in enumerate(bottlenecks[:5], 1):
            plugin = bottleneck["plugin_name"]
            issues = bottleneck["issues"]
            metrics = bottleneck["metrics"]
            severity_icon = "ğŸ”´" if bottleneck["severity"] == "high" else "ğŸŸ¡"

            if "execution_time" in issues:
                recommendations.append(
                    f"{severity_icon} ç“¶é¢ˆ #{i}: {plugin} å æ€»æ‰§è¡Œæ—¶é—´ "
                    f"{metrics['time_percentage']:.1f}%ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–å¯ç”¨ç¼“å­˜"
                )

            if "cache_miss" in issues:
                recommendations.append(
                    f"ğŸ’¾ ç¼“å­˜ä¼˜åŒ–: {plugin} ç¼“å­˜å‘½ä¸­ç‡ä»… "
                    f"{metrics['cache_hit_rate']:.1%}ï¼Œæ£€æŸ¥ç¼“å­˜å¤±æ•ˆåŸå› "
                )

            if "memory" in issues:
                recommendations.append(
                    f"ğŸ§  å†…å­˜ä¼˜åŒ–: {plugin} å³°å€¼å†…å­˜ "
                    f"{metrics['peak_memory_mb']:.1f}MBï¼Œè€ƒè™‘åˆ†å—å¤„ç†æˆ–æµå¼å¤„ç†"
                )

        # å»ºè®®4ï¼šæ¶æ„ä¼˜åŒ–
        max_depth = static_analysis.get("max_depth", 0)
        max_width = static_analysis.get("max_width", 0)

        if max_depth > 10:
            recommendations.append(
                f"ğŸ“Š æ¶æ„å»ºè®®ï¼šä¾èµ–é“¾æ·±åº¦è¾¾ {max_depth} å±‚ï¼Œ"
                f"è€ƒè™‘åˆå¹¶éƒ¨åˆ†æ’ä»¶ä»¥å‡å°‘å¼€é”€"
            )

        if max_width > 5:
            recommendations.append(
                f"ğŸŒŠ å¹¶è¡Œæ¶æ„ï¼šæœ€å¤§å®½åº¦ {max_width}ï¼Œ"
                f"ç¡®ä¿ä½¿ç”¨è¶³å¤Ÿçš„ workers æ”¯æŒå¹¶è¡Œæ‰§è¡Œ"
            )

        # å¦‚æœæ²¡æœ‰æ€§èƒ½æ•°æ®ï¼Œç»™å‡ºæç¤º
        if not has_performance:
            recommendations.append(
                "ğŸ“ˆ æ•°æ®æ”¶é›†å»ºè®®ï¼šå¯ç”¨æ€§èƒ½ç»Ÿè®¡ï¼ˆenable_stats=Trueï¼‰ä»¥è·å¾—æ›´è¯¦ç»†çš„åˆ†æå’Œå»ºè®®"
            )

        return recommendations
