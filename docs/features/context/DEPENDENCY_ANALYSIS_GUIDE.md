**å¯¼èˆª**: [æ–‡æ¡£ä¸­å¿ƒ](../../README.md) > [åŠŸèƒ½ç‰¹æ€§](../README.md) > [Context åŠŸèƒ½](README.md) > ä¾èµ–åˆ†æ

---

# ä¾èµ–åˆ†æåŠŸèƒ½ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£å±•ç¤ºå¦‚ä½•ä½¿ç”¨ WaveformAnalysis çš„ä¾èµ–åˆ†æåŠŸèƒ½ã€‚

---

## ğŸ“– åŠŸèƒ½æ¦‚è¿°

ä¾èµ–åˆ†æåŠŸèƒ½å¯ä»¥å¸®åŠ©æ‚¨ï¼š
- ğŸ” **ç†è§£æ•°æ®æµ**ï¼šå¯è§†åŒ–æ’ä»¶ä¹‹é—´çš„ä¾èµ–å…³ç³»
- âš¡ **è¯†åˆ«å¹¶è¡Œæœºä¼š**ï¼šå‘ç°å¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„æ’ä»¶
- ğŸ¯ **æ‰¾åˆ°å…³é”®è·¯å¾„**ï¼šè¯†åˆ«å½±å“æ•´ä½“æ€§èƒ½çš„ç“¶é¢ˆ
- ğŸ“Š **æ€§èƒ½åˆ†æ**ï¼šåŸºäºå®é™…æ‰§è¡Œæ•°æ®åˆ†ææ€§èƒ½
- ğŸ’¡ **ä¼˜åŒ–å»ºè®®**ï¼šè·å¾—æ™ºèƒ½çš„ä¼˜åŒ–å»ºè®®

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€åˆ†æï¼ˆé™æ€ï¼‰

ä¸éœ€è¦æ€§èƒ½æ•°æ®ä¹Ÿèƒ½è¿›è¡ŒåŸºæœ¬çš„ä¾èµ–åˆ†æï¼š

```python
from waveform_analysis.core.context import Context

# åˆ›å»º Context å¹¶æ³¨å†Œæ’ä»¶
ctx = Context()
# ... æ³¨å†Œæ’ä»¶ ...

# æ‰§è¡Œé™æ€åˆ†æ
analysis = ctx.analyze_dependencies(
    'paired_events',
    include_performance=False  # ä¸ä½¿ç”¨æ€§èƒ½æ•°æ®
)

# æŸ¥çœ‹ç®€è¦æ‘˜è¦
print(analysis.summary())
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
=== ä¾èµ–åˆ†ææ‘˜è¦ï¼špaired_events ===
åˆ†ææ¨¡å¼: é™æ€
æ€»æ’ä»¶æ•°: 7
DAG æ·±åº¦: 6, å®½åº¦: 2

å…³é”®è·¯å¾„ (6 ä¸ªæ’ä»¶):
  raw_files â†’ waveforms â†’ st_waveforms â†’ features â†’ dataframe â†’ paired_events

å¹¶è¡Œæœºä¼š: 2 ç»„
  ç†è®ºåŠ é€Ÿæ¯”: 2.00x

ä¼˜åŒ–å»ºè®®: 3 æ¡
  é¦–è¦å»ºè®®: âš¡ å¹¶è¡Œæœºä¼š #1ï¼špeaks, charges å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Œé¢„è®¡åŠ é€Ÿ 2.0x
```

### 2. æ€§èƒ½åˆ†æï¼ˆåŠ¨æ€ï¼‰

å¯ç”¨æ€§èƒ½ç»Ÿè®¡åï¼Œå¯ä»¥è·å¾—æ›´è¯¦ç»†çš„åˆ†æï¼š

```python
from waveform_analysis.core.context import Context

# å¯ç”¨æ€§èƒ½ç»Ÿè®¡
ctx = Context(
    enable_stats=True,
    stats_mode='detailed'  # 'basic' æˆ– 'detailed'
)
# ... æ³¨å†Œæ’ä»¶å¹¶æ‰§è¡Œæ•°æ®å¤„ç† ...

# æ‰§è¡ŒåŠ¨æ€åˆ†æï¼ˆåŒ…å«æ€§èƒ½æ•°æ®ï¼‰
analysis = ctx.analyze_dependencies(
    'paired_events',
    include_performance=True
)

# æŸ¥çœ‹è¯¦ç»†æ‘˜è¦
print(analysis.summary())

# æŸ¥çœ‹ç“¶é¢ˆåˆ—è¡¨
print("\næ€§èƒ½ç“¶é¢ˆ:")
for bottleneck in analysis.bottlenecks:
    print(f"  {bottleneck['severity']}: {bottleneck['plugin_name']}")
    print(f"    é—®é¢˜: {', '.join(bottleneck['issues'])}")
    print(f"    æ—¶é—´å æ¯”: {bottleneck['metrics']['time_percentage']:.1f}%")

# æŸ¥çœ‹æ‰€æœ‰ä¼˜åŒ–å»ºè®®
print("\nä¼˜åŒ–å»ºè®®:")
for i, rec in enumerate(analysis.recommendations, 1):
    print(f"  {i}. {rec}")
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
=== ä¾èµ–åˆ†ææ‘˜è¦ï¼špaired_events ===
åˆ†ææ¨¡å¼: åŠ¨æ€ï¼ˆå«æ€§èƒ½æ•°æ®ï¼‰
æ€»æ’ä»¶æ•°: 7
DAG æ·±åº¦: 6, å®½åº¦: 2

å…³é”®è·¯å¾„ (4 ä¸ªæ’ä»¶):
  waveforms â†’ grouped_events â†’ st_waveforms â†’ features
  æ€»è€—æ—¶: 15.23s

å¹¶è¡Œæœºä¼š: 2 ç»„
  ç†è®ºåŠ é€Ÿæ¯”: 1.85x

æ€§èƒ½ç“¶é¢ˆ: 2 ä¸ª
  é«˜ä¸¥é‡æ€§: 1 ä¸ª

ä¼˜åŒ–å»ºè®®: 5 æ¡
  é¦–è¦å»ºè®®: ğŸ¯ å…³é”®è·¯å¾„ä¼˜åŒ–ï¼šé‡ç‚¹å…³æ³¨ waveforms, grouped_events, st_waveformsï¼ˆæ€»è€—æ—¶ 15.23sï¼‰

æ€§èƒ½ç“¶é¢ˆ:
  high: waveforms
    é—®é¢˜: execution_time, cache_miss, critical_path
    æ—¶é—´å æ¯”: 55.8%
  medium: grouped_events
    é—®é¢˜: execution_time, critical_path
    æ—¶é—´å æ¯”: 21.0%

ä¼˜åŒ–å»ºè®®:
  1. ğŸ¯ å…³é”®è·¯å¾„ä¼˜åŒ–ï¼šé‡ç‚¹å…³æ³¨ waveforms, grouped_events, st_waveformsï¼ˆæ€»è€—æ—¶ 15.23sï¼‰ï¼Œå®ƒä»¬å†³å®šäº†æ•´ä½“æ‰§è¡Œæ—¶é—´
  2. âš¡ å¹¶è¡Œæœºä¼š #1ï¼špeaks, charges å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Œé¢„è®¡åŠ é€Ÿ 2.0x
  3. ğŸ”´ ç“¶é¢ˆ #1: waveforms å æ€»æ‰§è¡Œæ—¶é—´ 55.8%ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–å¯ç”¨ç¼“å­˜
  4. ğŸ’¾ ç¼“å­˜ä¼˜åŒ–: waveforms ç¼“å­˜å‘½ä¸­ç‡ä»… 15.0%ï¼Œæ£€æŸ¥ç¼“å­˜å¤±æ•ˆåŸå› 
  5. ğŸŸ¡ ç“¶é¢ˆ #2: grouped_events å æ€»æ‰§è¡Œæ—¶é—´ 21.0%ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–å¯ç”¨ç¼“å­˜
```

## ğŸ“Š å¯¼å‡ºæŠ¥å‘Š

### å¯¼å‡ºä¸º Markdown

```python
# ç”Ÿæˆ Markdown æŠ¥å‘Š
analysis.to_markdown()  # è¿”å›å­—ç¬¦ä¸²

# æˆ–è€…ç›´æ¥ä¿å­˜åˆ°æ–‡ä»¶
analysis.save_markdown('dependency_report.md')
```

ç”Ÿæˆçš„ Markdown æŠ¥å‘ŠåŒ…å«ï¼š
- ğŸ“Š æ¦‚è§ˆä¿¡æ¯
- ğŸ—ï¸ å±‚æ¬¡ç»“æ„
- ğŸ¯ å…³é”®è·¯å¾„è¯¦æƒ…
- âš¡ å¹¶è¡Œæœºä¼šåˆ—è¡¨
- ğŸ”´ æ€§èƒ½ç“¶é¢ˆåˆ†æ
- ğŸ’¡ ä¼˜åŒ–å»ºè®®

### å¯¼å‡ºä¸º JSON

```python
# è½¬æ¢ä¸ºå­—å…¸ï¼ˆå¯ä¿å­˜ä¸º JSONï¼‰
data = analysis.to_dict()

# æˆ–è€…ç›´æ¥ä¿å­˜ä¸º JSON æ–‡ä»¶
analysis.to_json('dependency_analysis.json', indent=2)
```

JSON æ ¼å¼é€‚åˆï¼š
- ç¨‹åºåŒ–å¤„ç†
- é›†æˆåˆ°CI/CDæµç¨‹
- æ€§èƒ½è¶‹åŠ¿è¿½è¸ª
- è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆ

## ğŸ¨ å¯è§†åŒ–å¢å¼º

ç»“åˆä¾èµ–å›¾å¯è§†åŒ–ï¼Œé«˜äº®æ˜¾ç¤ºåˆ†æç»“æœï¼š

```python
from waveform_analysis.utils.visualization import plot_lineage_labview

# æ‰§è¡Œåˆ†æ
analysis = ctx.analyze_dependencies('paired_events')

# å¯è§†åŒ–å¹¶é«˜äº®å…³é”®è·¯å¾„å’Œç“¶é¢ˆ
plot_lineage_labview(
    lineage=ctx.get_lineage('paired_events'),
    target_name='paired_events',
    context=ctx,
    analysis_result=analysis,  # ä¼ å…¥åˆ†æç»“æœ
    highlight_critical_path=True,  # é«˜äº®å…³é”®è·¯å¾„ï¼ˆçº¢è‰²ç²—è¾¹æ¡†ï¼‰
    highlight_bottlenecks=True,    # é«˜äº®ç“¶é¢ˆèŠ‚ç‚¹ï¼ˆçº¢/æ©™/é»„èƒŒæ™¯ï¼‰
    highlight_parallel_groups=True, # æ ‡è®°å¹¶è¡Œç»„ï¼ˆå½©è‰²å¾½ç« ï¼‰
    interactive=True  # å¯ç”¨äº¤äº’å¼åŠŸèƒ½
)
```

å¯è§†åŒ–ç‰¹æ€§ï¼š
- ğŸ”´ **å…³é”®è·¯å¾„**ï¼šçº¢è‰²ç²—è¾¹æ¡†
- ğŸŸ¥ **é«˜ä¸¥é‡æ€§ç“¶é¢ˆ**ï¼šçº¢è‰²èƒŒæ™¯ + çº¢è‰²è¾¹æ¡†
- ğŸŸ§ **ä¸­ä¸¥é‡æ€§ç“¶é¢ˆ**ï¼šæ©™è‰²èƒŒæ™¯ + æ©™è‰²è¾¹æ¡†
- ğŸŸ¨ **ä½ä¸¥é‡æ€§ç“¶é¢ˆ**ï¼šé»„è‰²èƒŒæ™¯
- ğŸ¨ **å¹¶è¡Œç»„**ï¼šå³ä¸Šè§’å¸¦é¢œè‰²å¾½ç« ï¼ˆP1, P2, ...ï¼‰
- ğŸ–±ï¸ **äº¤äº’å¼**ï¼šé¼ æ ‡æ‚¬åœæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

## ğŸ’¼ å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šæ–°é¡¹ç›®ç†è§£æ•°æ®æµ

```python
# 1. é™æ€åˆ†æå¿«é€Ÿç†è§£
analysis = ctx.analyze_dependencies('final_output', include_performance=False)
print(analysis.summary())

# 2. æŸ¥çœ‹å±‚æ¬¡ç»“æ„
for depth, plugins in analysis.layers.items():
    print(f"æ·±åº¦ {depth}: {', '.join(plugins)}")

# 3. å¯¼å‡ºæ–‡æ¡£
analysis.save_markdown('project_architecture.md')
```

### åœºæ™¯ 2ï¼šæ€§èƒ½è°ƒä¼˜

```python
# 1. å¯ç”¨è¯¦ç»†æ€§èƒ½ç»Ÿè®¡
ctx = Context(enable_stats=True, stats_mode='detailed')
# ... æ‰§è¡Œæ•°æ®å¤„ç† ...

# 2. åˆ†æç“¶é¢ˆ
analysis = ctx.analyze_dependencies('final_output')

# 3. æŒ‰ä¸¥é‡æ€§å¤„ç†ç“¶é¢ˆ
for bottleneck in analysis.bottlenecks:
    if bottleneck['severity'] == 'high':
        plugin = bottleneck['plugin_name']
        issues = bottleneck['issues']

        if 'cache_miss' in issues:
            print(f"æ£€æŸ¥ {plugin} çš„ç¼“å­˜é…ç½®")
        if 'memory' in issues:
            print(f"ä¼˜åŒ– {plugin} çš„å†…å­˜ä½¿ç”¨")
        if 'execution_time' in issues:
            print(f"ä¼˜åŒ– {plugin} çš„ç®—æ³•")

# 4. éªŒè¯ä¼˜åŒ–æ•ˆæœ
# ... åº”ç”¨ä¼˜åŒ–æªæ–½ ...
analysis_after = ctx.analyze_dependencies('final_output')
print(f"ä¼˜åŒ–å‰: {analysis.critical_path_time:.2f}s")
print(f"ä¼˜åŒ–å: {analysis_after.critical_path_time:.2f}s")
```

### åœºæ™¯ 3ï¼šå¹¶è¡Œæ‰§è¡Œè§„åˆ’

```python
# 1. è¯†åˆ«å¹¶è¡Œæœºä¼š
analysis = ctx.analyze_dependencies('final_output')

# 2. æŸ¥çœ‹å¯å¹¶è¡Œæ’ä»¶
for i, group in enumerate(analysis.parallel_groups, 1):
    print(f"\nå¹¶è¡Œç»„ {i}:")
    print(f"  æ’ä»¶: {', '.join(group)}")
    print(f"  æ’ä»¶æ•°: {len(group)}")

# 3. ä¼°ç®—åŠ é€Ÿæ¯”
print(f"\nç†è®ºåŠ é€Ÿæ¯”: {analysis.parallelization_potential:.2f}x")

# 4. é…ç½®å¹¶è¡Œæ‰§è¡Œ
from waveform_analysis.core.execution import enable_global_load_balancing

enable_global_load_balancing(
    min_workers=1,
    max_workers=len(max(analysis.parallel_groups, key=len))  # æ ¹æ®æœ€å¤§å¹¶è¡Œç»„è®¾ç½®
)
```

### åœºæ™¯ 4ï¼šCI/CD é›†æˆ

```python
import json

# åœ¨ CI/CD æµç¨‹ä¸­è‡ªåŠ¨åˆ†æ
analysis = ctx.analyze_dependencies('final_output')

# å¯¼å‡º JSON ç”¨äºè¶‹åŠ¿è¿½è¸ª
data = analysis.to_dict()
data['commit_sha'] = os.getenv('CI_COMMIT_SHA')
data['timestamp'] = datetime.now().isoformat()

with open(f'performance_{data["commit_sha"][:8]}.json', 'w') as f:
    json.dump(data, f, indent=2)

# æ£€æŸ¥æ˜¯å¦æœ‰é«˜ä¸¥é‡æ€§ç“¶é¢ˆï¼ˆå¤±è´¥æ„å»ºï¼‰
high_bottlenecks = [b for b in analysis.bottlenecks if b['severity'] == 'high']
if len(high_bottlenecks) > 3:
    print(f"âŒ å‘ç° {len(high_bottlenecks)} ä¸ªé«˜ä¸¥é‡æ€§ç“¶é¢ˆï¼Œè¯·ä¼˜åŒ–ï¼")
    exit(1)
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰åˆ†æé€»è¾‘

```python
# è·å–åŸå§‹åˆ†ææ•°æ®
analysis = ctx.analyze_dependencies('target')

# è‡ªå®šä¹‰è¿‡æ»¤ç“¶é¢ˆ
cache_issues = [
    b for b in analysis.bottlenecks
    if 'cache_miss' in b['issues'] and b['metrics']['cache_hit_rate'] < 0.2
]

memory_issues = [
    b for b in analysis.bottlenecks
    if 'memory' in b['issues'] and b['metrics']['peak_memory_mb'] > 2048
]

# ç”Ÿæˆè‡ªå®šä¹‰æŠ¥å‘Š
print("ç¼“å­˜é—®é¢˜:")
for issue in cache_issues:
    print(f"  {issue['plugin_name']}: {issue['metrics']['cache_hit_rate']:.1%}")

print("\nå†…å­˜é—®é¢˜:")
for issue in memory_issues:
    print(f"  {issue['plugin_name']}: {issue['metrics']['peak_memory_mb']:.1f}MB")
```

### æ‰¹é‡åˆ†æå¤šä¸ªç›®æ ‡

```python
targets = ['st_waveforms', 'features', 'dataframe', 'paired_events']

for target in targets:
    print(f"\n{'='*60}")
    print(f"åˆ†æç›®æ ‡: {target}")
    print('='*60)

    analysis = ctx.analyze_dependencies(target)
    print(analysis.summary())

    # ä¿å­˜æŠ¥å‘Š
    analysis.save_markdown(f'report_{target}.md')
```

## ğŸ“š å‚è€ƒ

### API æ–‡æ¡£

**Context.analyze_dependencies()**
```python
def analyze_dependencies(
    self,
    target_name: str,
    include_performance: bool = True,
    run_id: Optional[str] = None
) -> DependencyAnalysisResult
```

å‚æ•°ï¼š
- `target_name`: ç›®æ ‡æ•°æ®åç§°
- `include_performance`: æ˜¯å¦åŒ…å«æ€§èƒ½æ•°æ®ï¼ˆéœ€è¦ `enable_stats=True`ï¼‰
- `run_id`: ä¿ç•™å‚æ•°ï¼Œå½“å‰æœªä½¿ç”¨

è¿”å›ï¼š`DependencyAnalysisResult` å¯¹è±¡

**DependencyAnalysisResult å±æ€§**
- `target_name`: ç›®æ ‡åç§°
- `total_plugins`: æ€»æ’ä»¶æ•°
- `execution_plan`: æ‰§è¡Œè®¡åˆ’ï¼ˆæ‹“æ‰‘æ’åºï¼‰
- `max_depth`: DAG æœ€å¤§æ·±åº¦
- `max_width`: DAG æœ€å¤§å®½åº¦
- `layers`: æŒ‰æ·±åº¦åˆ†å±‚çš„æ’ä»¶
- `critical_path`: å…³é”®è·¯å¾„æ’ä»¶åˆ—è¡¨
- `critical_path_time`: å…³é”®è·¯å¾„æ€»æ—¶é—´ï¼ˆå¦‚æœ‰æ€§èƒ½æ•°æ®ï¼‰
- `parallel_groups`: å¯å¹¶è¡Œæ‰§è¡Œçš„æ’ä»¶ç»„
- `parallelization_potential`: ç†è®ºåŠ é€Ÿæ¯”
- `bottlenecks`: æ€§èƒ½ç“¶é¢ˆåˆ—è¡¨
- `recommendations`: ä¼˜åŒ–å»ºè®®åˆ—è¡¨
- `has_performance_data`: æ˜¯å¦åŒ…å«æ€§èƒ½æ•°æ®

**DependencyAnalysisResult æ–¹æ³•**
- `summary()`: ç”Ÿæˆç®€è¦æ–‡æœ¬æ‘˜è¦
- `to_dict()`: è½¬æ¢ä¸ºå­—å…¸
- `to_json(filepath=None)`: è½¬æ¢ä¸º JSON
- `to_markdown()`: ç”Ÿæˆ Markdown æŠ¥å‘Š
- `save_markdown(filepath)`: ä¿å­˜ Markdown æŠ¥å‘Š

### ç›¸å…³æ–‡æ¡£

- [ARCHITECTURE.md](../../architecture/ARCHITECTURE.md) - æ•´ä½“æ¶æ„
- [ç¼“å­˜æœºåˆ¶](DATA_ACCESS.md#ç¼“å­˜æœºåˆ¶) - ç¼“å­˜æœºåˆ¶
- [EXECUTOR_MANAGER_GUIDE.md](../advanced/EXECUTOR_MANAGER_GUIDE.md) - å¹¶è¡Œæ‰§è¡Œ

## â“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•å¯ç”¨æ€§èƒ½ç»Ÿè®¡ï¼Ÿ

A: åœ¨åˆ›å»º Context æ—¶è®¾ç½® `enable_stats=True`ï¼š
```python
ctx = Context(enable_stats=True, stats_mode='detailed')
```

### Q: é™æ€åˆ†æå’ŒåŠ¨æ€åˆ†ææœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

A:
- **é™æ€åˆ†æ**ï¼šä»…åŸºäºä¾èµ–å…³ç³»å›¾ï¼Œä¸éœ€è¦å®é™…æ‰§è¡Œæ•°æ®
- **åŠ¨æ€åˆ†æ**ï¼šç»“åˆå®é™…æ‰§è¡Œæ—¶é—´ã€ç¼“å­˜å‘½ä¸­ç‡ã€å†…å­˜ä½¿ç”¨ç­‰æ€§èƒ½æ•°æ®

### Q: å¦‚ä½•ç†è§£åŠ é€Ÿæ¯”ï¼Ÿ

A: åŠ é€Ÿæ¯” = é¡ºåºæ‰§è¡Œæ—¶é—´ / å¹¶è¡Œæ‰§è¡Œæ—¶é—´ã€‚ä¾‹å¦‚ï¼š
- åŠ é€Ÿæ¯” 2.0x è¡¨ç¤ºç†è®ºä¸Šå¯ä»¥å¿«ä¸€å€
- å®é™…åŠ é€Ÿæ¯”é€šå¸¸å°äºç†è®ºå€¼ï¼ˆå—å¹¶è¡Œå¼€é”€ã€èµ„æºé™åˆ¶ç­‰å½±å“ï¼‰

### Q: ç“¶é¢ˆä¸¥é‡æ€§å¦‚ä½•åˆ¤æ–­ï¼Ÿ

A: åŸºäºå¤šä¸ªç»´åº¦ç»¼åˆè¯„ä¼°ï¼š
- **High**: æ—¶é—´å æ¯” >20% æˆ–åœ¨å…³é”®è·¯å¾„ä¸Šä¸”æœ‰å…¶ä»–é—®é¢˜
- **Medium**: æ—¶é—´å æ¯” 10-20% æˆ–ç¼“å­˜å‘½ä¸­ç‡ä½
- **Low**: æœ‰æ½œåœ¨é—®é¢˜ä½†å½±å“è¾ƒå°

### Q: å¦‚ä½•å¯¼å‡ºå®Œæ•´çš„æ€§èƒ½æŠ¥å‘Šï¼Ÿ

A: ç»“åˆä½¿ç”¨ï¼š
```python
# 1. ä¾èµ–åˆ†ææŠ¥å‘Š
analysis = ctx.analyze_dependencies('target')
analysis.save_markdown('dependency_report.md')

# 2. æ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š
with open('performance_stats.txt', 'w') as f:
    f.write(ctx.get_performance_report())
```

## ğŸ‰ æ€»ç»“

ä¾èµ–åˆ†æåŠŸèƒ½å¸®åŠ©æ‚¨ï¼š
1. âœ… å¿«é€Ÿç†è§£å¤æ‚çš„æ•°æ®æµå’Œä¾èµ–å…³ç³»
2. âœ… è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œä¼˜åŒ–æœºä¼š
3. âœ… è·å¾—å¯æ‰§è¡Œçš„ä¼˜åŒ–å»ºè®®
4. âœ… é€šè¿‡å¯è§†åŒ–ç›´è§‚å±•ç¤ºåˆ†æç»“æœ
5. âœ… å¯¼å‡ºæŠ¥å‘Šç”¨äºæ–‡æ¡£å’Œè¶‹åŠ¿è¿½è¸ª

Happy analyzing! ğŸš€
