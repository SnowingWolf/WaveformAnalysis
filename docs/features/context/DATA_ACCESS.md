**å¯¼èˆª**: [æ–‡æ¡£ä¸­å¿ƒ](../../README.md) > [åŠŸèƒ½ç‰¹æ€§](../README.md) > [Context åŠŸèƒ½](README.md) > æ•°æ®è·å–

---

# æ•°æ®è·å–

> **é˜…è¯»æ—¶é—´**: 10 åˆ†é’Ÿ | **éš¾åº¦**: â­ å…¥é—¨

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨ Context è·å–æ’ä»¶äº§å‡ºçš„æ•°æ®ã€‚

---

## ğŸ“‹ ç›®å½•

1. [åŸºæœ¬æ•°æ®è·å–](#åŸºæœ¬æ•°æ®è·å–)
2. [ç¼“å­˜æœºåˆ¶](#ç¼“å­˜æœºåˆ¶)
3. [ç¼“å­˜æ‰«æä¸è¯Šæ–­](#ç¼“å­˜æ‰«æä¸è¯Šæ–­)
4. [è¿›åº¦æ˜¾ç¤º](#è¿›åº¦æ˜¾ç¤º)
5. [æ—¶é—´èŒƒå›´æŸ¥è¯¢](#æ—¶é—´èŒƒå›´æŸ¥è¯¢)
6. [æ‰¹é‡è·å–](#æ‰¹é‡è·å–)
7. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## åŸºæœ¬æ•°æ®è·å–

### get_data() æ–¹æ³•

```python
from waveform_analysis.core.context import Context

ctx = Context(storage_dir="./cache")
# ... æ³¨å†Œæ’ä»¶ ...

# è·å–æ•°æ®
data = ctx.get_data(run_id="run_001", data_name="waveforms")
```

### å‚æ•°è¯´æ˜

```python
def get_data(
    run_id: str,           # è¿è¡Œæ ‡è¯†ç¬¦ï¼ˆå¿…éœ€ï¼‰
    data_name: str,        # æ•°æ®åç§°ï¼ˆå¿…éœ€ï¼‰
    show_progress: bool = False,  # æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
    progress_desc: str = None,    # è‡ªå®šä¹‰è¿›åº¦æè¿°
    **kwargs               # ä¼ é€’ç»™æ’ä»¶çš„é¢å¤–å‚æ•°
) -> Any
```

### è‡ªåŠ¨ä¾èµ–è§£æ

```python
# è·å– paired_events ä¼šè‡ªåŠ¨æ‰§è¡Œæ•´ä¸ªä¾èµ–é“¾
# raw_files â†’ waveforms â†’ st_waveforms â†’ features â†’ dataframe â†’ paired_events
paired = ctx.get_data("run_001", "paired_events")

# ä¾èµ–çš„æ•°æ®ä¼šè¢«ç¼“å­˜ï¼Œåç»­è®¿é—®ç›´æ¥è¿”å›
waveforms = ctx.get_data("run_001", "waveforms")  # ç›´æ¥ä»ç¼“å­˜è¿”å›
```

---

## ç¼“å­˜æœºåˆ¶

### ä¸‰çº§ç¼“å­˜

Context ä½¿ç”¨ä¸‰çº§ç¼“å­˜åŠ é€Ÿæ•°æ®è®¿é—®ï¼š

```
1. å†…å­˜ç¼“å­˜ â†’ æœ€å¿«ï¼Œå½“å‰ä¼šè¯æœ‰æ•ˆ
2. ç£ç›˜ç¼“å­˜ â†’ æŒä¹…åŒ–ï¼Œè·¨ä¼šè¯æœ‰æ•ˆ
3. é‡æ–°è®¡ç®— â†’ æœ€æ…¢ï¼Œç¼“å­˜å¤±æ•ˆæ—¶æ‰§è¡Œ
```

### ç¼“å­˜æŸ¥è¯¢é¡ºåº

```python
# get_data çš„å†…éƒ¨æµç¨‹ï¼š
# 1. æ£€æŸ¥å†…å­˜ç¼“å­˜ â†’ å‘½ä¸­åˆ™ç›´æ¥è¿”å›
# 2. æ£€æŸ¥ç£ç›˜ç¼“å­˜ â†’ å‘½ä¸­åˆ™åŠ è½½åˆ°å†…å­˜å¹¶è¿”å›
# 3. æ‰§è¡Œæ’ä»¶è®¡ç®— â†’ è®¡ç®—å¹¶ç¼“å­˜ç»“æœ
```

### æ ¸å¿ƒæœºåˆ¶

#### Lineage Hashing (è¡€ç¼˜è¿½è¸ª)

æ¯ä¸ªæ•°æ®å¯¹è±¡ï¼ˆå¦‚ `hits`ï¼‰éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„ Lineageï¼ŒåŒ…å«ï¼š
- **Plugin**: æ’ä»¶ç±»å
- **Version**: æ’ä»¶ç‰ˆæœ¬å·
- **Config**: æ’ä»¶åŠä¸Šæ¸¸æ’ä»¶çš„é…ç½®
- **DType**: æ ‡å‡†åŒ– dtypeï¼ˆ`dtype.descr`ï¼‰
- **Dependencies**: ä¸Šæ¸¸æ•°æ®çš„ Lineage

Lineage ä¼šåºåˆ—åŒ–å¹¶è®¡ç®— SHA1 å“ˆå¸Œï¼Œä½œä¸ºç¼“å­˜é”®çš„ä¸€éƒ¨åˆ†ã€‚
é…ç½®/ç‰ˆæœ¬/dtype ä»»æ„å˜åŒ–éƒ½ä¼šå¯¼è‡´ç¼“å­˜è‡ªåŠ¨å¤±æ•ˆå¹¶é‡æ–°è®¡ç®—ã€‚
ç›¸åŒé…ç½®å’Œä»£ç ä¼šæŒ‡å‘ç›¸åŒç¼“å­˜é”®ï¼Œä¿è¯ç»“æœç¡®å®šæ€§ã€‚
åŠ è½½ç¼“å­˜æ—¶ä¼šæ¯”å¯¹å…ƒæ•°æ®ä¸­çš„ lineageï¼Œè‹¥ä¸ä¸€è‡´ä¼šæç¤ºå¹¶å¼ºåˆ¶é‡ç®—ã€‚
å¦‚æœæ’ä»¶å®ç°äº† `get_lineage(context)`ï¼Œ`Context.get_lineage()` ä¼šä¼˜å…ˆä½¿ç”¨è¯¥å®ç°è¦†ç›–é»˜è®¤è¡€ç¼˜ç”Ÿæˆé€»è¾‘ã€‚

#### Memmap å­˜å‚¨ (é›¶æ‹·è´è®¿é—®)

ç»“æ„åŒ–æ•°ç»„ä½¿ç”¨ `numpy.memmap` å­˜å‚¨ï¼š
- **åŸå­å†™å…¥**: å…ˆå†™ `.tmp`ï¼ŒæˆåŠŸåé‡å‘½åä¸º `.bin`
- **æŒ‰éœ€åŠ è½½**: è¯»å–æ—¶åªæ˜ å°„ï¼Œä¸ä¸€æ¬¡æ€§åŠ è½½å…¨é‡æ•°æ®
- **è¶…å¤§æ•°æ®æ”¯æŒ**: å¯å¤„ç†è¶…å†…å­˜æ•°æ®é›†
- **å¿«é€Ÿå¯åŠ¨**: å»ºç«‹æ˜ å°„å‡ ä¹æ˜¯ç¬æ—¶çš„

### ç¼“å­˜ç›®å½•ç»“æ„

é»˜è®¤ç¼“å­˜ç›®å½•ä¸º `storage_dir`ï¼ˆé»˜è®¤ `./strax_data`ï¼‰ï¼š

```text
strax_data/
â”œâ”€â”€ run_001-hits-abc12345.bin      # äºŒè¿›åˆ¶æ•°æ® (memmap)
â”œâ”€â”€ run_001-hits-abc12345.json     # å…ƒæ•°æ® (dtype, lineage, count)
â””â”€â”€ _side_effects/                 # ä¾§æ•ˆåº”æ’ä»¶è¾“å‡º (ç»˜å›¾, å¯¼å‡ºç­‰)
    â””â”€â”€ run_001/
        â””â”€â”€ my_plot_plugin/
            â””â”€â”€ plot.png
```

### ç¼“å­˜çŠ¶æ€æŸ¥çœ‹

```python
# é¢„è§ˆæ‰§è¡Œè®¡åˆ’å’Œç¼“å­˜çŠ¶æ€
result = ctx.preview_execution("run_001", "paired_events")

# æŸ¥çœ‹å“ªäº›å·²ç¼“å­˜
for plugin, status in result['cache_status'].items():
    if status['in_memory']:
        print(f"{plugin}: å†…å­˜ç¼“å­˜")
    elif status['on_disk']:
        print(f"{plugin}: ç£ç›˜ç¼“å­˜")
    elif status.get('pruned'):
        print(f"{plugin}: ç¼“å­˜å‰ªæ")
    else:
        print(f"{plugin}: éœ€è¦è®¡ç®—")
```

### æ¸…é™¤ç¼“å­˜

```python
# æ¸…é™¤æŒ‡å®š run + æ•°æ®çš„å†…å­˜/ç£ç›˜ç¼“å­˜
ctx.clear_cache_for("run_001", "waveforms")

# ä»…æ¸…é™¤å†…å­˜ç¼“å­˜ï¼ˆä¿ç•™ç£ç›˜ï¼‰
ctx.clear_cache_for("run_001", "waveforms", clear_disk=False)

# æ¸…é™¤ run çš„å…¨éƒ¨ç¼“å­˜ï¼ˆå†…å­˜ + ç£ç›˜ï¼‰
ctx.clear_cache_for("run_001")
```

> æç¤ºï¼š`clear_cache()` æ˜¯æ—§çš„æ­¥éª¤çº§ç¼“å­˜æ¥å£ï¼Œæ’ä»¶æ•°æ®ç¼“å­˜è¯·ä½¿ç”¨ `clear_cache_for()`ã€‚

### æ³¨æ„äº‹é¡¹

- **DType ä¸€è‡´æ€§**: æ’ä»¶å¿…é¡»å®šä¹‰ `dtype`ï¼Œç¡®ä¿ memmap å¯è§£æã€‚
- **å¹¶å‘å®‰å…¨**: å­˜å‚¨ä½¿ç”¨æ–‡ä»¶é”åè°ƒå†™å…¥ï¼Œä½†ä¸é€‚åˆè·¨èŠ‚ç‚¹/ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿçš„å¼ºä¸€è‡´å†™å…¥ã€‚

### CI ä¸å®è·µå»ºè®®

- CI ä¸­å»ºè®®ä½¿ç”¨ä¸´æ—¶ç›®å½•å­˜æ”¾æŒä¹…åŒ–ç¼“å­˜ï¼Œé¿å…æ±¡æŸ“å·¥ä½œåŒºã€‚
- å¯ç¼“å­˜ä¾èµ–/æµ‹è¯•æ•°æ®ï¼Œä½†ä¸å»ºè®®ç¼“å­˜å¯èƒ½å¯¼è‡´éç¡®å®šæ€§çš„ç»“æœæ–‡ä»¶ã€‚
- æ¨èè¦†ç›–ç‚¹ï¼š
  - æŒä¹…åŒ–ç¼“å­˜åˆ›å»ºä¸è¯»å–
  - `watch_attrs` å¯¼è‡´çš„ç¼“å­˜å¤±æ•ˆ
  - å†…å­˜ç¼“å­˜å¯ç”¨/ç¦ç”¨è¡Œä¸º

ç®€åŒ–çš„ GitHub Actions ç¤ºä¾‹ï¼š

```yaml
name: Python tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"
      - name: Install deps
        run: python -m pip install -r requirements.txt
      - name: Run tests
        run: pytest -q
      - name: Upload test artifacts (optional)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: test-output
          path: .pytest_cache
```

### å®è·µå°è´´å£«

- ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿå¯èƒ½å¯¼è‡´ mtime ç²¾åº¦ä¸è¶³ï¼Œå¿…è¦æ—¶æŠŠ `watch_attrs` è®¾ä¸ºæ›´ç¨³å®šçš„å†…å®¹ã€‚
- å¤šè¿›ç¨‹å…±äº«ç¼“å­˜æ—¶ï¼Œç¡®ä¿å†™å…¥æ˜¯åŸå­æ“ä½œï¼ˆä¸´æ—¶æ–‡ä»¶ + é‡å‘½åï¼‰ã€‚

---

## ç¼“å­˜æ‰«æä¸è¯Šæ–­

Context ä¹Ÿæä¾›ä¾¿æ·æ¥å£ï¼š

```python
analyzer = ctx.analyze_cache()
stats = ctx.cache_stats(detailed=True)
issues = ctx.diagnose_cache(auto_fix=True, dry_run=True)
```

### æ‰«æä¸ç´¢å¼•ï¼ˆCacheAnalyzerï¼‰

`CacheAnalyzer` ç”¨äºæ‰«æå½“å‰ storage ç›®å½•å¹¶æ„å»ºç¼“å­˜ç´¢å¼•ï¼Œæ”¯æŒå¢é‡æ‰«æå’Œè¿‡æ»¤æŸ¥è¯¢ï¼š

```python
from waveform_analysis.core.storage.cache_analyzer import CacheAnalyzer

analyzer = CacheAnalyzer(ctx)
analyzer.scan()  # é»˜è®¤å¢é‡æ‰«æ

# å¼ºåˆ¶åˆ·æ–°ç´¢å¼•
analyzer.scan(force_refresh=True)

# æŒ‰æ¡ä»¶è¿‡æ»¤æ¡ç›®
entries = analyzer.get_entries(run_id="run_001", min_size=1024 * 1024)

# æŸ¥çœ‹æ‘˜è¦
analyzer.print_summary(detailed=True)
```

### ç¼“å­˜ç»Ÿè®¡ï¼ˆCacheStatsCollectorï¼‰

`CacheStatsCollector` æ±‡æ€»ç¼“å­˜è§„æ¨¡ã€æŒ‰ run/æ•°æ®ç±»å‹ç»Ÿè®¡ï¼Œå¹¶æ”¯æŒå¯¼å‡º JSON/CSVï¼š

```python
from waveform_analysis.core.storage.cache_statistics import CacheStatsCollector

collector = CacheStatsCollector(analyzer)
stats = collector.collect()
collector.print_summary(stats, detailed=True)

# å¯¼å‡ºç»Ÿè®¡
collector.export_stats(stats, "cache_stats.json", format="json")
collector.export_stats(stats, "cache_stats.csv", format="csv")
```

### ç¼“å­˜åˆ†ææ’ä»¶ï¼ˆCacheAnalysisPluginï¼‰

å¦‚æœéœ€è¦åœ¨ Context ä¸­ç›´æ¥è·å–ç¼“å­˜åˆ†ææŠ¥å‘Šï¼Œå¯æ³¨å†Œ `CacheAnalysisPlugin`ï¼š

```python
from waveform_analysis.core.plugins.builtin.cpu import CacheAnalysisPlugin

ctx.register(CacheAnalysisPlugin())
report = ctx.get_data("run_001", "cache_analysis", include_entries=False)
print(report["summary"])
```

### è¯Šæ–­é—®é¢˜ï¼ˆCacheDiagnosticsï¼‰

`CacheDiagnostics` ç”¨äºæ£€æŸ¥ç‰ˆæœ¬ä¸åŒ¹é…ã€æ•°æ®æ–‡ä»¶ç¼ºå¤±ã€å¤§å°ä¸åŒ¹é…ã€æ ¡éªŒå’Œå¤±è´¥ã€
å­¤å„¿æ–‡ä»¶ç­‰é—®é¢˜ï¼Œå¹¶æ”¯æŒè‡ªåŠ¨ä¿®å¤ï¼ˆå»ºè®®å…ˆ dry-runï¼‰ï¼š

```python
from waveform_analysis.core.storage.cache_diagnostics import CacheDiagnostics

diag = CacheDiagnostics(analyzer)
issues = diag.diagnose(
    run_id="run_001",
    check_integrity=True,
    check_orphans=True,
    check_versions=True
)

diag.print_report(issues, group_by="severity")

# é¢„æ¼”ä¿®å¤
diag.auto_fix(issues, dry_run=True)
```

### æ¸…ç†ç¼“å­˜ï¼ˆCacheCleanerï¼‰

`CacheCleaner` æ”¯æŒæŒ‰ LRUã€æœ€å¤§æ–‡ä»¶ã€ç‰ˆæœ¬ä¸åŒ¹é…ç­‰ç­–ç•¥æ¸…ç†ç¼“å­˜ã€‚
å»ºè®®å…ˆç”¨ `CacheAnalyzer` æ‰«æå¹¶é¢„è§ˆæ¸…ç†è®¡åˆ’ï¼Œå†æ‰§è¡Œå®é™…åˆ é™¤ã€‚

å¯ç”¨ç­–ç•¥ï¼ˆ`CleanupStrategy`ï¼‰ï¼š
- `LRU`: æœ€è¿‘æœ€å°‘ä½¿ç”¨ï¼ˆæŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œä¼˜å…ˆåˆ é™¤æœ€æ—©åˆ›å»ºï¼‰
- `OLDEST`: æœ€æ—§çš„ï¼ˆåŒ LRUï¼Œä½†è¯­ä¹‰æ›´ç›´è§‚ï¼‰
- `LARGEST`: æœ€å¤§æ–‡ä»¶ä¼˜å…ˆ
- `VERSION_MISMATCH`: æ’ä»¶ç‰ˆæœ¬ä¸åŒ¹é…çš„ç¼“å­˜
- `FAILED_INTEGRITY`: å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥æˆ–æ–‡ä»¶å¼‚å¸¸
- `BY_RUN`: æŒ‰ run æ¸…ç†
- `BY_DATA_TYPE`: æŒ‰æ•°æ®ç±»å‹æ¸…ç†

å¸¸ç”¨å‚æ•°è¯´æ˜ï¼š
- `target_size_mb`: ç›®æ ‡é‡Šæ”¾ç©ºé—´ï¼ˆä¸ `max_entries` äºŒé€‰ä¸€ï¼‰
- `max_entries`: æœ€å¤šåˆ é™¤æ¡ç›®æ•°
- `keep_recent_days`: ä¿ç•™æœ€è¿‘ N å¤©çš„æ•°æ®
- `run_id` / `data_name`: é™å®šæ¸…ç†èŒƒå›´
- `dry_run`: æ¼”ç»ƒæ¨¡å¼ï¼Œé»˜è®¤å»ºè®® `True`

```python
from waveform_analysis.core.storage.cache_analyzer import CacheAnalyzer
from waveform_analysis.core.storage.cache_cleaner import CacheCleaner, CleanupStrategy

analyzer = CacheAnalyzer(ctx)
analyzer.scan()

cleaner = CacheCleaner(analyzer)
cleaner.plan_cleanup(
    strategy=CleanupStrategy.LRU,
    target_size_mb=500
).preview_plan(detailed=True)
cleaner.execute(dry_run=True)
```

æ›´å¤šç”¨æ³•ç¤ºä¾‹ï¼š

```python
# 1) æŒ‰ç›®æ ‡æ€»å¤§å°æ¸…ç†ï¼ˆä¿ç•™åˆ° 2GBï¼‰
cleaner.cleanup_to_target_size(target_total_mb=2048, strategy=CleanupStrategy.LRU, dry_run=True)

# 2) æŒ‰å¹´é¾„æ¸…ç†ï¼ˆä¿ç•™ 7 å¤©å†…æ•°æ®ï¼‰
cleaner.cleanup_by_age(max_age_days=7, dry_run=True)

# 3) åªæ¸…ç†æŸä¸ª run
cleaner.cleanup_run("run_001", dry_run=True)

# 4) åªæ¸…ç†æŸä¸ªæ•°æ®ç±»å‹
cleaner.cleanup_data_type("peaks", dry_run=True)

# 5) ä»…æ¸…ç†ç‰ˆæœ¬ä¸åŒ¹é…æˆ–å®Œæ•´æ€§å¤±è´¥çš„æ¡ç›®
cleaner.plan_cleanup(strategy=CleanupStrategy.VERSION_MISMATCH)
cleaner.execute(dry_run=True)
```

æ³¨æ„äº‹é¡¹ï¼š
- `VERSION_MISMATCH` ä¾èµ–å·²æ³¨å†Œæ’ä»¶çš„ `version` ä¿¡æ¯
- `FAILED_INTEGRITY` ä¼šæ£€æŸ¥æ–‡ä»¶ç¼ºå¤±å’Œå¤§å°å¼‚å¸¸
- `dry_run=False` æ‰ä¼šå®é™…åˆ é™¤æ–‡ä»¶ï¼Œå»ºè®®å…ˆé¢„è§ˆ

### è¿è¡Œæ—¶ç¼“å­˜æ£€æŸ¥ï¼ˆRuntimeCacheManagerï¼‰

`RuntimeCacheManager` æ˜¯ Context å†…éƒ¨çš„è¿è¡Œæ—¶ç¼“å­˜æ£€æŸ¥å™¨ï¼Œç”¨äºç»Ÿä¸€æ£€æŸ¥å†…å­˜/ç£ç›˜ç¼“å­˜ã€‚
é€šå¸¸åªåœ¨è°ƒè¯•æˆ–é«˜çº§ç”¨æ³•ä¸­ç›´æ¥ä½¿ç”¨ï¼š

```python
from waveform_analysis.core.storage.cache_manager import RuntimeCacheManager

cache_manager = RuntimeCacheManager(ctx)
cache_key = ctx.key_for("run_001", "st_waveforms")

data, cache_hit = cache_manager.check_cache("run_001", "st_waveforms", cache_key)
print(f"cache_hit={cache_hit}")
```

---

## è¿›åº¦æ˜¾ç¤º

### å¯ç”¨è¿›åº¦æ¡

```python
# æ–¹å¼ 1: get_data æ—¶å¯ç”¨
data = ctx.get_data("run_001", "paired_events", show_progress=True)

# æ–¹å¼ 2: è‡ªå®šä¹‰è¿›åº¦æè¿°
data = ctx.get_data(
    "run_001", "paired_events",
    show_progress=True,
    progress_desc="å¤„ç†æ³¢å½¢æ•°æ®"
)
```

### è¿›åº¦æ¡è¾“å‡ºç¤ºä¾‹

```
å¤„ç†æ³¢å½¢æ•°æ®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00, 1.2 plugins/s]
  âœ“ raw_files (0.5s)
  âœ“ waveforms (2.1s)
  âœ“ st_waveforms (0.8s)
  âœ“ features (0.6s)
  âœ“ dataframe (0.4s)
  âœ“ paired_events (0.6s)
```

### å…¨å±€è¿›åº¦è®¾ç½®

```python
# åœ¨é…ç½®ä¸­è®¾ç½®é»˜è®¤è¿›åº¦æ˜¾ç¤º
ctx.set_config({'show_progress': True})

# ä¹‹åæ‰€æœ‰ get_data è°ƒç”¨éƒ½ä¼šæ˜¾ç¤ºè¿›åº¦
data = ctx.get_data("run_001", "paired_events")  # è‡ªåŠ¨æ˜¾ç¤ºè¿›åº¦
```

---

## æ—¶é—´èŒƒå›´æŸ¥è¯¢

### get_data_time_range() æ–¹æ³•

å¯¹äºå¤§å‹æ•°æ®é›†ï¼Œå¯ä»¥åªè·å–ç‰¹å®šæ—¶é—´èŒƒå›´çš„æ•°æ®ï¼š

```python
# è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®
data = ctx.get_data_time_range(
    run_id="run_001",
    data_name="st_waveforms",
    start_time=1000000,   # èµ·å§‹æ—¶é—´ï¼ˆçº³ç§’ï¼‰
    end_time=2000000      # ç»“æŸæ—¶é—´ï¼ˆçº³ç§’ï¼‰
)

print(f"è·å–äº† {len(data)} æ¡è®°å½•")
```

### æ„å»ºæ—¶é—´ç´¢å¼•

å¯¹äºé¢‘ç¹çš„æ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼Œé¢„å…ˆæ„å»ºç´¢å¼•å¯ä»¥æå‡æ€§èƒ½ï¼š

```python
# é¢„å…ˆæ„å»ºæ—¶é—´ç´¢å¼•
ctx.build_time_index("run_001", "st_waveforms")

# ä¹‹åçš„æŸ¥è¯¢ä¼šæ›´å¿«
data1 = ctx.get_data_time_range("run_001", "st_waveforms", 1000, 2000)
data2 = ctx.get_data_time_range("run_001", "st_waveforms", 3000, 4000)

# æŸ¥çœ‹ç´¢å¼•ç»Ÿè®¡
stats = ctx.get_time_index_stats()
print(stats)
```

### æ—¶é—´å­—æ®µé…ç½®

```python
# å¦‚æœæ•°æ®ä½¿ç”¨éæ ‡å‡†æ—¶é—´å­—æ®µï¼ˆæµå¼é»˜è®¤ä½¿ç”¨ timestampï¼‰
ctx.build_time_index(
    "run_001", "st_waveforms",
    time_field="timestamp",  # è‡ªå®šä¹‰æ—¶é—´å­—æ®µå
    endtime_field="computed"  # endtime è®¡ç®—æ–¹å¼
)
```

---

## æ‰¹é‡è·å–

### å¤šä¸ªæ•°æ®åç§°

```python
# è·å–å¤šä¸ªæ•°æ®
results = {}
for data_name in ["waveforms", "st_waveforms", "features"]:
    results[data_name] = ctx.get_data("run_001", data_name)
```

### å¤šä¸ª run_id

```python
# è·å–å¤šä¸ª run çš„åŒä¸€æ•°æ®
run_ids = ["run_001", "run_002", "run_003"]
all_features = {}

for run_id in run_ids:
    all_features[run_id] = ctx.get_data(run_id, "features")
```

### ä½¿ç”¨ BatchProcessor

å¯¹äºå¤§è§„æ¨¡æ‰¹é‡å¤„ç†ï¼Œä½¿ç”¨ä¸“é—¨çš„æ‰¹å¤„ç†å™¨ï¼š

```python
from waveform_analysis.core.data.export import BatchProcessor

processor = BatchProcessor(ctx)

# å¹¶è¡Œå¤„ç†å¤šä¸ª run
results = processor.process_runs(
    run_ids=["run_001", "run_002", "run_003"],
    data_name="paired_events",
    max_workers=4,
    show_progress=True
)

# è®¿é—®ç»“æœ
for run_id, data in results['results'].items():
    print(f"{run_id}: {len(data)} events")
```

---

## æ•°æ®ç±»å‹

### ç»“æ„åŒ–æ•°ç»„

å¤§å¤šæ•°æ’ä»¶è¿”å› NumPy ç»“æ„åŒ–æ•°ç»„ï¼š

```python
st_waveforms = ctx.get_data("run_001", "st_waveforms")

# è®¿é—®å­—æ®µ
times = st_waveforms['time']
waves = st_waveforms['wave']
channels = st_waveforms['channel']

# æŸ¥çœ‹ dtype
print(st_waveforms.dtype)
# [('time', '<f8'), ('wave', '<f4', (1000,)), ('channel', '<i4')]
```

### DataFrame

æŸäº›æ’ä»¶è¿”å› pandas DataFrameï¼š

```python
df = ctx.get_data("run_001", "dataframe")

# æ ‡å‡† DataFrame æ“ä½œ
print(df.head())
print(df.columns)
filtered = df[df['charge'] > 100]
```

### åˆ—è¡¨å’Œç”Ÿæˆå™¨

æŸäº›æ’ä»¶è¿”å›åˆ—è¡¨æˆ–ç”Ÿæˆå™¨ï¼š

```python
# åˆ—è¡¨ç±»å‹ï¼ˆæŒ‰é€šé“åˆ†ç»„ï¼‰
waveforms = ctx.get_data("run_001", "waveforms")
for ch_idx, ch_data in enumerate(waveforms):
    print(f"é€šé“ {ch_idx}: {len(ch_data)} æ¡æ³¢å½¢")

# ç”Ÿæˆå™¨ç±»å‹ï¼ˆæµå¼å¤„ç†ï¼‰
# æ³¨æ„ï¼šç”Ÿæˆå™¨åªèƒ½æ¶ˆè´¹ä¸€æ¬¡
stream = ctx.get_data("run_001", "waveforms_stream")
for chunk in stream:
    process(chunk)
```

---

## å¸¸è§é—®é¢˜

### Q1: æ•°æ®è·å–å¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
```python
# 1. æ£€æŸ¥ç¼“å­˜çŠ¶æ€
ctx.preview_execution("run_001", "target_data")

# 2. å¯ç”¨è¿›åº¦æ¡æŸ¥çœ‹ç“¶é¢ˆ
ctx.get_data("run_001", "target_data", show_progress=True)

# 3. è€ƒè™‘ä½¿ç”¨æµå¼å¤„ç†
# 4. æ£€æŸ¥ç£ç›˜ç¼“å­˜æ˜¯å¦å¯ç”¨
print(f"Storage dir: {ctx.storage_dir}")
```

### Q2: å¦‚ä½•å¼ºåˆ¶é‡æ–°è®¡ç®—ï¼Ÿ

**A**: æ¸…é™¤ç¼“å­˜åé‡æ–°è·å–ï¼š
```python
# æ¸…é™¤ç‰¹å®šæ•°æ®çš„ç¼“å­˜
ctx.clear_data("run_001", "waveforms")

# é‡æ–°è·å–ï¼ˆä¼šé‡æ–°è®¡ç®—ï¼‰
data = ctx.get_data("run_001", "waveforms")
```

### Q3: å¦‚ä½•æ£€æŸ¥æ•°æ®æ˜¯å¦å·²è®¡ç®—ï¼Ÿ

**A**: ä½¿ç”¨ preview_executionï¼š
```python
result = ctx.preview_execution("run_001", "waveforms")
status = result['cache_status']['waveforms']

if status['in_memory'] or status['on_disk']:
    print("æ•°æ®å·²ç¼“å­˜")
else:
    print("éœ€è¦è®¡ç®—")
```

### Q4: get_data è¿”å› None æ€ä¹ˆåŠï¼Ÿ

**A**: å¯èƒ½çš„åŸå› ï¼š
- æ’ä»¶æœªæ³¨å†Œ â†’ æ£€æŸ¥ `ctx.list_provided_data()`
- æ•°æ®åç§°æ‹¼å†™é”™è¯¯ â†’ æ£€æŸ¥ `plugin.provides`
- æ’ä»¶è®¡ç®—è¿”å›äº† None â†’ æ£€æŸ¥æ’ä»¶å®ç°

### Q5: å¦‚ä½•è·å–åŸå§‹æ•°æ®çš„è·¯å¾„ï¼Ÿ

**A**:
```python
# è·å– raw_files æ’ä»¶çš„è¾“å‡º
raw_files = ctx.get_data("run_001", "raw_files")
print(raw_files)  # é€šå¸¸æ˜¯æ–‡ä»¶è·¯å¾„åˆ—è¡¨
```

### Q6: å¯ä»¥æŠŠç¼“å­˜æ–‡ä»¶æäº¤åˆ°ä»“åº“ç”¨äºåŠ é€Ÿ CI å—ï¼Ÿ

**A**: ä¸å»ºè®®ã€‚ç¼“å­˜å¯èƒ½ä¾èµ–æœ¬åœ°è·¯å¾„ã€mtime æˆ–ç¯å¢ƒå·®å¼‚ï¼Œæäº¤åå®¹æ˜“å¯¼è‡´ä¸å¯é¢„æœŸçš„ç»“æœã€‚
å¦‚éœ€åŠ é€Ÿ CIï¼Œå»ºè®®ç¼“å­˜ä¾èµ–æˆ–æµ‹è¯•ç”Ÿæˆçš„æ•°æ®ï¼Œå¹¶ä¿æŒç¼“å­˜å¯å¤±æ•ˆã€‚

---

## ç›¸å…³æ–‡æ¡£

- [æ’ä»¶ç®¡ç†](PLUGIN_MANAGEMENT.md) - æ³¨å†Œå’Œç®¡ç†æ’ä»¶
- [é…ç½®ç®¡ç†](CONFIGURATION.md) - è®¾ç½®æ’ä»¶é…ç½®
- [ç¼“å­˜æœºåˆ¶](#ç¼“å­˜æœºåˆ¶) - ç¼“å­˜åŸç†ä¸ç›®å½•ç»“æ„
- [ç¼“å­˜ç®¡ç† CLI](../../cli/WAVEFORM_CACHE.md) - ç¼“å­˜æ‰«æã€è¯Šæ–­ä¸æ¸…ç†
- [é¢„è§ˆæ‰§è¡Œ](PREVIEW_EXECUTION.md) - æ‰§è¡Œå‰é¢„è§ˆ
- [ä¾èµ–åˆ†æ](DEPENDENCY_ANALYSIS_VS_PREVIEW_EXECUTION.md) - ä¾èµ–åˆ†æ


---

**å¿«é€Ÿé“¾æ¥**: [æ’ä»¶ç®¡ç†](PLUGIN_MANAGEMENT.md) | [é…ç½®ç®¡ç†](CONFIGURATION.md) | [é¢„è§ˆæ‰§è¡Œ](PREVIEW_EXECUTION.md)
