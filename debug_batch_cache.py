#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
BatchProcessor ç¼“å­˜è¯Šæ–­è„šæœ¬

ç”¨äºè¯Šæ–­ä¸ºä»€ä¹ˆ BatchProcessor ä¼šé‡æ–°è®¡ç®—å·²ç»åŠ è½½è¿‡çš„æ•°æ®
"""

def diagnose_cache_status(ctx, run_ids, data_name):
    """
    è¯Šæ–­ç¼“å­˜çŠ¶æ€

    Args:
        ctx: Context å¯¹è±¡
        run_ids: è¦æ£€æŸ¥çš„ run_id åˆ—è¡¨
        data_name: æ•°æ®åç§°
    """
    print("=" * 80)
    print(f"ğŸ” ç¼“å­˜è¯Šæ–­ï¼š{data_name}")
    print("=" * 80)

    for run_id in run_ids:
        print(f"\nğŸ“¦ Run ID: {run_id}")
        print("-" * 80)

        # 1. æ£€æŸ¥å†…å­˜ç¼“å­˜
        cache_key = (run_id, data_name)
        in_memory = cache_key in ctx._results
        print(f"  1ï¸âƒ£  å†…å­˜ç¼“å­˜: {'âœ… å­˜åœ¨' if in_memory else 'âŒ ä¸å­˜åœ¨'}")

        if in_memory:
            data = ctx._results[cache_key]
            if hasattr(data, '__len__'):
                print(f"      â””â”€ æ•°æ®å¤§å°: {len(data):,} æ¡è®°å½•")
            print(f"      â””â”€ æ•°æ®ç±»å‹: {type(data).__name__}")

        # 2. æ£€æŸ¥ç£ç›˜ç¼“å­˜
        if data_name in ctx._plugins:
            key = ctx.key_for(run_id, data_name)
            on_disk = ctx.storage.exists(key, run_id)
            print(f"  2ï¸âƒ£  ç£ç›˜ç¼“å­˜: {'âœ… å­˜åœ¨' if on_disk else 'âŒ ä¸å­˜åœ¨'}")

            if on_disk:
                meta = ctx.storage.get_metadata(key, run_id)
                if meta:
                    print(f"      â””â”€ ç¼“å­˜æ–‡ä»¶: {key}")
                    if 'lineage' in meta:
                        # æ£€æŸ¥ lineage æ˜¯å¦åŒ¹é…
                        current_lineage = ctx.get_lineage(data_name)
                        import json
                        cached_lineage_str = json.dumps(meta['lineage'], sort_keys=True, default=str)
                        current_lineage_str = json.dumps(current_lineage, sort_keys=True, default=str)
                        lineage_match = (cached_lineage_str == current_lineage_str)
                        print(f"      â””â”€ Lineage åŒ¹é…: {'âœ… ä¸€è‡´' if lineage_match else 'âŒ ä¸ä¸€è‡´ï¼ˆä¼šè§¦å‘é‡æ–°è®¡ç®—ï¼‰'}")

                        if not lineage_match:
                            print(f"      â””â”€ âš ï¸  Lineage å·®å¼‚åˆ†æ:")
                            print(f"          ç¼“å­˜ç‰ˆæœ¬: {meta['lineage'].get('version', 'N/A')}")
                            print(f"          å½“å‰ç‰ˆæœ¬: {current_lineage.get('version', 'N/A')}")
        else:
            print(f"  2ï¸âƒ£  ç£ç›˜ç¼“å­˜: âš ï¸  '{data_name}' ä¸æ˜¯æ’ä»¶æä¾›çš„æ•°æ®")

        # 3. æ£€æŸ¥ run_id æ ¼å¼
        print(f"  3ï¸âƒ£  Run ID æ ¼å¼æ£€æŸ¥:")
        print(f"      â””â”€ é•¿åº¦: {len(run_id)} å­—ç¬¦")
        print(f"      â””â”€ åŒ…å«ç©ºæ ¼: {'æ˜¯' if ' ' in run_id else 'å¦'}")
        print(f"      â””â”€ repr: {repr(run_id)}")

        # 4. æ˜¾ç¤ºæ‰€æœ‰ç›¸å…³çš„å†…å­˜ç¼“å­˜é”®
        related_keys = [k for k in ctx._results.keys() if k[0] == run_id or k[1] == data_name]
        if related_keys:
            print(f"  4ï¸âƒ£  ç›¸å…³å†…å­˜ç¼“å­˜é”®:")
            for k in related_keys[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"      â””â”€ {k}")
            if len(related_keys) > 5:
                print(f"      â””â”€ ... è¿˜æœ‰ {len(related_keys) - 5} ä¸ª")

    print("\n" + "=" * 80)
    print("ğŸ’¡ è¯Šæ–­å®Œæˆ")
    print("=" * 80)


def test_batch_processor_cache(ctx, run_ids, data_name):
    """
    æµ‹è¯• BatchProcessor æ˜¯å¦æ­£ç¡®ä½¿ç”¨ç¼“å­˜

    Args:
        ctx: Context å¯¹è±¡
        run_ids: è¦æµ‹è¯•çš„ run_id åˆ—è¡¨
        data_name: æ•°æ®åç§°
    """
    from waveform_analysis.core.data.export import BatchProcessor
    import time

    print("\n" + "=" * 80)
    print(f"ğŸ§ª æµ‹è¯• BatchProcessor ç¼“å­˜æœºåˆ¶")
    print("=" * 80)

    # å…ˆæ‰‹åŠ¨åŠ è½½ä¸€æ¬¡ï¼Œç¡®ä¿ç¼“å­˜å­˜åœ¨
    print(f"\nğŸ“¥ ç¬¬ä¸€æ¬¡åŠ è½½ï¼šæ‰‹åŠ¨é€šè¿‡ Context.get_data() åŠ è½½")
    print("-" * 80)
    for run_id in run_ids:
        print(f"  â³ åŠ è½½ {run_id}...", end=" ")
        start = time.time()
        data = ctx.get_data(run_id, data_name)
        elapsed = time.time() - start
        print(f"âœ“ ({elapsed:.2f}s, {len(data):,} æ¡è®°å½•)")

    # è¯Šæ–­ç¼“å­˜çŠ¶æ€
    diagnose_cache_status(ctx, run_ids, data_name)

    # ä½¿ç”¨ BatchProcessor åŠ è½½
    print(f"\nğŸ“¥ ç¬¬äºŒæ¬¡åŠ è½½ï¼šä½¿ç”¨ BatchProcessor åŠ è½½")
    print("-" * 80)

    batch_processor = BatchProcessor(ctx)
    start = time.time()
    results = batch_processor.process_runs(
        run_ids=run_ids,
        data_name=data_name,
        show_progress=True,
        max_workers=2,
    )
    total_elapsed = time.time() - start

    print(f"\nğŸ“Š BatchProcessor ç»“æœ:")
    print("-" * 80)
    print(f"  æ€»è€—æ—¶: {total_elapsed:.2f}s")
    print(f"  æˆåŠŸ: {len(results['results'])} ä¸ª")
    print(f"  å¤±è´¥: {len(results['errors'])} ä¸ª")

    # âœ… æ­£ç¡®çš„éå†æ–¹å¼
    for run_id, df_run in results['results'].items():
        print(f"    âœ“ {run_id}: {len(df_run):,} æ¡è®°å½•")

    if results['errors']:
        print(f"  âš ï¸  é”™è¯¯:")
        for run_id, error in results['errors'].items():
            print(f"    âœ— {run_id}: {error}")

    # åˆ†ææ€§èƒ½
    print(f"\nğŸ’¡ æ€§èƒ½åˆ†æ:")
    print("-" * 80)
    avg_time_per_run = total_elapsed / len(run_ids)
    print(f"  å¹³å‡æ¯ä¸ª run: {avg_time_per_run:.2f}s")
    if avg_time_per_run < 1.0:
        print(f"  âœ… ä½¿ç”¨äº†ç¼“å­˜ï¼ˆæ¯ä¸ª run < 1sï¼‰")
    else:
        print(f"  âš ï¸  å¯èƒ½æœªä½¿ç”¨ç¼“å­˜ï¼ˆæ¯ä¸ª run > 1sï¼‰")


if __name__ == "__main__":
    print("""
ä½¿ç”¨æ–¹æ³•ï¼š

1. åœ¨ Jupyter Notebook ä¸­è¿è¡Œï¼š

```python
from debug_batch_cache import diagnose_cache_status, test_batch_processor_cache

# è¯Šæ–­å½“å‰ç¼“å­˜çŠ¶æ€
run_ids = ["Co60_R50", "All_SelfTrigger"]
diagnose_cache_status(ctx, run_ids, "df_events_with_code")

# å®Œæ•´æµ‹è¯• BatchProcessor ç¼“å­˜
test_batch_processor_cache(ctx, run_ids, "df_events_with_code")
```

2. å¦‚æœå‘ç°ç¼“å­˜æœªå‘½ä¸­ï¼Œæ£€æŸ¥ï¼š
   - run_id æ˜¯å¦å®Œå…¨ä¸€è‡´ï¼ˆå¤§å°å†™ã€ç©ºæ ¼ï¼‰
   - æ˜¯å¦åœ¨ä¸¤æ¬¡è°ƒç”¨ä¹‹é—´ä¿®æ”¹äº†æ’ä»¶ä»£ç 
   - æ˜¯å¦æ‰‹åŠ¨æ¸…ç©ºäº†ç¼“å­˜
""")
