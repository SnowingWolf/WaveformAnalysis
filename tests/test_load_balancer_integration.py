#!/usr/bin/env python
"""
æµ‹è¯• DynamicLoadBalancer é›†æˆåˆ° ExecutorManager å’Œ StreamingPlugin
"""

import time

import numpy as np


def test_executor_manager_integration():
    """æµ‹è¯• ExecutorManager çš„è´Ÿè½½å‡è¡¡é›†æˆ"""
    print("=" * 60)
    print("æµ‹è¯• ExecutorManager é›†æˆ")
    print("=" * 60)

    from waveform_analysis.core.execution import (
        disable_global_load_balancing,
        enable_global_load_balancing,
        get_load_balancer_stats,
        parallel_apply,
        parallel_map,
    )

    # 1. å¯ç”¨è´Ÿè½½å‡è¡¡
    print("\n1. å¯ç”¨å…¨å±€è´Ÿè½½å‡è¡¡...")
    enable_global_load_balancing(
        min_workers=2, max_workers=8, cpu_threshold=0.8, memory_threshold=0.85, check_interval=1.0
    )
    print("   âœ“ è´Ÿè½½å‡è¡¡å·²å¯ç”¨")

    # 2. æµ‹è¯• parallel_map ä½¿ç”¨è´Ÿè½½å‡è¡¡
    print("\n2. æµ‹è¯• parallel_map ä½¿ç”¨è´Ÿè½½å‡è¡¡...")

    def process_item(x):
        """æ¨¡æ‹Ÿå¤„ç†ä»»åŠ¡"""
        time.sleep(0.01)
        return x**2

    data = list(range(50))
    results = parallel_map(
        process_item,
        data,
        executor_type="thread",
        use_load_balancer=True,
        estimated_task_size=1024,  # 1KB per task
    )

    assert len(results) == len(data)
    assert results[10] == 100
    print(f"   âœ“ å¤„ç†äº† {len(data)} ä¸ªä»»åŠ¡")

    # 3. è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\n3. è·å–è´Ÿè½½å‡è¡¡ç»Ÿè®¡ä¿¡æ¯...")
    stats = get_load_balancer_stats()
    if stats:
        print(f"   - æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
        print(f"   - æˆåŠŸä»»åŠ¡æ•°: {stats['successful_tasks']}")
        print(f"   - å½“å‰ workers: {stats['current_workers']}")
        if stats["total_tasks"] > 0:
            print(f"   - å¹³å‡è€—æ—¶: {stats['avg_duration']:.3f}s")
    else:
        print("   âš  æœªè·å–åˆ°ç»Ÿè®¡ä¿¡æ¯")

    # 4. æµ‹è¯• parallel_apply
    print("\n4. æµ‹è¯• parallel_apply ä½¿ç”¨è´Ÿè½½å‡è¡¡...")

    def add_numbers(x, y):
        """æ¨¡æ‹Ÿå¤„ç†ä»»åŠ¡"""
        time.sleep(0.01)
        return x + y

    args_list = [(i, i * 2) for i in range(30)]
    results = parallel_apply(
        add_numbers,
        args_list,
        executor_type="thread",
        use_load_balancer=True,
        estimated_task_size=512,  # 512B per task
    )

    assert len(results) == len(args_list)
    assert results[10] == 30  # 10 + 20
    print(f"   âœ“ å¤„ç†äº† {len(args_list)} ä¸ªä»»åŠ¡")

    # 5. å†æ¬¡è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\n5. æ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯...")
    stats = get_load_balancer_stats()
    if stats:
        print(f"   - æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
        print(f"   - æˆåŠŸä»»åŠ¡æ•°: {stats['successful_tasks']}")
        print(f"   - å½“å‰ workers: {stats['current_workers']}")
        if stats["total_tasks"] > 0:
            print(f"   - å¹³å‡è€—æ—¶: {stats['avg_duration']:.3f}s")

    # 6. ç¦ç”¨è´Ÿè½½å‡è¡¡
    print("\n6. ç¦ç”¨å…¨å±€è´Ÿè½½å‡è¡¡...")
    disable_global_load_balancing()
    print("   âœ“ è´Ÿè½½å‡è¡¡å·²ç¦ç”¨")

    # 7. éªŒè¯ç¦ç”¨åæ— ç»Ÿè®¡ä¿¡æ¯
    stats = get_load_balancer_stats()
    assert stats is None, "ç¦ç”¨ååº”è¿”å› None"
    print("   âœ“ ç¡®è®¤å·²ç¦ç”¨")

    print("\nâœ… ExecutorManager é›†æˆæµ‹è¯•é€šè¿‡")


def test_streaming_plugin_integration():
    """æµ‹è¯• StreamingPlugin çš„è´Ÿè½½å‡è¡¡é›†æˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• StreamingPlugin é›†æˆ")
    print("=" * 60)

    from waveform_analysis.core.plugins.core.streaming import StreamingPlugin
    from waveform_analysis.core.processing.chunk import Chunk

    # 1. åˆ›å»ºå¯ç”¨è´Ÿè½½å‡è¡¡çš„æµå¼æ’ä»¶
    print("\n1. åˆ›å»ºå¯ç”¨è´Ÿè½½å‡è¡¡çš„æµå¼æ’ä»¶...")

    class TestStreamingPlugin(StreamingPlugin):
        """æµ‹è¯•ç”¨æµå¼æ’ä»¶"""

        provides = "test_data"
        depends_on = ()
        dtype = np.dtype([("value", np.int32)])

        # å¯ç”¨è´Ÿè½½å‡è¡¡
        use_load_balancer = True
        load_balancer_config = {"min_workers": 2, "max_workers": 4, "cpu_threshold": 0.75}

        def compute_chunk(self, chunk, context, run_id, **kwargs):
            """å¤„ç†å•ä¸ª chunk"""
            time.sleep(0.01)
            # ç®€å•åœ°è¿”å›ç›¸åŒçš„ chunk
            return chunk

    plugin = TestStreamingPlugin()
    print("   âœ“ æ’ä»¶åˆ›å»ºæˆåŠŸ")
    print(f"   - use_load_balancer: {plugin.use_load_balancer}")
    print(f"   - load_balancer_config: {plugin.load_balancer_config}")

    # 2. éªŒè¯è´Ÿè½½å‡è¡¡å™¨å·²åˆå§‹åŒ–
    print("\n2. éªŒè¯è´Ÿè½½å‡è¡¡å™¨...")
    assert plugin._load_balancer is not None, "è´Ÿè½½å‡è¡¡å™¨åº”å·²åˆå§‹åŒ–"
    print("   âœ“ è´Ÿè½½å‡è¡¡å™¨å·²åˆå§‹åŒ–")

    # 3. è·å–æ’ä»¶çš„è´Ÿè½½å‡è¡¡ç»Ÿè®¡
    print("\n3. è·å–åˆå§‹ç»Ÿè®¡ä¿¡æ¯...")
    stats = plugin.get_load_balancer_stats()
    if stats:
        print(f"   - æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
        print(f"   - å½“å‰ workers: {stats['current_workers']}")

    # 4. æµ‹è¯•å¹¶è¡Œå¤„ç†ï¼ˆæ¨¡æ‹Ÿï¼‰
    print("\n4. æµ‹è¯•å¹¶è¡Œå¤„ç†...")

    # åˆ›å»ºæµ‹è¯• chunks
    def create_test_chunks(n=20):
        """åˆ›å»ºæµ‹è¯• chunks"""
        # ä½¿ç”¨æ­£ç¡®çš„ dtypeï¼ŒåŒ…å« time, dt, length å­—æ®µ
        dtype = np.dtype(
            [("time", np.int64), ("dt", np.int32), ("length", np.int32), ("value", np.int32)]
        )
        for i in range(n):
            data = np.array([(i * 100, 1, 100, i)], dtype=dtype)
            yield Chunk(
                data=data,
                start=i * 100,
                end=(i + 1) * 100,
                run_id="test_run",
                data_type="test_data",
            )

    # æ¨¡æ‹Ÿå¹¶è¡Œå¤„ç†
    input_chunks = create_test_chunks(20)
    output_chunks = list(plugin._compute_parallel(input_chunks, context=None, run_id="test_run"))

    assert len(output_chunks) == 20
    print(f"   âœ“ å¤„ç†äº† {len(output_chunks)} ä¸ª chunks")

    # 5. è·å–æ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯
    print("\n5. æ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯...")
    stats = plugin.get_load_balancer_stats()
    if stats:
        print(f"   - æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
        print(f"   - æˆåŠŸä»»åŠ¡æ•°: {stats['successful_tasks']}")
        print(f"   - å½“å‰ workers: {stats['current_workers']}")
        if stats["total_tasks"] > 0:
            print(f"   - å¹³å‡è€—æ—¶: {stats['avg_duration']:.3f}s")

    print("\nâœ… StreamingPlugin é›†æˆæµ‹è¯•é€šè¿‡")


def test_backward_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§ï¼ˆé»˜è®¤ä¸å¯ç”¨è´Ÿè½½å‡è¡¡ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å‘åå…¼å®¹æ€§")
    print("=" * 60)

    from waveform_analysis.core.execution import get_load_balancer_stats, parallel_map
    from waveform_analysis.core.plugins.core.streaming import StreamingPlugin

    # 1. é»˜è®¤æƒ…å†µä¸‹ï¼Œè´Ÿè½½å‡è¡¡æœªå¯ç”¨
    print("\n1. éªŒè¯é»˜è®¤æœªå¯ç”¨è´Ÿè½½å‡è¡¡...")
    stats = get_load_balancer_stats()
    assert stats is None, "é»˜è®¤æƒ…å†µä¸‹åº”è¿”å› None"
    print("   âœ“ é»˜è®¤æœªå¯ç”¨")

    # 2. parallel_map ä»ç„¶æ­£å¸¸å·¥ä½œ
    print("\n2. æµ‹è¯• parallel_map é»˜è®¤è¡Œä¸º...")

    def process(x):
        return x * 2

    results = parallel_map(process, list(range(10)), executor_type="thread")
    assert results == [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
    print("   âœ“ parallel_map æ­£å¸¸å·¥ä½œ")

    # 3. StreamingPlugin é»˜è®¤ä¸ä½¿ç”¨è´Ÿè½½å‡è¡¡
    print("\n3. éªŒè¯ StreamingPlugin é»˜è®¤è¡Œä¸º...")

    class DefaultPlugin(StreamingPlugin):
        provides = "default_data"
        depends_on = ()
        dtype = np.dtype([("value", np.int32)])

    plugin = DefaultPlugin()
    assert plugin.use_load_balancer is False
    assert plugin._load_balancer is None
    print("   âœ“ StreamingPlugin é»˜è®¤æœªå¯ç”¨è´Ÿè½½å‡è¡¡")

    print("\nâœ… å‘åå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    print("\n" + "ğŸš€ å¼€å§‹æµ‹è¯• DynamicLoadBalancer é›†æˆ" + "\n")

    try:
        # æµ‹è¯• ExecutorManager é›†æˆ
        test_executor_manager_integration()

        # æµ‹è¯• StreamingPlugin é›†æˆ
        test_streaming_plugin_integration()

        # æµ‹è¯•å‘åå…¼å®¹æ€§
        test_backward_compatibility()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        exit(1)
